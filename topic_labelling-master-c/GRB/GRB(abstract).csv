"Deep Learning,Convolution Neural Networks,Object Detection Networks,MLP,Digital Image Processing,PCBA Inspection,AOI","The automatic inspection of Printed Circuit Board Assembly (PCBA) is one of the most important issues in industry. Many AOI companies in Taiwan, such as Machvision, TRI, Utechzone, etc., have developed many AOI systems to help facilitating the PCBA process. Currently, due to the low defect detection rate, the PCBA process heavily depends on human inspectors such that the factory automation cannot be achieved. Recently, deep learning networks have been prosperously studied and produce reliable classification and detection results. Therefore, this study applies deep learning neural networks, including Object Detection Networks (ODN), convolution neural networks (CNN), and digital image process (DIP) to robustly segment the PCBA components, Dual In-line Package (DIP) and Surface Mount Device (SMD), from the PCB and expect to reduce the overkilled and under-killed rates. In this project, the case study company is one of the largest electronic manufacturer in Taiwan. A three-year project is proposed to integrate 2D/3D digital image process and deep learning networks to solve the ineffectiveness problem of current AOI PCBA inspection process. For the first year, instead of extracting ROI (region of interest) information through Gerber file, we had tried a color MLP to segment the SMD components but with unsatisfied result, and then a CNN model was built to distinguish good components from defectiveness with manual image segmentation, and meanwhile the hardware of 3D profile builder has been also constructed . In the second year, we will replace the color MLP with an Object Detection Networks (Yolo and FRCNN), which will extract the ROI's of SMD components with bounding boxes, and then build up DIP algorithm to inspect defectiveness simultaneously. Finally, in the third year, the self-built 3D profiler and the Gocator 3D sensor will be used to obtain the 3D information of SMD for comparison, and then a 3D-CNN model will be built to detect the defective components in a PCBA process."
"Deep Learning, Machine Learning, Reinforcement Learning, Robotic Manipulation.","This three-year project will work on the design, development, and implementation of a deep learning based system for controlling a robotic manipulator with visual feedback. The robot controller learns autonomy by a series of pixel-based images and without any prior knowledge of the working environment. We build the work based on the success of our recent deep reinforcement learning and develop a robot manipulation system for learning simple tasks with a multi-joint robot manipulator using external visual observation. In the first year, a tailored Deep Q Network (DQN) architecture will be proposed to perform the simple target reaching task after training in simulation and transferring to a real manipulator. As well, in the second year, in addition to a tailored DQN will evolve to accommodate the basic skill of obstacle avoidance, a newly proposed capsule network will replace the function of the convolution neural network as a feature extractor in DQN, which is vulnerable to variations in translations and rotations of images. It is noted that not just only does the avoidance occur on the end effector but also on the serial links (the body itself). The main task in the third year is aimed at expanding the capability and capacity of the proposed DQN to integrate the functionality of learned heterogeneous skill derived from different working configurations. These basic behaviors are the common problem in robot motion control and operation. All of these tasks proposed in this project make it possible to enhance the deep learning implemented in robotics for the industries and are indispensable techniques in the smart manufacturing of prompted Industry 4.0."
"Deep recommendation model, matrix factorization, latent factors, deep learning, autoencoder, recommender systems","This project plans to leverage on the deep learning technology to build a multi-objective recommendation model, which relaxes the constraints of the matrix factorization-based recom- mendation models. The matrix factorization-based recommendation models at least have the following problems.

1. MF-based models assume that the weight of each latent factor is the same, which may not always be a reasonable assumption.

2. MF-based models assume that each latent factor is independent of other factors, which may not always be a reasonable assumption.

3. MF-based models require the number of latent factors of a user equaling the number of latent factors of an item. However, this may not be a good encoding mechanism.

4. We probably over-simplify the interaction between a user and an item if only applying the inner-product operation. Particularly, we should consider higher-order interactions, such as the kernel method or the deep learning related operations.

This research attempts to design the recommendation model based on the deep learning architecture to relax these restrictions. For the first issue, we have already developed a prototype such that each latent factor has distinct weight. Initial experimental results show that the new method performs better than the other MF-based approaches on the test dataset in terms of the root-mean-squared-error (RMSE).

In addition to recommender systems, MF-based approaches can be applied to a wide range of applications, such as link prediction, imputation of the missing values, image compression, etc. This study may relax the constraints of the traditional MF-based approaches, so the results can also be applied to the above domains. Since the new techniques are more general than the MF-based approaches, we may get better results on the above applications."
"Deep reinforcement learning, Deep learning, Feature matching, Feature descriptor, Feature detector","In the field of computer vision, there are many tasks need the technique of feature matching such as image retrieval, object recognition, localization, image stitching and stereo matching. To achieve the target mentioned above, the motivation of feature matching is to compare the two input images with their corresponding features in order to check if there exist any similarity between this image pair. It can be separated into two main procedures to accomplish the calculation of feature matching in current research method. The first one is feature detection. Since the final target is to match the given image pair, it is necessary to find every feature in the corresponding image, and these features must be irreplaceable, i.e the detected features must be representative for that input image. Second step is feature description. It aims to make the machine have the ability to transfer the given image into a description vector, which is also known as a descriptor. In this project, we will utilize the learning framework of deep reinforcement learning to design a feature detector which can automatically decide the amount feature numbers and use the concept of deep learning to design a feature descriptor which can deal with the easy-positive samples and hard-positive samples at the same time. Furthermore, we will combine the feature detector and descriptor into an end-to-end training to boost the overall matching performance. The novelty of this project is very high no matter it is in the design of detector or descriptor since there are no prior research aim to take the above method."
"haptics, deep learning, scene recognition, immersive virtual environment","In this project, we design a 4D-VR cinema combined with the experience of haptic feedback. While users are watching VR movie, they not only receive the visual and auditory feedbacks from their first-person perspective, but also feel the haptic experiences according to different movie scenes. The 4D VR-cinema contains a scene recognition system and a set of haptic devices named as Haptic Simulator. In scene recognition system, we hierarchical deep learning methods to construct an object detector which can sense and locate specific objects (e.g. fire, light, umbrella and snow) in a movie scene. According to these detected objects, the scene recognition system then classifies the movie scenes into four major categories, which are glare, scorch, gale and cold. In addition, we also design a haptic device namely as Haptic Simulator to control the corresponding haptic modules to simulate immersive environments with haptics which are based on the movie scene for VR-movie viewers."
"Deep learning, fast algorithms, reinforcement learning, meta-learning, online display advertisement, real-time bidding","In this project, we hope to study deep learning algorithms and design related algorithms for the following three goals: to accelerate the current deep learning training process by combining the input data compression techniques and simplify the training network structure while maintaining an acceptable training quality, to study how deep learning algorithms can be applied to do model-free meta-reinforcement learning, and to apply deep learning models on predicting the winning prices for real-time bidding of online display advertisement."
"Elderly care, deep learning, low-resourced speech recognition, multilingual code-switching speech recognition, empathetic response","With the advances in information technology, how to let the elderly live in their own home with dignity is one of the most important fields of the technology for health care in recent years. This project proposes a research plan to study the technology on speech and language processing, deep learning, and artificial intelligence for a multiparty interactive dialogue system with empathetic response in three years. The research topic of the project is the combination of the four research topics: speaker identification, low-resourced and multilingual code switching speech recognition, multi-party dialog state tracking and dialog action selection mechanisms, and empathetic response generation. For low-resourced and multilingual code switching speech recognition, this project will focus on Taiwanese and Mandarin speech recognition.
	In speaker identification part, this project intends to use deep learning method to build an audio-visual speaker identification system which focus on text-independent speaker identification tasks. In low-resourced and multilingual code-switching speech recognition part, this project not only enriches Taiwanese speech  and text corpus, but also integrates speaker identification and transfer learning techniques. In dialog state tracking and dialog action selection mechanism part, the project plans to establish a robust dialog state tracker, dialog action selection and addressee selection model. This project will analyze the user semantic and use the results to select a dialog action and the addressees. In the research of empathetic response generation part, the project intends to generate an empathetic response that lets the user know that we are sharing the same emotional experience.
	Finally, the project will integrate research results in the first two years and use these results to build a multiparty dialogue system with empathetic response. The dialog system can interact with the elderly by using mobile phone or robot as the interactive platform. And the interactive platform consists of the following functions: interactive warm companionship, emotional empathy, friend links, and other warm functions."
"Recommendation System, Latent Topic Model, Matrix Factorization, Aspect Analysis, Deep Learning, Convolutional Neural Network, Generative Adversarial Network","The booming of Internet has increasingly promoted the rise of new types of online information and e-commerce platforms. It is an important application and development trend to attract more users and increase the traffic of the information platform through a personalized recommendation system. Personalized article and cold start recommendations are important applications and issues for emerging online information platforms. Deep learning recommendation systems and Generative Adversarial Network (GAN) for optimizing model learning are popular research issues. GAN recommendation is a new research topic, and there are very few literatures. In the first year, this project will investigate a new article recommendation approach combining aspect-based latent feature extraction and deep learning model. The proposed approach uses latent topic model – LDA (Latent Dirichlet Allocation) and convolutional neural network (CNN) to extract aspect-based latent features, and learns the aspect preference weights of different users through the attention network layer. The existing literatures do not use LDA aspect analysis combined with CNN for latent feature extraction. There is also no deep learning recommendation approach with aspect attention mechanism. The developed approach will improve the traditional aspect analysis and deep learning recommendations. In the second year, this project will investigate a new hybrid recommendation method based on Generative Adversarial Network (GAN), focusing on solving cold start recommendation issues. Existing researches on GAN recommendations adopt matrix factorization as the core preference prediction model. There are still some shortcomings for the cold start recommendation. This project will develop new GAN-based core preference prediction models, which combine the advantages of content-based LDA recommendation and CNN feature extraction, enhanced with deep learning attention mechanism to improve the effectiveness of preference prediction. There is no GAN recommendation literature focusing on the issues of recommending cold start and new articles. The proposed approaches will strengthen the learning of latent features of cold start items and user preferences through GAN's competitive learning framework and sampling mechanism, and further improve GAN's effectiveness on recommending cold start articles."
"patent analysis, cross-lingual topic model, deep learning recommender, cross-regional patent map","With the rapid growth of the economy and business globalization in recent decades, managing an increasing volume of patent documents written in different languages has become inevitably important from both legal and managerial perspectives. Thus, to analyze in different regions and diverse writing styles and languages of patent documents is very time-consuming and often requires huge human efforts for cross-language patent translation and cross-regional analysis. However, the most existing patent cross-language applications just adopt machine learning for the monolingual dataset and use machine translation techniques or bilingual dictionary for translating the query into another language, thereby limiting the accuracy of cross-language patent search and information retrieval. In this research, we propose this three-year research plan to solve those major issues. The first year of this research plan is to collect patent databases from three different regions, including the United States, Taiwan, and China. Thus, we develop the cross-regional patent comparison and analytics system based on cross-lingual patent topic model among English and Chinese. In the second year, we extract cross-lingual word embedding features for constructing cross-regional patent collaborative deep learning recommender. For the last phase, we conduct the comprehensive cross-regional patent analysis for providing more insights into the global technology trend to enable the R&D, industries, or policymakers to forecast future technologies and identifying worldwide potential competitors or collaborators."
"clothing brand and price information retrieval, feature extraction, classification, deep learning, clothing collocation subjective test","Over the past decade or so, the behavior of human consumption has changed significantly with the popularization of the Internet and smart mobile devices. Online shopping has become a popular mode of consumption for the public. Clothes make up a large part of the consumer's online shopping market. Customers often need to use the multiple search process when shopping online. So, a simple and effective clothing search recommendation system is worth to study. Designing an image-based way to search clothes on Internet store – see, snap, search, purchase, is practical and convenient, and therefore is the goal of this research project. Currently, there is no specific research focused on the design of the clothing brand and price information retrieval system. We will design a clothing retrieval system that can predict brand and price. Also, since there is no clothing dataset containing brand and price attributes, we will need to construct a clothing dataset with brand and price information. With this newly collected clothing dataset, we can design a new deep learning based model to retrieve clothing brand and price information with high accuracy. We will also deal with clothing collocation problem by first constructing a clothing collocation subjective test dataset. Then, we use this dataset to learn a deep learning based model to predict the clothing collocation scores, and the clothing collocation model having higher Pearson linear correlation coefficient (PLCC) with subjective opinion will be used to recommend customers the clothing item. Finally, we hope that the research results and technology transfer of this project will be used by domestic and foreign industries. I also hope that the research results in this respect can be published in famous conferences or journals to increase Taiwan's international visibility."
"Mobil Urban Probe, IoT, Cloud Information System, Deep Learning, GIS Visualization, 3D Interface, Urban Thermal Environment","For the mitigation of UHI effect, most researches concentrated near-surface layer, which limited the comprehension of urban thermal environment. This study would include the vertical thermal structure of urban climate such as, urban canopy and Urban boundary layer.
Based on integrated data application by drones, IoT, crowd sensing and cloud data base, this study would survey the thermal environmental data in horizontal and vertical interspace of urban areas, in order to construct 3D cloud data base of urban thermal environments.
In the 1st year, sensor instruments, field survey and their cloud data base would be executed, and the deep learning of the data would be explored. In the 2nd year, application of deep learning models and parameters visualization and 3D cloud data base of urban thermal environments would set up for the phenomenon prognosis and interactive application. The results could be implemented for corrected urban planning, environmental management and building code regulation."
"Machine Learning, Deep Learning, Neural Networks, Low-Power System, Multi-Processor Silicon-on-Chip, Reconfigurable Heterogeneous Systems","In this proposal, we will comprehensively tackle the various problems involved in designing and evaluating a compute node for large-scale machine learning and deep learning applications.  The aim of this project is to investigate reconfigurable MPSoC systems to accelerate the computation time of the above-mentioned applications, and develop the necessary simulation and modeling infrastructure for reconfigurable MPSoCs.  We propose to build an infrastructure that allows rapid power-performance trade-offs of the entire multi-die MPSoC system during early design stages.  Using this infrastructure, we intend to explore various combinations of dynamic power management (DPM) techniques for both fine-grain and coarse-grain MPSoCs, by varying both the processor and network microarchitecture in a parameterized fashion.  The other goal of this project is to investigate techniques from the circuit-level to the architectural-level to reduce the power consumption of systems that have CNNs executed on it.  

The first part of this project is to develop fast and power efficient CNN techniques for GPU-based systems, and then explore techniques to integrate multiple CPUs and GPUs synergically to become a heterogeneous SoC system.  Multi-core processors and heterogeneous computing are two possible ways to boost up the performance of the existing compute nodes.  In such heterogeneous systems, processor cores provide generality over a wide range of applications, while specialized accelerators provide better power efficiency and performance for specific computation requirements.  In the first phase, we propose to develop a fast and power efficient CNN networks specific for heterogeneous system deployment, and investigate low power GPU techniques for CNNs at the framework level.  We plan to develop new architectures for such a heterogeneous system, and deploy the proposed fast and power efficient CNN network to measure its performance.  Potential low power techniques include accuracy reduction, workload balancing, task pipelining, dynamic voltage and frequency scaling, memory prefetching, computation sharing, etc.  

In the second phase of the sub-project, we plan to develop a modeling framework for reconfigurable on-chip networks for MPSoC systems with consideration of the multi-die InFo technology.  A state-of-the-art MPSoC is typically composed of multiple heterogeneous components, including CPUs, GPUs, ASICs, and even FPGAs.  These components are traditionally interconnected with a network fabric and a large amount of on-chip caches on a single die.  These heterogeneous components enable an MPSoC system to speed up critical sections of the application and improve power efficiency.  To extend the network fabric to connect multi-dies and provide run-time configurability, an EDA platform is required for modeling the timing, power, and performance of such a system.

In the third phase of the sub-project, we plan to develop DPM techniques for MPSoCs for machine learning applications.  Although DPM techniques have been presented for various on-chip components, DPM techniques that can synergistically tackle all the components of an on-chip system are needed.  These techniques need to consider the interplay between power and thermal contributions of individual components to balance the overall chip thermal profile, while keeping the adverse performance impact to a minimum.  We will investigate various combinations of DPM techniques for MPSoCs."
"Heterogeneous Network, Deep learning, B5G Mobile Communication, Fog Computing, Cloud Computing, Cloud Radio Access Networks, Fog Radio Access Networks.","The 3G and 4G mobile communications had been developed for many years. The 5G mobile communication is scheduled to be launched in 2020. In the future, network environment will exist a great diversity of different cells and communication technologies that forms a special architecture of Heterogeneous Networks (HetNet). Under the complex network architecture, interference and handover problems are critical challenges in access network. How to efficiently manage the different small cells and access technologies for the better quality of service is a vital research issue. In order to achieve these goals, the integrated research project expects that our proposed Deep Learning-based B5G Mobile Network is able to enhance and improve communication performance through combing some specific technologies, e.g., deep learning, fog computing, cloud computing, cloud radio access network (C-RAN) and fog radio access network (F-RAN). The main project will develop a B5G mobile network platform and the sub-project 1 will construct the platform as a Deep Learning-based B5G Mobile Network Platform. In the first year, our main goal is to build a base station in a novel access network based on C-RAN and F-RAN architectures, and connect the deep learning platform with it. The computational efficiency of the deep learning platform will be enhanced by using cloud and fog computing technologies. The main project will adopt deep learning methods to enhance 10% network transmission efficiency. The sub-project 1 will investigate data preprocessing methods to achieve 95% data accuracy. In the second year, the main goal is that the deep learning-based B5G mobile networks platform will be extended to heterogeneous architecture. The main project implements the extended base station by using power amplifier and low noise amplifier, and investigates scheduling problem in control channel of base band unit (BBU) to increase 10% number of users. The sub-project 1 aims to connect the deep learning platform with the heterogeneous B5G mobile network platform on a large-scale, and investigates network optimization problem based on deep learning algorithms. Deep learning computational efficiency and accuracy rate will be increased 20% by using metaheuristic algorithms, clustering algorithms, classification algorithms and network service-oriented methods. In the third year, the main goal is to optimize the deep learning-based heterogeneous B5G mobile network. The main project researches about mode switch of demodulation method that based on deep learning and associate rule method to reduce 10% packets loss rate and to increase 20% system stability. The sub-project 1 combines deep learning algorithms with associated rule methods for increasing 20% data utilization. Other sub-projects are able to do their researches on this platform. This integrated research project also collaborate with industries. The achievements of the main project and sub-projects will be integrated and provided for the Far Eas Tone (FET) Telecommunications Co., Ltd. to verify the practicality of this integrated research project."
"deep learning, software engineering, defect prediction, automated program repairing, search-based repair, LSTM, Attention, RNNrepairing, search-based repair, DBN, RNN","A complete computer system usually consists of two main parts: hardware and software. With the development of computer technology in the past three decades, the importance of software is increasing. Software Development Life Cycle (SDLC) can typically be divided into requirement elicitation, system analysis & design, coding, and system maintain. Among the cycle, software maintenance process usually takes a lot of effort and cost almost the same as the development process. That is the main reason why software quality assurance is essential. Deep learning is a booming technique in the machine learning literature. It shows important breakthrough in many aspects of computer science. However, whether deep learning can be used to improve the software maintenance seems to be an unknown. Therefore, we propose a 3-year project to study two important research problems of software maintenance, defect prediction and automated program repairing, based on deep learning techniques. Firstly, in the error prediction, we implement program language processing skill to process data and enhance the credibility of the feature. Afterward, with different text representation ways (Bag of Words, Word Embedding), using different deep learning models (LSTM model, Attention model) do feature excitation. Finally, the features obtained are input into the machine learning classification models (Supported Vector Machine, Naive Bayes, Random Forest) to do defect prediction. For the software repair part, we will implement RNN to optimize the fix localization. Use the location of the repair material, the similarity of the repair material and so on 5 features as a training input to obtain the order of the repair materials and improve search efficiency. In addition, we will use deep learning model to verify repair candidates. In test suite based repair process, our model can filter and discard candidates with obvious errors to achieve cost savings. As a result, we can analyze and optimize the process of predicting errors. Basically this 3-year project would propose three models for defect prediction and automated program repairing. The first selected model is designed for feature extraction and it can be a more efficient solution to predict the wrong file. The second selected model learns from the ingredients features to identify the ingredients that are easier to repair errors instead of choosing randomly. The third selected model is proposed to learn from the candidate characteristics to identify the candidates which have more fitness. This will reduce the cost of executing the test cases. Some experiments will be performed real data and some Computer-aided software engineering (CASE) tools will also developed accordingly. These three selected models and CASE tools will effectively solve the dilemma of today's software debugging and also greatly improve the efficiency and performance of software maintenance."
"Distributed Deep Learning computing, hierarchical distributed computation, deep learning model, deep learning applications, OpenCL acceleration for deep learning computation, virtualization, heterogeneous parallel computing, graphics accelerators, FPGA, performance analysis tool, Internet Of Things applications, smart environment, smart medical, smart wearhousing","This project focuses on developing a distributed deep learning computing framework for the Internet of Things (IoT) applications, smart medical and factory. The distributed computing framework leverages the key property of the distributed deep neural network (DDNN) model, which allows an end device to handle partial network layers in feedforward inference, and the rest of the network layers could be further processed by a server device to improve the accuracy, if necessary. The hierarchical handling of network layers is very different from that in the mainstream deep learning computing systems, which often use one or more computer nodes with graphical processing units or manycore processors to accelerate the training process of an application model. The proposed design is able to satisfy the huge computational demands required by the smart IoT applications, and reduces the demand for computing power of end devices, which results in lower cost of the system deployment. In addition, when the same application runs on the hardware platforms with different computing capabilities, the system-wide performance optimization is done by tuning the model parameters on each hardware to adjust the loading of end and server device pairs, which will reduce the optimization time since it does not involve significant modification of the application source code. 

This application-oriented hardware/software co-design approach is adopted to develop the prototype framework, where we focus on the development of the distributed deep neural network computation layer (DDNNCL). DDNNCL is responsible for the efficient execution of the developed model, where the computation required by the inference operations is able to be offloaded to the acceleration hardware on an end device or the accelerator on the server device by the computation offloading module through the OpenCL/CUDA interfaces. DDNNCL also includes the development of the virtualization technology, which consolidates available computing resources for handling the inference operations required by multiple end devices, while the computing demand of each device is satisfied and the performance of the entire computing system is maximized. We will select a real application scenario to demonstrate the capability of the developed system. Furthermore, our developed code and technical documents will be opened in the hope of facilitating the advance of the technology and helping Taiwan’s companies for developing complex IoT systems."
"carpal tunnel syndrome, deep learning, artifical intelligence, dynamic ultrasound imaging, nerve registration","Median nerve entrapment, usually referred to as carpal tunnel syndrome, is a common and debilitating condition clinically. The nerve fiber is pathologically entrapped by the surrounding tissues, which leads to numbness and weakness of the innervated tissues. The recent advances in high-frequency ultrasonic imaging markedly promote the popularity of using ultrasound for the evaluation of median nerve entrapment. Compared with the electrophysiological studies, an increasing line of evidence indicates that the abnormality revealed by ultrasonic imaging has higher correlation with the clinical symptoms in median nerve entrapment. Since the entrapment commonly results from repetitive motion of the surrounding tissues, it is generally believed that the entrapped nerves exhibit abnormal motion patterns on the dynamic images. However, parameters of the motion patterns are usually chosen intentionally, rather than from a comprehensive, objective basis. Additionally, most of the tracking and analysis of the dynamic pattern require manual and off-line work, which is time consuming and demands tons of labors, making it hard to implement the analysis in real time. We recently developed a smart system automatically registering median nerve in dynamic sonography using instance segmentation. In this proposal, we seek to improve the tracking performance of the developed system, and differentiate which motion patterns are highly correlated with nerve entrapment using deep learning. Our main goal is to assist the diagnosis of median nerve entrapment using artificial intelligence and we anticipate that the accomplishment of the project will promote the application of machine learning in medical imaging, in particular the object tracking in dynamic sonography, and improve the clinical service and decision-making by an intelligence-based assistive framework."
"Deep Learning, Patent, Natural Language Processing, Graph Neural Network, Transfer Learning","This project aims to help inventors create new patents by Deep Learning. Our previous project is based on Euclidean domain such as CNN and RNN. This new project focuses on non-Euclidean domain such as Graph Neural Network (GNN). By exploring both, we expect to know which would be better for what kinds of patent tasks. Particularly, we hypothesize that a patent is in fact a graph, in terms of using patent claims to define a patent scope. Therefore, a project milestone is to generate text between two vertices in the same patent graph or different patent graphs. Human would be required to judge whether the generated text makes any practical sense. Such human-machine co-creation is how “Augmented Invent-ing” works. 
In order to reach the milestone, this project is planned with three phases: (1) Graph Neural Network, (2) Transfer Learning, and (3) “Augmented Inventing” by Graph Genera-tion. In the first phase, we plan to leverage DeepMind “Graph Nets” library and Google Pa-tents Public Datasets. GNN for NLP is still an emerging field. A challenge is to figure out how to convert patent claims into graphs and save them in graph database. In the second phase, we plan to explore Transfer Learning in four quadrants. One dimension of a quadrant could be “the transfer learning for artificial neural networks” or “the transfer learning for pa-tent domains.” The other dimension could be “the transfer learning in Euclidean domain” or “the transfer learning in non-Euclidean domain.” Particularly, we plan to apply the BERT model by Google which reaches state-of-the-art results on 11 NLP tasks. In the third phase, we anticipate two levels of Augmented Inventing and possibilities in between. For example, at the lower level, a use case is to predict the next word a patent engineer may write. At the higher level, a use case is to predict a new patent based on all existing patents. The project milestone we set is somewhere challenging enough between these two. At the final phase of this project, we have to figure out how to find the shortest or approximate path between two vertices in patent graphs, expand the path to graph and convert the graph to patent claims.  
The purpose of patent law is to “promote the progress of science and useful arts.” At the intersection of technology and law, we aim to push LegalTech forward. In addition, we aim to “accelerate the progress of science and useful arts” by augmenting human to invent faster, better and easier."
"Deep Learning, Deep Generative Models, Generative Adversarial Networks, Discriminators, Generators.","The generative adversarial network (GAN) is  a deep learning technique that can generate data. It has a wide variety of applications. In particular, it is taken as a promising solution for getting rid of the expensive annotation cost of supervised learning. In addition, it has shown great success on many computer vision and computational photography problems such as semantic segmentation, cross-domain relation learning, pixel-to-pixel translation between images, image super-resolution and image inpainting. The goals of the project are  improving training stability of the generative adversarial network, understanding how it works and verifying the ideas on several applications. For achieving these goals, we will propose methods for improving generators, 1-way generative adversarial network, 2-way generative adversarial network and study the theory behind the generative adversarial network. In addition to improving the stability on training generative adversarial networks, we would also expect to propose new deep generative models through deeper understanding of the theory behind generative adversarial networks. We will verify these ideas on a few real-world applications including image contrast enhancement, frame interpolation for videos, virtual dressing image synthesis and video generation. By providing better generative models, we hope to promote the applications of deep generative models and help developing unsupervised learning."
"deep learning, neural networks, magnetic resonance, electron paramagnetic resonance, positron emission tomography, compressed sensing, image reconstruction, tissue oxygenation","Artificial neural networks and deep learning are widely popular and in high demand in various fields these days. The integration of deep learning in tomographic imaging not only can facilitate image analysis, but also can improve image quality in the process of image reconstruction. Instead of training neural networks with images downstream of imaging processes, whose scanning parameters, detector or coil imperfectness, subject background, preprocessing steps, and many others are unknown and never take into account in the model training, we will focus on incorporating the networks into the generation of images. Specifically, we plan to dedicate efforts on developing deep learning guided magnetic resonance (MR) and electron paramagnetic resonance (EPR) compatible positron emission tomography (PET) image reconstruction. The proposed system is particularly suitable for investigating various biological and physiological problems in clinics. In particular, through the reconstruction of spin locations, EPRI can acquire the oxygenation status of tissues in living animals. The combination of EPRI, MRI, and PET can provide tumor hypoxia status and guide radiation therapy with hypoxic dosage boost. The project will provide the required software support and integration for MR and EPRI compatible PET inserts or systems. The goals of this project include (i) development of deep learning based attenuation correction for PET images by co-registering MR and CT, (ii) development of reconstruction algorithms that imposes Image sparsity regularization using neural networks (iii) development of adaptive neural networks for proximal mapping, (iv) development of deep-learning guided reconstructed algorithm in MR-PET and EPRI-PET imaging to enhance image quality and minimize artifacts, (v) development of generative models for compressed sensing reconstruction (vi) evaluation the PET/MRI and PET/EPRI system performance and computational efficacy of the developed methods using numerical and experimental phantoms. The reconstruction and optimization of the multi-modality image software platform will show the efficacy in various application-specific imaging."
"boccia, special education, scientific assistive device, intelligent coaching and training system, video processing, deep learning","The development trend of the intelligent vision and deep learning has raised lots of notification in commercial sports. These techniques, however, have not been widely applied to special education for the disabled yet. Individuals with disabilities usually performed not as well as typical developed individuals in motions, communication, and recognition aspects. Thus, the design of proper activities and the use of appropriate assistive devices can promote the physical development and activity participation of the disabled. Boccia is such a sport designed for people with disabilities, requiring highly coordinated motor skills and strategy planning. It has been proved that this sport can bring significant improvements in motor function, recognition ability, and social communication for the disabled. However, the game and the training of boccia participants requires much support from teachers, assistants, coaches and therapists. To promote health for the disabled and save education resources, we aim to design and develop an intelligent assistive technology and coaching system for boccia. The project includes three stages. At the first stage, we will apply the video processing technology to mark the ball positions and identify the movement features of each participant automatically. At the second stage, we will construct a deep learning model to classify the movements of each participant and analyze their skeleton parameters precisely. At the third stage, we will develop an intelligent coaching and training system which can provide different scenarios and suggestions to guide the participants with proper training strategy and practice program. The outcomes of the project will be applied to real games fields and schools for disabled community. We will also construct a cloud database to collect aa analysis results. These data can be retrieved for movement evaluation, exercise prescription, physical activity promotion, and also serve as references for more healthcare applications."
"Empty Nose Syndrome, Paranasal Sinus, Nasal Cavity Symmetry, Turbinates, Computed Tomography","Empty nose syndrome (ENS) is referred to as a clinical phenomenon in which people with clear nasal passages experience a range of discomforts. Patients with ENS may complain physical or emotional distress, such as nasal congestion, drainage, headache, paranasal aching, dyspnea, nasal and pharyngeal dryness, hyposmia, rhinorrhea or postnasal drip, nasal crusting, inability to concentrate, chronic fatigue, frustration, irritability, anger, anxiety, or depression and even hyperventilation syndrome. Since the terminology first used by Eugene Kern and Monika Stenkvist in 1994, ENS remains a poorly recognized but crippling disease for rhinologists and patients. The diagnostic criteria for ENS have not been established due to the lack of reliable objective measurement, neither have defined consistent causes. One shared characteristic of ENS is, however, loss of nasal turbinates, resulting into asymmetric nasal septum and the lateral wall. In the proposed project, we plan to quantitatively characterize the symmetry of the nasal cavity and correlate with the patient’s clinical complaints by constructing a deep-learning framework. The aims of the proposed project are threefold: (1) to quantify nasal cavity symmetry/asymmetry from three-dimensional Computed Tomography (3DCT) images; (2) to conduct preoperative and postoperative questionnaire surveys to characterize the patient’s ENS complaints; (3) to construct a symmetry/asymmetry classifier, in form of a deep-learning framework, that can morphometrically categorizes nasal septum and lateral wall and determine its relationship with the patient’s complaints. In the first year of the project, a preliminary deep-learning algorithm shall be designed and developed. The questionnaire surveys will be continuously conducted, with clinical helps of the co-PIs, during the two-year’s span. The questionnaire results, verified and validated, will serve as the ground truth to adjust the proposed model in most part of the second year of the project. The principal investigator expects to publish two academic journal articles."
"Elastic scaling, Distributed computing, Cloud native application, Deep learning, Computing framework, Performance optimization","With the arrival of the era of AI , deep learning has quickly become one of the mainstream computation workload in data centers and clusters. Especially for model training, it requires lots of computation power. Hence, how to reduce the computation time and cost for deep learning is a critical research problem. Distributed computing and cloud computing are the two pillars to address this challenge. Distributed computing allows us to utilize the abundant computing resources of a parallel computer system, and cloud computing paradigm provide cost efficient resources through dynamic resource management. As known, many existing computing frameworks, like TensorFlow, PyTorch, CNTK, already support distributed computations. The technologies to build a cloud platform based on virtual machine and containers are also getting matured. For instance, several deep learning computing frameworks already have their docker image available for users to quickly deploy and run their deep learning jobs. However, there is currently lack of the proper resource management tools to run deep learning jobs on cloud efficiently. Even worse, the natural of dynamic and shared resources in cloud environment can easily cause significant performance degradation to a deep learning job. Therefore, our project aims to address the following two key research problems when running deep learning jobs on cloud. The first problem is that the existing deep learning frameworks are distributed, but not elastic. Thus, deep learning jobs cannot adapt to the dynamic resource management in cloud. The second problem is that the gradient descent algorithm used by deep learning can produce high data transfer network traffic. But the network bandwidth and channels are often hard to be isolated in cloud environment. As a result, without proper resource management strategy, deep learning jobs can suffer significant network overhead and interference. To tackle the two problems, on one hand, this project will study and extend the current TensorFlow computing framework to support elasticity. On the other hand, we will study the resource usage and network communication pattern of deep learning to develop proper job scheduling and scaling algorithms, and implement the proposed approach in one of the well known container orchestrator (Kubernetes) for performance evaluations."
"Deep learngin, hash functions, image retrieval","Nowadays, images are one of the very important information available in the society. Human can easily identify the faces, objects, activities, etc. present in the image. This is a great challenge for computers to do the similar task and research is being done in this area from last two decades very actively. Image retrieval is one of the frameworks, where similar images are retrieved from a large-scale database against a query image. Nevertheless, convolutional neural network and deep learning concepts are being more popular to do such kind of task in computer vision. 

The research plan is to develop the image hashing code for image retrieval in large-scale database using deep learning approaches. Two types of deep learning models will be used to generate the hash codes in supervised and un-supervised fashion.

The convolutional neural network based framework will be developed for supervised hashing techniques. The aim is to learn a mapping from training images to binary code of k-bit, such that visually/semantically similar images are encoded to similar binary codes. Thus, the codes of intra-class images should be as similar as possible, while the codes of inter-class images should be as dissimilar as possible. This leads to an objective with following characteristics: pull the hash codes of similar images close to each other whereas push the hash codes of dissimilar images far away from each other. 

The unsupervised hashing techniques are required in real practice as annotating the large database is very time consuming and not feasible in very large-scale. A class of network called as auto-encoder will be used in this project for unsupervised hashing. The deep auto-encoder will be considered to train the hash codes from unsupervised training data. There are two networks in auto-encoder: 1) an encoder to convert the input image into a hash code, and 2) a decoder to project the hash code into image space. The encoder is a convolutional neural network, whereas the decoder is an up-convolutional neural network. The objective is to minimize the error between input image and projected image. After training, the decoder network is not required. Only trained encoder network will be used to compute the hash codes for images. 

The expected outcome of the project will be in the form of software for large-scale image retrieval using efficient hash codes computed by learning the training data in supervised and un-unsupervised manner. The outcome will be also in the form of published research articles arising from the project. Patents can be also filed based on the proposed work in this project."
"Smart grid, convolutional neural network, and metaheuristic algorithm.","In this three-year project, an intelligent smart grid management system will be designed and implemented to deal with three critical research issues in the smart grid environment. The problems are: (1) “electricity consumption forecasting,” “devices damage detection,” and “electrical power theft detection.” In the first year, we will use particle swarm optimization (PSO) and search economics (SE) to improve the results of short-term load forecasting (STLF) method to forecast the power consumption of a smart grid, which will be very useful in balancing the delivery of electric power. More precisely, the PSO will play the role of adjusting the weights of a neural network (NN) while the SEs will play the role of finding out a better optimizer for NN. In the second year, the goal is to develop a long-term learning model for fault detection based on the convolutional neural network (CNN) to recognize the reasons for unusual electric power. It will use a genetic algorithm (GA) to adjust the number of layers, neurons, and filters as well as the value of filters to improve the accuracy rate of this module. In the third year, the goal of this project is to distinguish electrical power theft from devices damage. The proposed system will integrate CNN with the clustering algorithm to make it an incremental classification algorithm, which makes it possible for this management system to construct additional classifiers on the fly. By using this method, the training time of a CNN can be significantly reduced. In summary, this project is aimed at developing an intelligent management system for smart grid based on metaheuristic and deep learning algorithms. It is expected that the proposed system will be able to provide services more precisely than a traditional management system for electricity consumption forecasting and smart grid monitor can."
"B5G, Evolved Packet Core, Artificial Intelligence, Deep Learning, Security Testing, Fuzz Testing, Anomaly Detection","This research project is a sub-project 2 of Deep Learning-based B5G Mobile Networks (DLMN). This research project focuses on the Deep Learning-based Security Testing and Anomaly Detection for B5G Mobile Networks. This research project will cover the whole system in three years, including access network security and core network security of B5G mobile communication network. In the first year of this project, we will first conduct Security Fuzz Testing research on User Equipment devices of B5G mobile network and integrate Deep Learning technologies to design and develop interactive Security Fuzzing tools that can communicate with User Equipment. It is expected to generate and cover more than 90% of the protocols of B5G mobile communications access network. In this way, there will be no need to customize the standard protocol format to test mobile devices manufactured by different vendors. In the second year of the project, we will further analyze the traffic flow of B5G access network and develop the anomaly detection mechanism based on Deep Learning technologies. It is expected that the proposed detection mechanism components will not seriously affect more than 10% of EPC front-end component performance, and timely detect and defense the time-dependent attacks and time-independent attacks. In the last year of the project, we will use Deep Learning techniques to analyze various complicated standard protocols in the core network. By comparing different deep learning algorithms to identify abnormal connection behaviors, we expected to achieve an accuracy of over 95% and discover unknown attacks."
"Adaptive Learning, Wearable Devices, Deep Learning Technologies, Big Data Analysis, Adaptive Mobile Learning System.","Adaptive learning is one of the most representative research issues in the field of digital learning research, but currently, most adaptive learning systems adjust the learning contents through the ways the learners formulate in advance. To make the systems have the automatic adaptability, it often involves collecting the feature data difficult for learners to express or hard to be shown subjectively, which usually requires combination with artificial intelligence for practice. Hence, this project plans to develop a wearable guide system combining deep learning technology with adaptive learning model through a three-year study and imports it to the field environment having abundant physical learning resources. Besides collecting mass learning process data of learners via the advantages of smart glasses, it also analyzes huge amounts of data by using the deep learning technology, so as to establish the learning behavior model suitable for learners and recommend individualized guide contents and flows based on this model. Furthermore, this project as well guides learners via AR technology and GPS electronic maps and provides a customized virtual-real guide way, to help learners to rapidly determine their locations and the locations of their learning objects. In this way, learners can acquire the needed learning information in a simpler and faster way. Next, this project plans the flows and tasks of the experiment activities and designs three learning models for the teaching activities: the wearable guide system combining deep learning technology with adaptive learning model, the wearable guide learning system and the traditional manual guide way, to discuss whether there is any difference in learning effectiveness of different learning models. In the end, through complete statistics analysis and effectiveness evaluation, combining with observation and videos of learning process, this project analyzes and compares the learning behaviors of different groups to verify that the adaptive learning system proposed in this project can effectively promote the students’ learning motivations and interests."
"minimally invasive surgery, artificial intelligence, robotics, automation, image guidance, augmented reality","The first Minimally Invasive Surgery (MIS) was conducted in 1987 by Dr. Phillipe Mouret. Contrast to the conventional open surgery, MIS was operated with endoscope for images and the long surgery instruments through the small openings on the abdomen. Since the openings are small, MIS achieves low infections and much better recoveries of patients. Due to the operational characteristics of MIS, the medical robotic system, Da Vince, was introduced in 1994 and has been a great success. It adopted tele-operations of robot arms and 3D displays for better integration of technology and surgery. Just as the vast advancement witnessed lately in autonomous vehicles, autonomous surgery system is the obvious next step in MIS. 
A three-year integrated project for “Intelligent Autonomous MIS System Development” is proposed with three research topics: (1) Intelligent Robotic Surgery Motion Control for Autonomous MIS, (2) Deep Learning in Image-based Positioning and Augmented Reality Guidance for Autonomous Minimally Invaded Surgery, (3) Surgery Planning and Monitoring System for Autonomous MIS. Project-1 will focus on the development of the robotic autonomous surgery motion and its control systems. Project-2 will integrate Deep Learning with the endoscope images for object positioning, including instruments, tumors, and main blood vessels. The positioning system will work with Project-1 for robot motion control and also work with Project-3 for surgery monitoring. Moreover, the positioning system will also used for surgery guidance in an augmented reality system. Project-3 focuses on the surgery planning and monitoring. Surgery procedural information will be formulated with the knowledge from clinic surgeons and transformed into reference trajectories and motions for robots. The robot motions will be simulated and verified. Monitoring system will also be designed to provide warnings if the surgery motion is deviated from the pre-planned surgery motions.
The autonomous MIS system has the benefits of expanding the surgery capacity, lowering the surgeon load, and increasing the surgery efficiency to provide better medical service to the communities, especially for areas with insufficient medical resources. For the past two decades, artificial intelligence, especially in the fields of deep learning, has advanced significantly and is very likely to be able to learn the surgery skills to make the autonomous surgery system a viable solution."
"Deep learning, deep neural network, fMRI, MEG, EEG","Stimulated by visual and auditory sensory, neural network activity is activated to recognize the sensory information and thus form the perception of the stimulus.  By measuring the electromagnetic or BOLD signals of brain responses followed by signal analysis for the localization and interpretation of brain activity, researchers are able to investigate the mechanism of brain functions.  On the other hand, an emerging research field aims to reconstruct visual and auditory stimuli from the signals of brain responses through inverse estimation.  In this three-year project, we plan to apply our techniques and experiences in the decoding of brain signals and in the research of visual stimulus reconstruction to develop technologies for accurate image and audio reconstruction from the signals of brain responses to visual and auditory stimuli.  Three major goals of this project are: 1) development of generative deep neural network model for the reconstruction of face image stimuli from the fMRI data of visual responses; 2) development of generative deep neural network model for the reconstruction of rhythmic sound from the MEG data of auditory responses; 3) design of music auditory paradigm, conduction of EEG experiments for music auditory stimuli, and the development of generative deep neural network model for the reconstruction of music sound from the EEG data of auditory responses.  This interdisciplinary project contains the technology development of deep learning and brain science research on visual system. Researchers and students participated in this project will be cultivated with the caliber of both the development of deep neural network architecture and the application of deep neural network on biomedical engineering and research."
"Deep Learning, Analysis-Ready, Time-Series, Satellite Image, Spatiotemporal Fusion, Formosat-2","This project develops spectral-spatio-temporal fusion technique by the integration of physical Spatial and Temporal Adaptive Reflectance Fusion Model (STARFM) and deep learning Convolutional Neural Network (CNN). The objective is to generate Analysis-Ready Time-Series (ART) fused imagery from multi-sensor images. The contribution is to utilize the deep learning technology in Earth observation satellite image processing. The major work in the first year is the Spatio-Temporal Fusion using 30m Landsat-8 (LS-8) and 8m Formosat-2 (FS-2) images. The core technology is the integration of physical STARFM and CNN. The second-year focus on Spectral-Spatio-Temporal Fusion, which fuses the 8bands LS-8 and 8bands FS-2 for 8bands Synthetized FS-2 imagery. The third-year develop the feature-spatio-temporal fusion algorithm and performs time-series analysis."
"Predictive Maintenance, Industry 4.0, Government Open Data, Machine Learning, Deep Learning, Big Data Analytics","Due to the change of global industrial structure, the digital transformation in industry is imperative. The Ministry of Science and Technology (MOST) has promoted multiple projects, and aims to promote the speed of industrial upgrading through the innovative thinking and research capability of the academics, and thus respond to the direction of global industry. However, the inability to grasp the status of the relevant equipment in time is undoubtedly an obstacle for Taiwan developing Industry 4.0. Therefore, this three-year project proposal aims to ""apply machine learning, deep learning and big data analytics technology to construct equipment degradation prediction model and real-time integrated monitoring system"". In this project, we will integrate real equipment data from the industry and databases across different departments, including the government information open platform, the ""observation database"" of the Central Meteorological Bureau of the Ministry of Communications. We will construct equipment / environment / climate heterogeneous big data analytics platform based on 120 Nodes of IBM cluster servers in the YZU Big data and digital convergence innovation center. We will apply machine learning, deep learning and big data analytics technology to integrated data, combined with the industry's experts for in-depth analysis. In addition to the immediate diagnosis of equipment status, more important is to predict equipment and component degradation to prevent failures, reduce operation costs, improve efficiency and uptime, and reach the vision of an intelligent maintenance. Besides providing innovative academic insights on equipment intelligent maintenance, this study will also introduce methodology into industry. Apart from maintaining electronic equipment intelligently, it will further develop the intelligent dispatching of maintenance personnel and machine equipment. We expect to contribute in Taiwan industry’s digital transformation and Industry 4.0 development."
"ischemic stroke,noncontrast-enhanced CT,MRI,computer-aided diagnosis,deep learning","Cerebrovascular disease is one of the main cause of death and disability around the world. According to
statistical data released by Ministry of Health and Welfare, cerebral vascular accident is the third leading causes of death (after cancer and heart disease) in Taiwan. The population is also getting younger and younger. That brings the society the burden of health care and bring to patients serious trouble of life quality. How to prevent the occurrence of stroke has become an important issue. The types of stroke can be divided into hemorrhagic and ischemic. Ischemic stroke is by far the most common kind of stroke in Taiwan. It occurs when an artery to the brain is blocked, leads to the brain being starved of oxygen. Moreover, the goal of current treatment consensus in the initial phase of ischemic stroke is to restore blood perfusion of brain tissues. Therefore, rapid imaging diagnosis leads to right diagnosis and treatment. The use of noncontrast-enhanced computed tomography (NCCT) for stroke evaluation has progressively increased, since magnetic resonance imaging is less widely available than CT. It is, however, well-known that NCCT has a relatively low sensitivity, especially, within the limited time window for thrombolytic treatment (about 50% accuracy for hyperacute ischemic stroke). To strengthen the use of NCCT, the inter-operator variabilities should be further reduced. Image processing based and deep learning based computer-aided diagnosis (CAD) system were proposed in this project to improve the examination quality. The advantages of CAD systems are quantitative, efficiency, and consistent. Thus, this project will firstly establish an automated CAD system for the NCCT lesion in patients with ischemic stroke, secondly using MRI to evaluate the severity level, and combine both NCCT, MRI with clinical data, bio-signal and physical examination data for the prognosis model in the third year."
"Travel Recommendation, Social Media, Data Mining, Sentiment Analysis, Artificial Intelligence, Deep Learning.","A three-year project that explores how to integrate social media data mining and deep learning for improving the travel recommendation system is proposed. The first year of the project will collect the photos posted by the user on the social media. Based on the GPS coordinates of photos, the Mean-Shift algorithm will be applied to group and dynamically generate the landmarks visited by the users. The Latent Dirichlet Allocation (LDA) model is then applied to generate appropriate travel topics from all landmarks. Finally, based on the topics selected by the user, a deep learning MultiLayer Perceptron (MLP) model is built to predict the missing scores of the user-landmark preference matrix for travel landmark recommendation. In the second year of the project, we will take environmental information such as temperature, humidity, rainfall, and visiting time into consideration when building the landmark recommendation model. In order to solve the cold-start problem of new landmarks, we will use the web crawler to capture the text description information of each landmark, and combine the text mining and Denoising Autoencoder (DAE) to learn the important features of the texts. Based on the above process, the scores of the cold-start landmarks is estimated. In addition, the Long Short-Term Memory (LSTM) will be applied to construct a travel sequence generator for landmarks, so that the travel suggestion is no longer just a single (or several) landmark, but a sequence of landmarks with an appropriate visiting order. In the third year project, the first focus will be on solving the problem of inconsistent rating scores and text comments on the social media commentary platform. To this end, we will establish a sentiment classifier based on Word Embedding and LSTM to convert text comments into explicit scores. Then, the classifier will be used to determine whether the text comments are suitable or not. The second focus of the third year project will be on revising the deep learning methods proposed in the first and second years, and attempts to improve and compare with different deep learning models (such as SDAE, CNN, etc.) to increase the recommendation accuracy. We believe that the proposed three year project can make up for the shortcomings of the recommended system research in tourism-related businesses and fulfill the needs of personalized services."
"Beyond5G (B5G), Interference Avoidance, D2D (Device to Device Communication), Deep Learning, Millimeter Wave, Massive MIMO, Spectrum Splitting, Beam Forming, Beam Tracking, Power Control","In the 5G, how to avoid interference when deploying 5G networks and how to deploy BSs according to data amount will be our first research focus. For 5G networks, fog computing may generate huge amounts of data from D2D (Device to Device) communications and how to avoid the interference generated by local wireless terminals would be our second concern. 5G network uses high-frequency millimeter waves to increase the number of users but millimeter waves are directional and easily interfered. How to improve and adjust BSs to avoid interference and enhance the overall throughput would be our final consideration. This project proposes an interference avoidance and management mechanism based on deep learning and attempts to find the optimal solution, reduce interference, and increase the overall utilization rate. The research focuses in this three-year project are described below:
Research 1: For interference avoidance, BS deployment will be based on deep learning algorithms. Basic parameters include the number and locations of BSs, signal intensity, attenuation rate, coverage and penetration rate. Considerations are also given to topography, roads, building distribution, possible number and intensities of users, and the estimated throughput in each region. According to the computation result, macrocell BSs, microcell BSs, picocell BSs and femtocell BSs are vertically deployed. Generally, macrocell BSs together with microcell BSs reach the highest coverage rate. More picocell BSs and femtocell BSs will be deployed according the estimated throughput in the region. Through deep learning training, our proposed model can be capable of BS deployment and the deployment results can be verified according to the interference and requested throughput.
Research 2: Fog computing is adopted in 5G to solve the problem of centralized computing. However, huge amounts of data from D2D (Device to Device) communications may cause interference. To avoid and reduce interference, this research proposes to make use of spectrum splitting and power control: integrating Massive MIMO with spectrum splitting technique to train a power control model on a deep learning basis. According to the communications, signal intensity, services, and load between D2D devices, the power of the antennas can reach user requirements, prevent waste of power and reduce interference. The purpose of the research is to find the optimal parameter adjustment that maintains the maximal system load as well as the best quality of service. 
Research 3: Millimeter waves are used in 5G networks to increase usable frequency bands. In the research, we use beam forming and beam tracking to solve the problems of millimeter waves. When millimeter waves cannot penetrate obstacles, our proposed scheme will switch BSs so that users can connect with other BSs in the region. Without changing the connections of other signals, the proposed scheme, by deep learning, can learn to reduce the impact of obstacles by effects of refraction and reflection, and take obstacles, beam forming and so on as the condition parameters. When the signal intensity is poor, BSs, based on our scheme, will learn how to adjust beam forming and beam tracking to enhance signal intensity and quality of service."
"artificial intelligence,hearing aids,noise reduction,deep learning,mobilenet","According to the MOHW’s statistics, there were more than 120,000 people suffering from hearing impairment in Taiwan in 2016, of which 75% were over 60 years old. With the advent of an aged society, the number of people with hearing impairment has increased year over year. However, the research indicates that hearing-impaired patients are reluctant to use medical devices and they start wearing hearing aids in the 8th year of hearing loss. “Hearing-impaired patients may refuse to wear hearing aids because of the pesky problem of background noise. In addition, wearing hearing aids may feel weird because hearing aids are bad-looking”, audiologist Moru Lien said.
However, with the ever-changing nature of technology, the appearance of hearing aids has been greatly improved and become smaller. Analog hearing aids that only amplify sounds have evolved into digital hearing ones with high-quality noise reduction. In traditional analog hearing aids, the developers of hearing aids can only reduce noise by adjusting feedback signals or filters of analog components, on the contrary digital hearing aids can be adjusted with a computer. Recently, artificial intelligence has been widely used in acoustics. It can be used not only to distinguish the sounds of each voice but also to recognize vocabularies and grammars. The aim of this project is to use a deep neural network based on our previous researches, to distinguish noises from the input audio signal and filter them out so that users can hear clearly. This approach improves the quality of hearing aids and can be implemented in embedded system. Therefore, it may be feasible to implement our research on hearing aids in the future."
"Deep learning, convolutional neural networks, generative adversarial networks, machine learning, support vector machine, sparse representation classification, leaf images, Lauraceae, Fagaceae","Plants of families Lauraceae and Fagaceae dominate the subtropical evergreen forest in Taiwan. The derivatives of the plants provide significant economic benefits. Correctly identifying the species in the field is critical as the first step to utilize the biomaterials. Identifying the species also helps scientists and ecologists for the purposes of forest resource conservation. Leaves of plants in families Lauraceae and Fagaceae show variation in color, shape, and texture. Conventionally, the identification of the species is conducted using naked-eye inspection with leaf characteristics. However, expert training is time consuming and expensive. Moreover, within certain genus, there exists a high degree of interspecific similarity in leaf morphology. The morphological differences between the leaves are so subtle that it is challenging, even for experts, to distinguish the species. Thus, in this project, we propose to identify Lauraceae and Fagaceae species using leaf images, machine learning, and deep learning approaches. This is a 3-year project. In year one, we will focus on leaf specimen collection for species in family Fagaceae. Leaf specimens of species in family Lauraceae will also be collected if it is admissible. Leaf images will be acquired using flat-bed scanners. Subsequently, leaf traits, including color, shape, texture, and venation, will be quantified. Machine learning classifiers, such as support vector machine and sparse representation classification classifiers, will be developed to identify the species using the traits as inputs. In year two, we will focus on leaf specimen collection for species in family Lauraceae. Leaf specimens of species in family Fagaceae will also be continued. Machine learning classifiers will be developed to identify the species. In year three, leaf specimens of species in both families will be continued. Deep learners, including convolutional neural networks and generative adversarial networks, will be developed to discriminate the species. Deconvolutional networks will be applied to visualize the learned leaf features that are significant for species identification. We have collected some leaf images of the target species. Preliminary results showed that the proposed methods could reached reasonable accuracies. By conducting this project, we expect to cultivate experts in machine learning and deep learning. The experts will subsequently propagate the learned knowledge to the society and industry, eventually increasing the compatibility of Taiwan. We also expect to develop a computer-aided tool for identifying plants in families Lauraceae and Fagaceae. The tool can assist the forest explorers in plant identification. It also can provide information to the general public when they visit the nature."
"deep neural network, accelerator, 3D IC, 3D memory","In recent years, data analysis is often realized by deep neural network. To reduce the error rate, the number of the layers is increased in the deep neural network. This trend also increases the number of the parameters, the requirement of the computation, and the complexity of the interconnection. To solve these problems, many researches proposed the parallel-processing accelerators, high-bandwidth memories, and high-throughput interconnections to realize the low-latency and low-error deep learning architectures. The error rate and recognition time are different for different deep learning applications. Low-latency and low-error deep learning architectures are not suitable for all of the deep learning applications. Although low-latency and low-error deep learning architectures can reduce the latency, the computation of the parallel architecture may cause drastic changes of the power consumption. This situation may result in the increases of the temperature and the occurrences of the overheating. According to the problems mentioned above, we will propose a three dimensional reconfigurable deep-learning memory and accelerator design (3D RDLMA) in this project. The deep learning accelerator, 3D memory, and reconfigurable interconnection in 3D RDLMA are integrated to form the 3D-IC architecture. By considering the power density and temperature variation, 3D RDLMA dynamically change the architecture and function of the accelerator, 3D memory, and interconnection. The goal is to maintain the reasonable computation time and error rate of the deep neural network under the predefined thermal constraints. In this project, we focus on the following topics: 1) 3D RDLMA thermal-power-latency co-simulation tool 2) deep learning accelerator design, 3) reconfigurable interconnection circuit design, 4) architecture exploration of the 3D RDLMA, 5) thermal management design of 3D RDLMA, and 6) mapping design for 3D RDLMA."
"Deep Learning, DNA Variant Analysis, Parallel Computing, Distributed Computing, High-Performance Computing, Computing Clusters, Performance Analysis, Hardware Acceleration, heterogeneous Computing, GPGPU","Deep learning have emerged as an important technique for data analytics and artificial intelligence, while many scientists and engineers depend on high-performance computing (HPC) facilities to accelerate their research and development projects by analyzing large data sets with large computing clusters, latest hardware accelerators and complex deep learning models. In our previous research works, we have studied how to support high-performance distributed training for deep learning models by developing open source performance monitoring and analysis tools to pave the road for performance optimization. With our methods and tools, we have helped the National Center for High-performance Computing (NCHC) and companies in constructing high-performance deep learning training systems and services. In this research proposal, we would like to advance our research results by aggressively pursuing domain-specific whole system performance analysis and optimization with events and features taken from the systems and applications. We aim to support the concept of HPC-as-a-Service (HPaaS) by taking many hardware and software events and features into account dynamically during the execution and developing a mechanism to automatically optimize the system configurations, the update methods of neural network parameters, compiler optimization options, and other software tunables.  In addition to our continual collaboration with our industry partners on the latest deep learning system hardware and software, we will tackle the challenges in a practical application as a case study: building a high-performance deep learning system and service to accelerate variant calling in the next generation  sequencing (NGS) technologies for genome research. We would like to thoroughly analyze the performance issues in this system and application using the performance tools developed in this project, which not only validates our methodologies and tools, but also elevates the research environment for genome sequencing,  genome research, and possibly paves the road for precision medicine."
"Defect detection, deep learning, production line optimization","With the trend towards Industry 4.0, intelligent factory is already a major developing trend in manufacturing today, and machine vision technology plays an important role in this era. This project will apply deep learning to steel production process to explore the feasible methods of surface defect detection and to design various feasible deep learning models. We expect that our designed model can be applied to other areas of defect detection applications. The project is planned to be a three-year project. In the first year, we will focus on the detection of defects. Through semantic segmentation technology, we will detect possible defects, positions and sizes of defects, and types of defects. Upon the first year of in-depth understanding of flaw characteristics, in the second year, due to the demand for real-time inspection, we are committed to improving accuracy and speed so that defect detection can achieve real-time requirements. In the third year, we will develop production line optimization techniques, which are related to the entire steel production process, including temperature, pressure, additives, defect types, and so on. These parameters will help find out why defects happen, and then provide these clues to the relevant personnel to adjust the production line related parameters. We expect that these results can prevent the occurrence of defects or avoid the recurrence of defects. We have now conducted a detailed literature review of defect detection and put forward preliminary results to support the feasibility of the study."
"Chinese fonts, style transfer, deep learning","The goal of this project is to automatically generate Chinese fonts that satisfy the personal writing style of the user by deep learning techniques, and to develop a font generating service system prototype. The design of a Chinese font is fundamentally different from the font design of most other major languages in that the Chinese characters are structurally complex and there are a vast number of Chinese characters. Therefore, the design cost of a Chinese font is expensive. However, most existing researches on font generation restrict to western fonts, methods that are suitable for Chinese fonts remain very rare. This project expects to design and implement related methods and systems in two years. In the first year our focus will be on the method that learns and transfers a font style. The proposed method will be evaluated both on printed fonts and written characters. In order to relieve the burden of a user in providing sufficient written characters when generating personally styled fonts, this project will also study the selection of the sample character set so that a complete font set may be produced from a relatively few character samples. On the other hand, existing researches focus only on the generation of a single Chinese character but not character strings. Therefore, in the second year this project will study the learning of the personal writing style of the character spacing and the character size to generate natural-looking texts. We will also integrate the research results of this project into a prototype system that provides personally styled fonts to users."
"Artificial Intelligence,Intelligent transport system,Deep Learning,Generative Adversarial Network, GAN,Traffic trajectory and event data generator","This project is in accordance with the policy of Executive Yuan which is fully connected to the conclusion of SRB meeting. In this project, we fully develop niche intelligent transport application for Taiwan. Based on the special mixed traffic environment in Taiwan, the differentiated applications we develop will promote the industrial developments and boost the export to international markets, such as Asia Pacific markets.
In this project, we establish an AI-based crash avoidance system in mixed traffic flow environment which is adaptive to Asia Pacific environment. The first set of the road side mixed traffic flow database for deep learning system in Asia, a Road Safety System, and a Transport OS will be constructed. Hence, we can develop domestic solutions and construct the road safety industry chain, and lead the growth of AI-based road safety service in Taiwan.
The result of this project is expected to support telematics and road safety software companies in Taiwan. We will cooperate with these companies to create a public partnership platform and develop innovative TOS intelligent systems. Furthermore, we will verify test fields with ICT companies in local areas with innovative application services; and then we can promote the sales of road side equipment up a million sets to globally per year."
"multi-omics,pan-cancer,deep learning,autoencoder","Tumorigenesis is a complicated process that involves in various genetic disturbances from different omics layers. With the advance of next-generation sequencing technology, all kinds of omics data has been accumulated, which provides opportunities to get multi-faceted insights to the complex nature of cancer by integrating data from all omics layers and studying the interrelation among them. The goal of this study is to address this issue by constructing artificial intelligence algorithms that depict molecular landscape of cancer with multi-omics and pan-cancer data. Since multi-omics data are high-dimensional and exhibit high dependency, we aim to establish an effective model for comprehensively investigating the association between and among genomic layers. We will devise a multi-omics network of pan-cancer utilizing both LASSO and deep learning methods. TCGA data will be used as training and validation dataset. Furthermore, genomic profiles from CRISPR knockout cancer cell lines will also be applied to our model to identify cancer dependency genes for cancer diagnosis and treatment."
"feature selection,deep learning algorithm,predictive demand mode","The inventory management system of medical devices is very complicated and special. The main reason is that medical devices contain various types of specifications or sizes. Taking cardiovascular devices as an example, the same product have hundreds of different specifications or sizes, depend on the treatment needs of different patients. In order to not allow any errors to occur, all specifications must be stocked, resulting in a huge burden on inventory costs. This study uses deep learning algorithm to learn the different conditions and medical diagnosis of patients who have used cardiovascular devices in the past. The predictive demand model of cardiovascular devices, and then the optimization of the inventory management system. Based on feature selection and deep learning algorithm, this study proposes a “the predictive demand model of cardiovascular devices”. In this study, Pearson correlation coefficient (PPMCC), information gain and gain ratio are used to screen out important medical feature attributes. Furthermore, through back propagation neural network (BPNN), decision tree (DT), support vector machine (SVM) and deep neural network (DNN), the prediction accuracy analysis is performed for important attributes. Finally, the prediction performance of the category data is evaluated by the binary classification confusion matrix. The expected benefit of this study is to establish a &quot; the predictive demand model of cardiovascular devices &quot;; to enable hospital and supplier members to accurately grasp the demand prediction for cardiovascular devices, to plan an optimized inventory management system, and to avoid shortage of stocks to waste the physicians and patient's waiting time."
"asthma,allergic diseases,air pollutant,machine learning,deep learning,black-box","Allergic diseases, including asthma, allergic rhinitis and atopic dermatitis, is one of major global health threats. It is estimated that asthma affected approximately 358.2 million individuals worldwide in 2015, and our previous study also found that nearly 40% of children (&lt;6 year-old) had one of the aformentioned allergic diseases.  Air pollution is also an increasing threat to the global burden of disease, and nearly 7 million people died from air pollutant every year.  A number of studies have shown the correlation between air pollutant and exacerbation of allergic diseases, particularly asthma.  However, most of the studies were cross-sectional studies, and the cohort study with long-term follow-up is still lacking.  Notably, most of the studies simplified the complex and dynamic exposure of air pollutant into one averaged exposure level; therefore, the exact impact of air pollutant on exacerbation in asthmatics remains elusive.  It is hence essential to identify the representative air pollutant indicators, which have a clinical impact on exacerbation in patients with allergic diseases. Taichung Veterans General Hospital (TCVGH) has established Clinical Information and Research Center (CIRC), which acts to integrate electronic medical record (EMR) at TCVGH. Therefore, we are able to integrated air pollutant databases with EMR at TCVGH to establishe a comprehensive cohort of allergic diseases with long-term health and air pollutant data. The remarkable advances in machine learning and deep learning models in recent years have enabled us to use multi-dimensional variables in the development of a disease-specific outcome prediction system, which has the potential to be incorporated into a healthcare information system as an automated decision support system.  However, the black-box issue remains the main obstacle for the practical application of deep/machine learning in medical fields.  This integrated program aims to establish the allergic disease cohort through integrating EMR at TCVGH and air pollutant databases and to employ deep/machine learning models in predicting exacerbation of patients with allergic diseases.  Additionally, we will build an interactive interface which allows physicians for immediate response by kicking the crucial variables.  We believe that such an interpretable model and interactive interface through maximizing the value of multi-dimensional clinical and air pollutant databases in central Taiwan should have high practical value."
"chronic kidney disease,renal pathology,deep learning,computer vision","Chronic kidney disease (CKD) is a prevalent disease in Taiwan. Early and definite diagnosis is detrimental for early treatment and prevention of end-stage renal disease (ESRD). In clinical practice, the clinicians may suggest patients with overt symptoms to receive renal biopsy to identify the underlying diagnosis. However, the interpretation of renal pathology is time-consuming for the renal pathologist to make the pathological diagnosis. Currently, clinician can obtain the pathological report at least 1 to 2 weeks after the renal biopsy. It is possible to facilitate the efficacy, quality and accuracy of pathological diagnosis if there are useful assistive tools to help pathologist in the process of image interpretation. In this years, computer can have competent performance with human in many areas, such as computer vision, nature language processing and voice recognition due to the rapid development of deep learning. It would be a good news for CKD patients if we can use these advanced technologies to assist the interpretation of renal pathology. In this study, we aim to develop a classification model that can identify various pathological characteristics of glomerulus (such as glomerulosclerosis, proliferation…) The automatic detection system can help the clinician figure out the specimen quality in seconds and accelerate the process of pathological interpretation, and this may improve the quality and efficiency of pathology diagnosis in the future."
"Lung cancer,computed tomography,deep learning,convolutional neural networks","Lung cancer has been the leading cause of cancer death with the highest morbidity and mortality in Taiwan. However, early detection and diagnosis of pulmonary nodules by low-dose computer tomography (CT) images screening examination had been demonstrated the improvement of survival in lung cancer patients. In the past decades, a number of computer-aided detection and diagnosis (CAD) systems had been proposed to assist the radiologist in detecting pulmonary nodules when reading chest CT images. Recently, artificial intelligence have been extensively used in computerized pulmonary nodule analysis. Unlike conventional CAD systems, deep learning techniques with conventional neural networks provide the basic advantage of an automatic exploitation feature as they have the ability to learn image representations. In this study, we will develop a fully automatic and efficiently CAD system based on conventional neural networks and deep learning techniques to identify and localize the suspecting malignant pulmonary nodules. The system of this project is designed and expected to improve accuracy in diagnosis, assist in early detection of cancer and reduce the exam evaluation time when chest CT imaging reading. Moreover, this system will be also helpful in communication with patient and health caregivers."
"Pediatric heart and breathing sounds,smart medical device,deep learning network,artificial intelligent.","In the previous project, we developed a new method that can assist in the diagnosis of lung lesions and treatments, as well as being easy to carry and without CT diagnosis. In this year, we extend the technology to pediatric heart sound analysis, because the diagnosis of pediatric heart disease is more challenging than adults. Ultrasound is the most commonly used tool for diagnosing pediatric heart disease, but it is more expensive and less portable. Although auscultation can diagnose pediatric heart disease by abnormal heart sounds, it is cheaper, more mobile, non-radioactive, non-lodging, but relies on expert skills and experience, and each expert has different diagnostic accuracy. The use of auscultation sound information as a deep learning model to diagnose abnormal adult heart sounds proven to be an effective method after the use of electronic stethoscopes for clinical purpose. However, the diagnosis of pediatric heart disease remains to be studied and developed. This project proposes a one-year plan to establish a deep intensive learning network model for the study of the pediatric cardiopulmonary medical (PCM) sound diagnostic system. We are using artificial intelligence technology to let the computer learning the heart and lung sound signals of children. The result estimated by computerized tomography is combined with the doctor's treatment strategy so that the most useful information from the model is provided to the physician as an essential basis for diagnosis and treatment. The improvement of data collection is proposed to cooperate with multiple sets of dynamic filters to analyze the significant PCM sound effectively. We expect this project can develop a portable, real-time method as a useful tool to assist screening for diagnosis of pediatric heart disease."
"Work-related Musculoskeletal Disorders,Deep Learning,Occupational Medicine;","The  injury  resulted  from  the  repetitive  and  load-bearing  works  is  the  most  frequent work-related musculoskeletal disorders (WMSD) or cumulative trauma disorders (CTD). It comes  from  the  overload  of  repetitive  load-bearing  acts,  which  resulting  in  fatigue, inflammation, even injury of musculoskeletal system. According to the annular report of Labor Insurance Bureau, WMSD is up to 85~88% payment. Thus, the aim of the study is to evaluate the risk of WMSD during work by using the simple, quick, and correct methods by using the deep learning algorithms. In the proposed research method, After collection the videos of hand repeated movements, the ergonomic hazards are evaluated by using the 2D Human Pose Estimation method, which is based on the Key Indicator Method - Lifting, Holding, Carrying (KIM-LHC). The previous collaboration focused on the classification of hazard risk levels for hand-hitting actions in the Key Indicator Methods – Manual Handling Operating Tasks (KIM-MHO). The current research results are compared with the accuracy of the doctor's judgment classification of more than 80% (Accuracy). This project will continue the   research   results   of   previous   collaborations,   and   build   a   model   of   pre-defined classifications through deep learning algorithms for Lifting, Holding, and Carrying operations in the KIM-LHC scale. The research goal is set to the accuracy of the proposed method to more than 90% compared with experts and scholars, in order to achieve fast and accurate assistance to determine the risk of Ergonomics, and can immediately improve feedback"
"deep learning,fundoscopy,diabetes","Title: Detection of coronary artery disease from retinal fundus photographs via deep learning (1)Objective： To build deep learning model to predict cardiovascular disease with retinal fundus images. (2)Background and method:： Cardiovascular disease is the leading cause of death among patients with diabetes. The prevalence of cardiovascular disease is increasing despite our best efforts to control relevant risk factors. Early detection and thus prevention are important step for further bring down the cardiovascular risk. According the previous literature, diabetic retinopathy is a predictor for cardiovascular disease and all-cause mortality. The vascular structure, an caliber of blood supply to retina are reported highly related to cardiovascular burden. With the rapid progression and evolution al change in deep learning technique, deep learning model trained by fundus image labeled by expertise, can detect diabetic retinopathy in high accuracy. In the research, we aim to build deep learning model with retinal fundus image from our diabetic outpatient department to predict cardiovascular disease. Inclusion ： Fundus image: 10,0000, (80% as training set, 10% as validation set, 10% as test set) Inclusion criteria : 1.Patients with diagnosis of type 2 diabetes。 2.Patients with available coronary angiography reports. Exclusion criteria: 1.Fundus image reported as bad quality by VeriSee. (3)Method: We will collect retinal fundus images from our outpatient departments from 2008-2018 and assess the image quality by VeriSee, which is a deep-learning based software developed to auto-detect diabetic retinopathy or patients with diabetes, with reported accuracy around 90%. We will extract patients ever received coronary angiography in our hospital and labeled with coronary artery disease and without coronary artery disease accordingly. We will use convolution neural network and attention map technique to identify patient with coronary artery disease and further extract features related to the diagnosis."
"Face Alignment, 3D Face Reconstruction, Face Recognition, Deep Learning","In recent years due to the rapid development of deep learning, the accuracy of face recognition has greatly improved, and therefore face recognition has been applied to many everyday situations such as e-gate enrollment systems, access control, or financial identity recognition. For near frontal face images, face recognition methods based on deep learning can reach or surpass human-level performance. However, for face images with large pose variations, there is still a lot of room for improvement. Most face databases for deep learning are 2D images, and most recognition methods do not utilize the 3D information of faces. If the pose variation of a head is large, there will be a significant drop in the recognition performance.This project consists of three stages. The first stage is to develop a face alignment method, used for the preprocessing step in reconstructing 3D face models in the second stage. The second stage develops an algorithm for reconstructing 3D face model from a single 2D face image. The third stage develops deep-learning based algorithms for face recognition, utilizing both the information of 2D face images and 3D face models. The 3D face information enables the recognition model to learn how to extract face features without being influenced by pose variations of heads. The 3D face information is obtained by the algorithm developed in the second stage. Hence, the input to the face recognition system only requires a single 2D image, and there is no additional hardware required for obtaining 3D face information.We look forward to combing the information of 2D face images and 3D face models can lead to promising face recognition performance despite different pose variations of heads. In addition, the technology of reconstructing 3D face models from a single image can also be applied to augmented reality and virtual try on."
"glioma, deep learning, computer vision, digital pathology","Malignant gliomas, which make up majority of primary brain cancer, are difficult-to-treat, highly lethal tumors that result in global health threat. Due to their lethality and relevance of histological type to treatment and prognosis, histopathological diagnosis of gliomas is currently important area in oncology. Though confirmatory diagnosis of gliomas often relies on ancillary studies such as immunohistochemistry, sequencing or in situ hybridization, interpretation of H&E slides still plays a crucial role in accurate tumor classification. However, interpretation of glioma morphology, especially among some difficult-to-discriminate entities, such as between oligodendroglioma or astrocytoma, may be challenging and become source of diagnostic controversy. Therefore, after deep learning technology began to be applied in computer-aided histopathological interpretation in recent years, glioma classification on whole-slide image has become a popular subject in digital pathology. While many researchers have make process in some limited area of brain tumor histopathology, such as grading of astrocytomas, there still lack a complete digital system for glioma classification. The authors plan to build a system by deep learning on detailed annotation of histopathology slides and molecular tests, that will perform preliminary automatic classification of glioma, to facilitate diagnosis and treatment of gliomas."
"Clinical Decision Support System ,CDSS,artificial intelligence,AI,data mining,machine learning,deep learning","Due to the rapid development of information technologies, smart medicine has become an important trend of clinical practice. Clinical Decision Support System (CDSS) has been developed for several years and it can assist doctors to improve the quality and accuracy of diagnosis. However, most CDSSs exploit rule-based model for diagnosis and treatment strategies, which is not suitable for the construction of the complicated knowledge system. Hence, conventional CDSSs can not assist doctors for making a correct diagnosis efficiently. Recently, artificial intelligence has been widely used in many fields. In particular, medical artificial intelligence research has become an important trend. Therefore, in this project, we will focus on incorporating artificial intelligence techniques into the decision support system to improve the quality of medication.      In this subproject, we will construct a medical decision support system to increase the quality and efficiency of healthcare decision. This project is tailored to fit for different kinds of diseases using artificial intelligence techniques, including data mining, machine learning and deep learning methods, so as to construct an effective medical decision support model with incorporations of medication records, literatures and guidelines."
"Text Mining, Deep Learning, Cognitive Difference, Shared Decision Making, Doctor-Patient Communication","Applying information techniques to healthcare issues has become an emerging research topic recently. As patients draw attention to their health, there are more and more medical disputes might occur due to unexpected medical results, poor communication or cognitive differences between patients and healthcare professionals during the treatment. Yet, through shared decision-making model (SDM), it is hoped that mutual trust between healthcare professionals and patients can be enhanced and that medical disputes might be alleviated. Several research on shared decision-making model has been published, but few studies apply an integrated model combining cognitive theory, text mining and deep learning technologies to solve SDM issues. Therefore, this three-year project aims to propose the following three potential research topics.(1) Patients can express their disease concerns by using ordinary vocabulary to search for and retrieve similar disease treatment cases: When patients encounter the problem of disease treatment, they usually use daily vocabulary to describe the actual course of the disease. Since they may not necessary understand the medical terminology, they might have difficulties in describing their disease. Therefore, in the first year, a disease treatment case retrieval system will be designed for patients to use daily vocabulary to search for similar disease treatment cases, which provide a reference for disease problems.(2) Building a Shared Decision-Making corpus: In the communication process of disease treatment decision-making, the cognitive differences can be caused by patients' preferences and health literacy. Therefore, medical disputes might happen when the expected results are not achieved. In the second year, we will establish a shared decision-making corpus to analyze the extent of cognitive differences between patients and healthcare professionals when they jointly participate in the decision-making process. This corpus can assist them to reach a consensus in developing relevant decision-making tools.(3) Designing a disease treatment decision prediction model based on the patient's cognition and preference: In the process of disease treatment decision-making, it is difficult for patients to confirm the treatment plans due to various complex situations caused by physiological, psychological or external environment. In the third year, we will develop an ensemble prediction model of disease treatment decision. This will integrate several deep learning classifiers to support patients and healthcare professionals on disease treatment decisions."
"Big Data, Monitor water quality, recursive neural network","The main purpose of this research project is to use the image data through big data technology to monitor water quality variation. It is decided to develop a computing system that strengthens water time-history monitoring and presents water quality turbidity. The water conservation area in the catchment area has a wide range. To reinforce management, the plan is to expand and upgrade the water conservation intelligent image management platform and upgrade water quality monitoring to assist in the use and management of water supply quality. In the past, the vendor are limited to the observation and estimation of time series changes in water quality using only general linear regression models. However, the prediction model was not good. After interviews, the industry wanted to develop a neural network system that can solve the time series of water quality monitoring system. The RNN2 model was developed to predict the water quality change of Qingtan reservoir after heavy rain or soil quality change. Due to network model has a memorable recurrent neural network for analysis and prediction, the results will be compared with traditional linear regression models."
"deep learning,mesenchymal neoplasia,reagent spectrum","Mesenchymal neoplasia is rare; however, at specific site it may be quitecommon, such as in gastrointestinal tract (e.q., gastrointestinal stromal tumor, GIST). When high-risk features are present, these diseases are mainly treated by targeted therapy. However, to achieve effective treatment, mutational analysis of the target genes must be applied first, and there are usually multiple gene targets need to be tested. Current turn-around time, from receiving the pathology specimen to confirming the mutational status of the target genes, takes about 1 week to accomplish. To accelerate the test time and to reduce the waiting anxiety of the patients, in this project, we plan to incorporate artificial intelligence andnew-generation sequencing techniques in the pathological processes, trying to reduce the time needed on laboratory procedures. Among these, one of the major topics is how to enhance the reaction signals. Through synergetic physical and chemical techniques (either via reagent, by fluorescence, or spectrum distribution), a stronger and clearer signal can be obtained, compared with the current signal produced by a single reaction. Enhance the readability of the reaction signals means the increase of test sensitivity and the reduction in specimen amount that needed. The corresponding automatic analysis model based on deep learning can be established. The success of this project not only will lead into a quicker way in tumor gene testing, but also provide an opportunity in advancing future nano-techniques, which in turn benefits the whole oncologic society."
"Welding,Automation,Laser Triangulation,Deep Learning,Neural networks","In this project a research is proposed on the challenge of welding automation.  Welding qualities would be affected by the product types and the manufacture processes.  In General, a fully automated production could not be employed in the welding process.  Since most of the welding process are not easy to control because of the affected factors, e.g., weld environment and human intervene.  Therefore, in order to insure the quality of the welding process, it would be better to reprocessed instantly for the weld defects.  For those heavy pips, any welding defect found after process would cost twice or triple the general process time.In this research project, it proposed a laser-based smart vision system for the monitoring of the weld process in real time and to inspect the weld quality.  The laser vision system using the laser triangular techniques would be employed.  A structured laser line would be projected on the product under process.  An image sensor in a few inches apart with an appropriate angle would sense the laser lines in the associated pixels.  Each pixel is corresponding to a deviation to the middle, x axis value, and a height from vision system down to the product, z axis value.  The vision system could move forward or backward.  A sampling signal would be generated while the system moves every 0.1 millimeters.  A 3-D image would then be constructed.  The shape of weld pool could be analyzed to detect the weld defects.  The weld parameters, i.e., arc current, arc voltage, travel speed etc., could be employed for further study.  A deep learning algorithm are used to train a set of neural networks parameters.  The accuracy improvement of the weld defect detection should be achieved through the classifier with the recurrent neural networks structure."
"deep learning,hypoxemia,spectra,NIR,heart rate","Long-term hypoxia will lead to a sharp deterioration of body functions. Any environment that may cause changes in blood oxygen saturation concentration can be continuously monitored using blood oxygen equipment to provide life monitoring judgment. The supply of oxygen and blood is very important for the normal growth of human tissues. At present, oximeters are mostly used for bed monitoring, home care and cardiopulmonary monitoring during exercise.The research team of this laboratory has been developing equipment for infrared imaging technology and thermal radiation image analyzer for a long time. The development of deep learning blood oxygen concentration analyzer equipment can increase and establish a good industry-academia technology exchange and cooperation relationship, and develop technologies and products that meet market needs. We hope that the development of a deep learning spectroscopic blood oxygen concentration measuring instrument has two important technical issues.I. Integrated development of optical measurement and electromechanical systems for spectral measurementWe hope to develop a spectroscopic method for blood oxygen saturation concentration measurement, which is different from traditional blood oxygen saturation concentration measurement devices that can only provide data information, and it is susceptible to measurement variations caused by light sources, skin, and the environment. The technology we developed can provide continuous wavelength spectrum measurement. The blood oxygen concentration information of these skin tissues can provide important information in clinical diagnosis and become an important indicator for doctors to judge human health. This research project cooperates with Dekeyi to develop a continuous spectrum measurement blood oxygen saturation concentration analyzer with great market potential. In the development of continuous spectrum calculation and compensation background noise technology, the use of near-infrared (NIR) wavelengths It can penetrate into human tissues with a depth of about 5mm ~ 10mm, and proposes an innovative reflective blood oxygen saturation concentration measurement technology that can analyze the oxygen content of regional tissues, and through our proposed deep learning algorithms and correction methods, It has become a new measurement technology for determining blood oxygen saturation concentration and a physiological blood oxygen concentration analyzer for a biomedical diagnostic system.II. Hierarchical neural network construction and spectrum analysis algorithmAt the same time, we propose a deep spectrum learning (DSL) method to implement and construct the measurement sO2 algorithm. By training the neural network to directly correlate the spectral measurements with the corresponding independent sO2 tags, DSL avoids the parameter requirements of traditional mathematical models and develops deep learning methods similar to solving the inverse optical problem. Our preliminary research shows that DSL can be trained to make it highly reliable for a variety of changes in the experiment, which is suitable for including different equipment, variations in spectral sensitivity, speed, and other possible environmental variables. At the same time, we propose a layered neural network algorithm that can be further quantified to calculate the accurate pulse frequency, which is the measurement of heart rate."
"Image Recognition, Fingerprint on Display, Deep Learning, Fingerprint Recognition, Texture Inpainting, Optical Image Sensors","As the full screen display smartphone become the mainstream of the market, various modern techniques are proposed, such as 3D face recognition, broadside fingerprint recognition, fingerprint on display (FOD). This project proposes to develop an intelligent optical based fingerprint on display system with deep learning based texture inpainting, image quality stabilization, and recognition techniques. Each technical parts will be commercialized to support the development of biometrics that apply on mobile or end devices in industries. This project will develop four key techniques. First, we will calibrate and enhance the texture by an optical signal analysis and texture enhancement module. Second, when there are unclear partitions on fingerprint sensing images, we propose an intelligent inpainting technique to increase the clarity. Third, we will extract dominant feature points are extracted from the enroll images, which are representative enough to discriminate the differences between various users by the proposed partition-based fingerprint feature points extraction module. As a result, to recognize the personal fingerprint accurately, and improve the user experience as high as the user enroll times, we also developed a learning optimization mechanism of fingerprint recognition to gradually promote the recognition accuracy."
"deep learning, defect inspection, front opening unified pod (FOUP), neural network, Python programming language","The subject of project is the front opening unified pod (FOUP), a transfer device for silicon wafers in line. If there is any defect, all valuable wafers inside the FOUP will be severely damaged. Previously, the defect inspection was mainly conducted via experienced labors. However, it suffered from slowness and increasing cost. Popularity of lights-off factory further drives the development of alternative solutions, which are in need urgently. A promising one is the machine vision integrated with a well-developed program. To realize this objective, the project will develop programs based on deep learning. The programs will employ neural networks to build up their core model, while each model will be trained and optimized using a big database during the development process. The programs will be generated with Python program language, and graphic processing units (GPU) will be utilized to speed up the optimization. At the end, accuracy of the defect inspection program shall meet the requirement of industry.	This one-year-long project will be jointly participated by NTHU_PME and a world class supplier of manufacturing equipment, Taiwan Hirata Company. The timeline of this project divides into two phases. The first is to construct a trial model using MNIST (modified national institute of standards and technology) database. Accuracy higher than 0.8 will be realized as the milestone at this stage. A strong link between two participated groups will be constructed. The second phase is to collect and sort out tremendous FOUP images. Then, another model based on the prior success will be developed. The model will employ deep learning and experience twenty times optimization. The best performed model ensures its accuracy close to or even higher than 0.6. 	The representative outcome of this project is 1 term of technology transfer from NTHU to Taiwan Hirata Co. The transfer includes two models, programs, user manuals, and other technical supports. Other outcomes are 2 trained MS graduate students, 1 national conference paper, 1 international conference paper, and 1 technology report. Besides the direct benefits received by NTHU and Taiwan Hirata Co., the success of this project will help self-independence of manufacture industry in Taiwan. Technology level will be raised by converting R&D capacities in top universities to industries. A representative example will be set up through the execution of this project."
"deep learning, long-term bedridden, pressure ulcer, AI Smart Camera",The “AI Smart Camera: developing deep learning prediction model on pressure ulcer changes in long-term bedridden patients” study aims to use artificial intelligence to build an algorism for pressure ulcer detection. We combine daily videos of patients’ activity and medical records to build models to detect individual needs to prevent infection risks and reduce causes of complications. The pressure ulcer detection model will allow us to balance patients’ welfare and medical resources to maximize the benefits of the medication.
"Autonomous Vehicle, Connected Vehicle, Radio Localization, Channel State Information, Deep Learning, Support Vector Machine, Long Short-Term Memory, Deep Convolutional Generative Adversarial Network, Sensor Fusion.","Localization is one of the key technology for the operations of connected and autonomous vehicles. Due to the limited visibility of satellites in urban areas, the performance of satellite-based localization can be severely degraded. This project will focus on the study of high precision localization based on deep learning approaches for connected and autonomous vehicles. This is a two-year project. In the first year, it will study the localization based on the received signal strength in a large scale heterogeneous network, involving short-range WLAN access points and long-range 4G LTE base stations. This project will conduct signal measurements on the waypoints along the driving routes. A SVM and LSTM hybrid deep learning algorithm will be used to model the localization network. The localization error is set to be lower than 1 meter. Furthermore, in the second year, this project will pursue performance enhancement by incorporating OFDM channel state information. To measure the OFDM channel information, it will first implement an OFDM transceiver using the software-defined radio. Besides measuring the OFDM signal on the waypoints, this project will use a deep convolutional generative adversarial network to generate more OFDM signals to reduce labor costs. Both the measured and generated signals will be used to estimate vehicle location based on the SVM and LSTM hybrid model. Then, the extended Kalman filter will be used to fuses all the sensing data, including the estimated location information, HD map, IMU information, steering angle, and odometer information, to precisely predict the vehicle location. The location error is set to be lower than 50cm to fulfill the requirement for autonomous vehicles."
"Aggregate payment,Mobile payment, Deep learning, Recommendation system","There is a need for system integration in the retail market consumer market. For merchants, what is needed is a convenient and simple payment platform, and what consumers want is a convenient and smart payment method. This plan will develop the ""Fourth Party Aggregation Payment Platform System APP"" for electronic payment and third-party mobile payment system integration and API linking to provide merchants with a one-stop mobile payment solution and application method and QR code barcode. Collection and payment operations, which can start other payment channels after scanning, replacing the current inconvenient collection and payment mechanism of multiple barcodes. The plan also uses the iOS NFC API serial connection technology to develop QR code barcodes natively to launch the Apple Pay NFC transaction mechanism. Cooperative merchants do not need to purchase or rent additional NFC transaction sensor machines, which solves the ""multi-QR code barcodes, multi-machines"" in retail retailers. ""Pay for mobile payments with multiple lease fees.""In the consumer market, consumers mostly adopt the most favorable consumption mode, which can also be called ""little luck"". Another R & D focus of this plan is to combine the development and application of deep neural network technology (DNN) to build a consumer payment recommendation system, and use deep learning algorithms to mine and explore related bonuses implemented by different mobile payment platforms and different credit cards Credit feedback, focus and integration to provide consumers with the best payment advice, to meet consumers' ""better buy, more cost-effective bonus points, small rewards"", improve the overall app stickiness, and ensure the promotion and application of the platform APP .The main functions of the platform developed by this plan are: (1) Integrate multiple third-party payment payment channels and perform API linking, and provide merchant's exclusive QR code barcode for collection and payment; (2) Combine with deep neural network The development and application of technology (DNN), the establishment of a consumer payment recommendation system, the integration of bonuses and reward points from multiple different platforms and credit cards, to provide consumers with the best advice on payment options, meet the small fortunate, and increase consumer stickiness; (3) Establish a merchant's exclusive payment and payment APP platform system and report system to provide merchant consumption data and transaction analysis reports, and then assist merchants in developing marketing strategies."
"atmosphere precipitation products, regional drainage hydraulic model, surface two-dimensional inundation model, deep learning algorithm","Taiwan is located in the Pacific Rim, and is deeply influenced by the interaction between ocean and atmosphere. Whenever a typhoon strikes with torrential rainfall, it tends to bring exceeding amount and high intensity precipitation in a very short period of time, which often causes many complex flood disasters in Taiwan. The river, the regional drainage systems, urban rainwater sewers systems are all built with different standards of flood control facilities in the basin. Their respective design of rainfall intensity and duration are also different, which results in complex flood management issues. The goal of this triennium project is to use different atmosphere precipitation products and precipitation rainfall data of many ensemble members, input regional drainage hydraulic model and surface two-dimensional inundation model to perform drainage system water level simulation and inundation simulation with different geographical characteristics. Analyze the impact of different meteorological rainfall data on the results of surface hydraulic simulation and the correlation and applicability of drainage characteristics in different areas, and evaluate artificial intelligence or deep learning algorithms combined with meteorological forecast data to develop water level and flood forecasting technology. In the first year of the project, the Danshuei River Basin in northern Taiwan was the study area to establish surface runoff, regional drainage systems and surface inundation models. Execute the concatenation of various hydraulic modes and the verification of parameters. It also evaluates how the grid-type meteorological rainfall data is downscaled and input into the surface hydrological model. In the second year, the simulation results of different types of meteorological rainfall data input to the surface inundation model were analyzed to explore the relationship and applicability of different meteorological rainfall data in different regions. In the third year, artificial intelligence or deep learning algorithms were combined with meteorological rainfall forecast data to develop water level and flood forecasting technology for drainage systems to assess the feasibility of flood prevention and early warning in the future."
"Image de-noising, Deep learning, Pseudo-unsupervised learning, Particle swarm optimization.","Artificial intelligence had been defined as the focal point of national scientific and technological in the coming decade. However, while reviewing the development history of AI, the major reason of success or failure is whether it can prove that the application of AI is significantly more effective than traditional methods when dealing with practical problems. Since the remarkable success of deep learning in face recognition, many scholars have invested in the research of image enhancement with deep learning in recent years. However, most of them focus on processing Gaussian noise and it can't actually show the effectiveness of deep learning. By using the high discriminative ability of deep learning to very high random impulse noise that most needs this feature, the purpose of this research is to develop a high-performance image enhancement algorithm that fully demonstrates the practical value of AI. To cope with the difficulty of detecting very high random noise, we propose an efficient adaptive detector that combining the convolutional neural network (CNN) with particle swarm optimization (PSO). It leverages the powerful ability of deep CNN architecture to separate noise from the noisy image. Moreover, as the original unpolluted image is impossible or difficult to obtain in practice, this study is different from other works to development a novel pseudo unsupervised learning methods by using the no-reference quality index Q measure as the fitness function. This indicator is not only used to roughly estimate the noise rate of the image, but also to develop an appropriate denoising method for different images and different noise rates. This indeed achieves a better compromise between performance and efficiency. Finally, PSO is used to optimize the overall design parameters and thresholds to truly achieve a smart online and fully adaptive architecture. In order to test the robustness of the proposed method for solving high-density noise, the research will effectively prove the practical value of artificial intelligence through a large number of natural images and multiple indexes."
"3D Point Cloud Map, Autonomous Vehicle, Deep Learning, DIBR, LiDAR, HEOPC","This proposal presents “System and Chip Design of Autonomous Vehicle Virtual View and 3D Point Cloud Map Fusion Technology for Real Time Object Detection Based on Deep Learning.” We use the depth information of Depth Image Based Rendering (DIBR) technology to perform 3D point cloud image reconstruction. Then, we combined the color images modified by the Histogram Equalization and Optimal Profile Compression (HEOPC) algorithm, and further used MobileNet-YOLO neural network to achieve accurate three-dimensional autonomous vehicle environment detection and identification. In the first year of the project, we proposed “point cloud image matching and restoration design based on DIBR.” The DIBR technology is used to generate disparity map information, and the conversion formula is used to obtain the results of the depth map. The obtained results are used in combination with the LiDAR point cloud map, so that the objects in the point cloud map can be matched and repaired in depth to obtain more complete environmental information of the LiDAR point cloud map and provide a highly accurate LiDAR point cloud map for the neural network. In the second year of the project, we proposed the “night image enhancement and correction design based on the HEOPC Algorithm.”With the fast computing characteristics of HEOPC, our proposed method combines the accuracy of deep learning to achieve optimized color image enhancement and provides neural networks to obtain better color image information at night. In the third year of the project, we proposed “design of a three-dimensional LiDAR autonomous vehicle environment detection system based on MobileNet-YOLO neural network.” Based on the restored point cloud information, we use point cloud image segmentation and merging to perform object segmentation.The training data is an optimized image after enhancement. We find the area of interest as the input signal of the neural network. Then we use neural networks to recognize objects of interest area. This method can segment and identify obstacles such as vehicles and pedestrians on the road. Finally, the recognized obstacles and point cloud maps are matched to achieve “Autonomous Vehicle Virtual View and 3D Point Cloud Map Fusion Technology for Real Time Object Detection Based on Deep Learning.”"
"hyperspectral data classification, artificial neural network, deep learning network, cloud platform","Imaging spectroscopy studies how the light interacts with the observed materials, measuring the amount of light that is emitted, reflected or transmitted from a certain object or target. Hyperspectral Imaging follows this principal to collect 400-2500 nm spectral region, and narrows down the spectral resolution of each band to 10-20 nm. Due to its characteristics, every hyperspectral pixel contains abundant spectral information to detect tiny or invisible  targets and to estimate their abundance within a single pixel.This project will focus on the hyperspectral data classification by implementation of deep learning networks. The principal of DNN is the strategy of divide and conquer to divide a big problem into several smaller ones, and then takes advantage of layers and neurons to learn its pattern. Due to advance of computing power in recent years, the computable layers and neurons could be largely increased as well to form the deep learning network. Although the hardware and software of hyperspectral imaging have been advanced rapidly, most of hyperspectral data analysis techniques are still not available to the users compared with the affordable price of its sensors. It made the analysis of hyperspectral data more difficult and reduced its utility in the consumer market. This project would like to address the issues by building an open cloud platform on Google or AWS to implement several deep learning networks for hyperspectral data classification."
"active compliance control, deep learning, robotic polishing, surface roughness","With the advent of Industry 4.0 era and the ensuing smart factory construction, robot automation is regarded as the future trend for production line manufacturing and assembling, and for automated storage and retrieval system. And integration of robot arm and automatic optical inspection (AOI) technique plays an important role in robot automation. In addition, the rapid development of artificial intelligence (AI) in recent years has seen many applications that sweep through many sectors and will bring about profound impacts on society. This proposal aims to develop an integrated system that consists of AI AOI and robot arm, and to apply the system for robotic polishing and inspection of a workpiece with curved surfaces. Thus the developed system can enhance both intelligent automation of the production line and product competitiveness.    As a result of such advantages as flexibility, high freedom, large working space, and low price, the use of robot arm instead of a traditional numerically computer controlled polishing machine and artificial polishing has become a popular research topic. One-year plan has been scheduled for executing the project: active compliance control for robotic polishing of curved-surface workpiece and AI surface roughness prediction. Detailed tasks in sequential order include design of polishing tool, polishing force control development, robot polishing posture and path planning, curved-surface sample testing and mass production of training data using image augmentation and generative adversarial network, deep learning of predictive model for surface roughness, experimental accuracy evaluation of predictive model for surface roughness, and finally performance testing and evaluation of the integrated system combining robot arm polishing and AI AOI surface roughness inspection."
"AI, Deep Learning, Deep Neural Network","Recently, deep learning, which uses Deep Neural Networks (DNN), plays an important role in many fields. In this project, the following two related subtopics will be discussed:1. A Novel Privacy-Preserving Deep Learning Scheme without Using Cryptography ComponentTo build a DNN model, an entity (a service/model provider) usually needs massive human-labeled data, powerful computing hardware, meticulous parameter setting, and researchers’ efforts. When the training is over, the DNN model can perform prediction on the data from another entity (a customer). However, in the inferencing phase, the process requires one entity to provide private information (the customer’s data or the trained model) to the other entity for the data inferencing by the trained model. Without a secure solution and mutual trust between the model provider and the customer, it would be an impossible task. To protect the customer's data and prediction result, the classical cryptography uses encryption technologies such as Fully Homomorphic Encryption and Garbled Circuits. Unfortunately, they are not suitable for large-scale AI computing systems because of the limit of the hardware computing capabilities. Another technique to protect the ownership of the model is Watermark. However, the watermark technique only helps the trust third party to arbitrate the ownership of the model when it is stolen. Considering the security challenges faced by the above traditional solutions, we will propose a new privacy protection mechanism that can simultaneously protect the customer data, the prediction result, and the trained model, without using complex cryptography component.2. Job Scheduling Based on Weight Pruning in a Deep Learning Accelerator	Deep Learning (DL) has achieved a huge breakthrough in many fields. Many innovative AI applications requires efficient computation. Previous work [19, 20] has found that Deep Neural Networks (DNNs) have many zero and near-zero weights. These weights can be deleted, i.e. weight pruning, to improve computation efficiency of the deep neural networks. However, different neural network models vary from one to one. This may lead to a difficulty of the hardware design and job scheduling. Thus, using an automation technology to analyze and support the hardware accelerator design flow may be helpful. In the second part of this project, we will study an optimization problem based on weight pruning technology, discuss the performance of hardware design, and propose a solution for the job scheduling problem."
"Deep Learning, Image Recognition, ADAS, Edge Computing","This project focuses on developing image recognition techniques of road objects suitable for all weather conditions. The FIR thermal imaging is used together with RGB camera and LiDAR sensor to build up the image dataset of  road objects under sunny, rainy, and foggy weather conditions. Then a deep learning neural network will be trained using the built image dataset for classification of the road objects. The trained model will be deployed into edge devices for ADAS applications, such as Forward Collison Warning, Pedestrian & Vehicle Detection, or Night Vision System."
"Urban renewal,Time series analysis, Deep learning, Urban planning.","Urban renewal is an important work in urban planning fields, and has a very positive effect on the long-term development of the city. However, how to predict the possible locations of urban renewal among a large number of urban built-up areas and effectively deal with related big data is an urgent problem that needs to be solved. This study will collect related data on urban renewal in 33 urban planning districts of Taoyuan City from 1970 to 2019, and try to build a database of related text attributes and spatial information. After that, we will sort and filter out spatial characteristics,  internal characteristics and external influence factors related to urban renewal from a time series perspective.  The significant correlation factors that have been selected will be input into a machine learning algorithm to test its effectiveness in predicting the location of urban renewal afterwards. The feasibility of applying deep learning algorithms to the automatic prediction and correlation factor detection of urban renewal areas will also be put forward. Finally, this research will present standard operating procedures and usage recommendations for the location update analysis in urban renewal areas. The results of this research would be very helpful to  improve the efficiency of future urban planning operations and effectively link the long-term management of smart cities."
"Hearing impairment, natural sign language, sign language recognition, machine translation, deep learning, sign language dataset, data labeling, human pose estimation, keypoint extraction, convolutional neural network, recurrent neural network, long and short-term memory model, sequence-to-sequence model, attention model, performance evaluation","In human life, hearing is an important channel for people to perceive the external environment and communicate with others. Hearing impaired people cannot hear sounds, so they mainly rely on visual language, that is, sign language to talk to others. Unfortunately, most people are less exposed to sign language and are unable to communicate with the deaf in their most natural language. Over time, a gap between the two groups has formed. The theme of this research is to design a vision-based Taiwan natural sign language recognition and translation system using deep learning which has made major breakthroughs in computer vision and natural language processing in recent years.  The project can be divided into three parts. First, a video dataset for training a deep neural network model for Taiwan natural sign language is constructed. The data set contains videos of sign language words and sign sentences and their corresponding text tags. Secondly, a Taiwan sign language word recognition system is designed. The system consists of human pose keypoint estimation, sign language keypoint selection and normalization, and multi-layer long short-term memory models. The purpose is to improve the accuracy of sign language word recognition. Finally, we will use sequence-to-sequence models and attention models in deep neural networks to translate sign language videos and calculate translation quality evaluation indicators. The short-term goal of this project is to build a Taiwanese sign language training dataset and improve the accuracy of Taiwanese sign language recognition and translation. The long-term goal is to optimize and transplant the system to a handheld device platform to break barriers between the hearing impaired and the general public."
"Anomaly Detection, Log Data, Workflow, Deep Learning, LSTM","System logs are generated from an incredibly broad range of devices, apps and servers. These Logs are imperative in the development and maintenance process of many software systems. They record detailed runtime information during system operation that allows auditors to monitor their systems and track abnormal behaviors and errors. Traditionally, auditors often inspect the logs manually with keyword search and rule matching. The increasing scale and complexity of modern systems, however, make the volume of logs explode, which renders the infeasibility of manual inspection. To reduce manual effort, many anomaly detection methods based on automated log analysis are proposed. Existing approaches that leverage system log data for anomaly detection can be broadly classified into three groups: PCA based approaches over log message counters, invariant mining based methods to capture co-occurrence patterns between different log keys, and workflow based methods to identify execution anomalies in program logic flows. Even though they are successful in certain scenarios, none of them is effective as a universal anomaly detection method that is able to guard against different attacks in an online fashion. In this proposal, a deep neural network model utilizing Long Short-Term Memory (LSTM), to model a system log as a natural language sequence. This mechanism can help auditor to automatically learn log patterns from normal execution, and detect anomalies when log patterns deviate from the model trained from log data under normal execution. In the future, we will compare this method with other existing log-based anomaly detection methods based on traditional data mining methodologies. Otherwise, some different types of RNNs (recurrent neural networks) will implemented to test the efficiency, and integrating more and more log data from different applications."
"The hearing-impaired, Hand gesture intention cognition, Sign language recognition, Deep learning, Convolutional neural network, Principal component analysis network","Compared with human communication by speech information or facial expressions, the use of hand gestures is another important communication method to really express affection and semantics. For the hearing-impaired, the aged with hard-of-hearing or speechless problems, and the group with emotional problems of melancholic tendencies and less-talking, gesture-based command recognition for control will probably not be the most required AI application for them. A gesture recognition system that can understand the gesture semantics and gesture intention by observing hand action information can then really benefit such disadvantaged groups.The plan is to develop a sign language recognition communication system with hand gesture intention identification where the deep learning strategy can be incorporated to take multi-modality hand gesture sensor information into considerations, and such developed system will be specific to the above-mentioned group. In the first phase of this plan, researches on the analysis of continuous-time hand gesture data of hand gesture intention, sign language, and sign language including intention and application scenario planning of such specific groups will be done first. Following, this plan will present a sign language recognition approach using continuous-time hidden Markov model (HMM) with the Kinect-depth sensor data, a hand gesture intention recognition method by template matching with the Leap Motion-3D sensor data, and a hand gesture intention recognition scheme using support vector machine (SVM) with the sensor data of Myo armband-EMG or Myo armband-IMU. For these studies in the first phase of the plan, the design of feature extraction for original sensor RAW data and the use of appropriate pattern recognition methods without deep learning will be the main works. In the second phase of this plan, the deep learning-based strategy is employed to develop hand gesture intention cognition and sign language recognition. The VGG-CNN deep learning model with neural networks of a series of convolution estimates belonging to deep- layered convolution calculations and the PCANet deep learning model with a principal component analysis (PCA) network of few convolution estimates belonging to shallow-layered convolution calculations are developed. Such VGG-CNN and PCANet single-channel deep learning models will provide different amounts of convolution calculations on learning of input hand gesture sensor images. To further enhance such recognition systems using single-channel deep learning of designed VGG-CNN or PCANet, two different categorizations of multi-channel deep learning mechanisms, called Multi-Channel VGGNet and Multi-Channel Convolution Hybridizations, will be developed in this phase. These proposed two multi-channel deep learning architectures will then be able to take multiple different hand gesture sensor modality data into account simultaneously on developments of hand gesture intention cognition and sign language recognition systems. Furthermore, a multi-mode deep learning recognition architecture that can integrate both the deep learning hand gesture features and the hand gesture RAW features without deep learning will then be presented to make an evaluation of recognition performance improvements on hand gesture intention or sign language recognition. Finally, this plan will also explore the technique issues that can be involved when developed sign language recognition with hand gesture intention cognition is employed in the real-life applications."
"Image Authentication, Convolutional Neural Network (CNN), Image Tampering, Image Recovery, Deep Learning","Multimedia technology and network transmission technologies have been developed rapidly and used widely. Due to images easily damaged or tampered during transmission, it makes receivers unable to read image content correctly. In order to solve the problem of image being attacked, forged or tampered, this project proposed a novel scheme for image authentication and tampered image recovery. This research uses a pre-trained convolutional neural network for finding the attacked or tampered area and recovers images effectively. First, the authentication information is embedded into the protected image. This authentication information is the representative feature extracted from the image. The encoder and decoder are trained through the original image and authentication information. Furthermore, this research proposed an error location detector that can detect the tampered location. Finally, the recovery convolutional  neural network and error location detector are used to recover the image to improve the image quality, integrity and security of the recovered image. This research combines image authentication and deep learning technologies. Neural network learning feature improves the image recovery quality and is also capable of image integrity authentication."
"Text Mining, Beacon Text Data, Deep Learning Neural Networks, Neural Language Process, Semantic Ontology Analysis, Nature Language Processing System, Intelligent Integrated Mobile Systems","Text mining is a relatively young discipline in data mining. Text mining can extract useful and important information or knowledge from unstructured texts. Most of the information in traditional media, online new media and beacon advertising information is stored in words with unstructured texts. In addition, text mining is being used to explore a variety of unforeseen, innovative, and important information or knowledge on the internet in a very rapid way, accumulating more and more unstructured data such as product evaluation, intelligent surveillance, information integration, governance evaluation, opinion polls, community preferences and more. They are all very important tasks for government agencies, business groups or individuals. The related research and practice of text mining has become the hot topic on information or knowledge integration recently. At present, this sub-project, we have actually explored the beacon communication method, and set up beacon essays with different ID numbers on the server (cloud system). The proposed method can process beacon text data and test several different online Chinese word segmentation systems, text cleanup and tokenization of text pre-processing and bag of word and feature selection of text transformation have been tested. Proposed word processing systems with Python, Java and Matlab can process text data. We also develop a classification algorithm for text exploration based on bags of words and Latent Dirichlet allocation (LDA). Besides, the feature data of bag of words is integrated into the rough set theory, and a text exploration algorithm based on rough set theory and an information extraction algorithm for beacon text exploration based on rough set theory are proposed. The first year of this sub-project will be set up the Word2Vec model, the Word2Set with similar word determination rules and the nature language processing system that can deal with beacon text data. We will derive the language modeling and noisy language modeling of text mining based on N-gram model based Long-Short-Term-Memories deep learning neural networks. We will also derive new learning structure that hybrid Long-Short-Term-Memories and recurrent neural networks for beacon data language identification problem. The second year of this sub-project will be set up the semantic ontology analysis nature language processing system and new hybrid model system with the Word2Set and the Word2Vec that can deal with beacon text data. We will derive the text summarizers that automatically construct summaries of a natural language document under new deep learning neural networks of neural language processing. We will study new semantic neural language processing system. We will also derive new recurrent neural networks deep neural networks for identification problem of beacon data language. Finally, we will develop an intelligent integrated mobile system for beacon text data. This intelligent text mining mobile systems develop from machine learning to deep learning. Besides, this intelligent system integrated deep learning frameworks on mobile platforms and integrated the technologies of three years on deep learning for beacon text data mobile systems. We will also independently implement intelligent integrated mobile systems for beacon text data with Python and Java in this subproject."
"Deep Learning, Financial technology (FinTech), Big Data Analysis, Investment Behavior Modeling, Cloud Computing","With the advance in financial technologies, the financial industry has expanded and evolved a variety of different modern financial services. Analyzing people’s financial activities has become the emerging research fields that attract a lot of attentions. However, it is not easy to analyze users’ behavior through modern financial services. The reason is that the data collected from financial services always has big data properties, ie., High Volume, High Velocity, High Variety, Uncertain Veracity. According to above-mentioned 4Vs issues, the analysis of big data can not rely on a single computer. Accordingly, we have built a cloud-based platform for analytics of big data which is founded through our previous project, Study on Cloud-Computing-based Investment Behavior Modeling Platform of Deep Learning (MOST 108-2221-E-224 -038 -). Due to the 4Vs issues, there are still many research issues would not be addressed in the previous project. Therefore, in this project, I plan to propose a series of deep learning technologies based on our previously proposed cloud-computing-based platform which can be utilized for analyzing investors’ behavior that is revealed through financial services. We can apply the analysis result of investors’ behavior for many real-world applications, such as Risk management, investment adviser, etc. Therefore, we expect that our proposed algorithm and application for improving cloud-computing-based platform not only benefit the industries but also improve the quality of their services."
"Deep learning, Multispectral imaging, Fully convolutional networks, Image processing, Skin condition","The global cosmetics market has grown steadily over the last decade. Even during 2009 economic recession its growth surprisingly remains positive. Among the numerous cosmetic products, how to choose the best one best for skin conditions of an individual is a challenging undertaking. The main reason is that skin conditions vary widely across individuals. Improper choice of skin care products could be harmful to health.In this project, two systems will be developed: one APP for users to take pictures through a mobile device and upload images to the cloud drive for face detection, and another inspection machine or a hood-equipped system with Multispectral imaging spectrometers. Through the analysis of skin textures in a hood-like environment with a multispectral camera to capture full-face images, detailed skin conditions can be characterized. Both systems can be compared with skin conditions stored in the database to provide three functional supports: viz., intelligent detection, customized recommendation, and autonomous management.In the first year of the project, we will collect facial images under different ambient lightings, and learn to identify features such as skin color, spots, and wrinkles through the Fully Convolutional Networks (FCN) to determine the skin conditions. In the second year, we will, by integrating with multispectral cameras and deep learning algorithms, detect various skin conditions (such as acne, wrinkle, red blood, ultraviolet sunburn, pigment, pore and oil distribution) and inform users to early detect potential changes in the skin, and to recommend timely treatments against dermal aging. In the third year, we will establish a skin image database, develop a human facial skin test APP to determine the skin conditions through cloud computing mechanisms, and recommend proper skin care products."
"deep learning, optical coherence tomography, macula, gender, age, epiretinal membrane, macular hole","The macula, located in the center of macula, is responsible for the most important part of central vision. Once there is structural change or damage in the macula, the vision well be severely impaired. Epiretinal membrane and macular hole are two macular diseases that would impair the vision, and both are more prevalent in females and older people. Both diseases have been thought to be mostly idiopathic, which means that no specific causes are correlated with them. As to the question why they are more prevalent in females, there has also been no answer to it. One study team has found that eyes with a wide foveal pit shown in optical coherence tomography (OCT) had a high prevalence of epiretinal membrane or macular hole in their contralateral eyes. Besides, the incidence of female was five times that of male. This means that there should be sexual differences in macular structure that result in the differences of disease prevalence between male and female. However, the ophthalmologists have known little about the sexual differences in macular structure. As for the age-related structural changes in macula, it has also been barely known. One of the main reason is that many structural characteristics in macular OCT are difficult to parametrize. The purpose of this study is to evaluate the correlations between macular structure and gender, age, epiretinal membrane and macular hole, and to evaluate the structural characteristics that affect vision in epiretinal membrane by analyzing macular OCT using deep learning due to its advantage of image analysis. We hope to unveil the secret of macular structure and its associating diseases from OCT by the help of artificial intelligence."
"edge computing, intelligent robots, deep learning control, embedded systems","This project aims to develop a biologically inspired edge computing paradigm based on metaheuristic multilayer perceptrons(MLP) for deep learning control of intelligent swarm robotic systems. In the first year, a modified grey wolf optimization(GWO) algorithm with adaptive L?vy flight and dynamic weight is proposed to optimize the MLP structure, called GWO-MLP. The modified GWO is applied to address the hyper-parameter tuning problem of MLPs. A distributed model with GPU(Graphics Processing Unit) implementation is employed to construct the GWO-MLP biologically inspired edge computing. In the second year, the proposed GWO-MLP edge computing is extended to cope with the deep learning control of Mecanum mobile robots in polar coordinates. The polar-space kinematic model of the Mecanum vehicles is derived and the motion control law with Lyapunov stability is synthesized. With the derived kinematics, the online deep learning control scheme is developed using the presented GWO-MLP edge computing. This real-time control method is superior to the traditional offline controllers because the control parameters are self-tuned at every sampling period. In the third year, the custom robotic IP(Intellectual Property) are developed in FPGA(Field-Programmable Gate Array) chip using SoPC(System on Programmable Chip) technology. These hardware IPs are integrated with GPU GWO-MLP deep learning control to provide GPU+FPGA solution for intelligent robots. Furthermore, this project will construct an experimental swarm robotic system in which each robot is equipped with an independent GPU+FPGA GWO-MLP edge computing node. Simulations and experimental results will be conducted to show the merit of the proposed GPU+FPGA GWO-MLP for deep learning control of swarm robotic systems."
"driving simulator, lane change, deep learning, convolutional neural network, decision network, trajectory planning, adaptive cruise control, lateral displacement control, traffic flow, simulation verification","Decision networks for automatic lane change using deep learning are proposed in this project. Vissim is used to establish scenarios with different traffic flows in the driving simulator. Whenever the driver makes lane change, the dynamics of the host vehicle and the relative distances of surrounding vehicles are recorded. These data are converted to time headway and time-to-collision which are commonly used in the advanced driver assist system as indexes for risk assessment. Corresponding decision intents of the driver are also recorded simultaneously. These data will be labeled and classified into training and verification sets. One dimensional convolution neural network is used to establish the decision network for lane change. The inputs of the network are time headway, time-to-collision and relative location area. The output is the driver’s intent. Lane change behaviors are classified into two modes. One is before lane change and the other is during lane change. Networks for these two modes will be developed separately. The decisions before lane change are lane following, lane change to right and lane change to left. The decisions during lane change are keeping lane change and aborting lane change. When lane change is determined by the decision network, the time-to-collision is used to design the lane change trajectory. The adaptive cruise control and lateral displacement control developed in previous projects will be integrated with the decision network to generate the steering, brake and throttle control commands. Finally, Vissim is used to establish the virtual traffic flows which consist of aggressive and conservative driving behaviors. The first test is open-loop verification. The driving simulator is operated by the driver. The decision accuracy of the decision network is verified against the driver’s lane change behavior in parallel. The second test is closed-loop verification. The decision network integrated with trajectory planning and tracking control is used to directly control the virtual host vehicle. The driving simulator is no longer operated by the driver. The driver only sits on the driver seat to perform subjective evaluation to confirm if the system meets his/her need for automatic lane change."
"Coffee roasting, Agtron-Time curve, Temperature -Time curve, Computer Vision,Convolutional Neural Networks (CNN), Remote monitoring of mobile phones","The goal of this project is to develop A Real-Time Coffee Roasting level Estimation system Based on Artificial Intelligence. It can be used in combination with the roasting machine to greatly prevent the coffee roaster from the tedious hand checking of the current coffee roasting level, and allows the use of the (more effective) Agtron-Time curve to replace the traditional (less effective) Temperature-Time curve in coffee roasting. The key ideas include: 1. Using the appropriate convolutional neural network technology to identify, and report in real-time the roasting level of coffee beans under roasting.2. Based on the above-mentioned developed instant coffee roasting identification technology, each time interval (seconds) in each roasting process is automatically collected by the sensor. {Agtron roasting degree, roasted time, drump temperature, room Temperature, humidity, sound, etc.} in order to establish and auto-update the Coffee Roasting Model, which combined with Experience based Reference Table(ERT) Analysis can estimate and remind the roaster(human or machine) the time required for the next category of coffee roasting level. Overall, Through the use of proper sensors and advanced artificial intelligence techniques including CNN and ERT Analysis, may allow the roaster (human or machine) to grasp the real-time roasting conditions more precisely.The project, in collaboration with Yunlin Mango Coffee and Tainan Dabanhua in Taiwan, is expected to contribute/promote the coffee industry in Taiwan and the world: 1. Allow the coffee roaster (human or machine) to better grasp necessary information for more sophisticated coffee roasting. 2. Allow Baking machine manufacturers to integrate this technique as a built-in module or Develop Independent Module of different types which may be add-on to different existing roasting machines. 3.Through the wireless transmission method, the information is transmitted to the mobile phone, so that the baker can monitor the baking degree in other places as well.The project, in collaboration with Yunlin Mango Coffee and Tainan Dabanhua in Taiwan, is expected to contribute/promote the coffee industry in Taiwan and the world: 1. Allow the coffee roaster (human or machine) to better grasp necessary information for more sophisticated coffee roasting. 2. Allow Baking machine manufacturers to integrate this technique as a built-in module or Develop Independent Module of different types which may be add-on to different existing roasting machines. 3.Through the wireless transmission method, the information is transmitted to the mobile phone, so that the baker can monitor the baking degree in other places as well."
"Intelligent Video Surveillance, Anomaly Detection, Unsupervised Hierarchical Deep Learning, Spatial Deep Anomaly Event Descriptor, Spatiotemporal Deep Anomaly Event Descriptor","Intelligent video surveillance (IVS) systems aim to provide automatic surveillance video analysis results for security issues in modern smart city applications. When IVS systems detect anomaly events, they can alarm police officers to handle related issues. Due to the variety of anomaly events and complicated city environments, it is hard to collect sufficient training data and label the data for supervised learning, including deep learning. To solve the problem, we propose a novel unsupervised hierarchical deep learning method. Our method is composed of two unsupervised networks, the spatial anomaly detection deep network and the spatiotemporal anomaly detection deep network. The front one aims to detect anomaly events from each frame, and efficiently remove backgrounds and normal events for fast computation. The latter one aims to effectively detect the anomaly events in the video domain. Moreover, we will apply the spatiotemporal deep anomaly event descriptor extracted from our unsupervised hierarchical deep learning method for multi-camera anomaly event verification and foreground object co-segmentation. In this way, we can solve the anomaly detection problem in IVS and provide the industry a practical solution."
"Hypopharynx cancer, Radiomics, Deep learning","Hypopharynx cancer has the worst prognosis of all head and neck squamous cell cancers. Approximately 80% of patients have stage III to IV disease at the time of diagnosis. MRI is commonly used in clinical practice for tumor staging and surveillance. Radiomics refers to the comprehensive and automated quantification of radiographic phenotypes using data characterization algorithms. Radiomics has shown promise in predicting clinical outcomes of various tumors, and hence potentially provides complementary information for decision support in clinical oncology. CT is pivotal for radiotherapy treatment planning of hypopharyngeal cancer because CT remains the only imaging modality for dose calculation, while MRI is often used to complement CT for tumor delineation. Tumor segmentation plays a critical procedure in both radiomics analysis and treatment planning of radiotherapy. While manual segmentation is time consuming, laborious, and subjective, deep neural networks have emerged as promising alternatives for automatic medical image segmentation. The aims of the proposed study are to: (1) establish a framework of deep learning algorithm to automatically segment tumor and extract radiomics features in patients with hypopharyngeal carcinoma. (2) use the generated radiomics features in quantifying phenotypic characteristics and predicting local control, distant metastasis, and survivals in patients with hypopharyngeal carcinoma. (3) automatically construct gross tumor volume (GTV) contour on CT image for hypopharyngeal tumor to aid treatment planning of radiotherapy.The proposed a two-year plan will retrospectively collect MR images of 480 patients diagnosed with hypopharyngeal squamous cell carcinoma treated with chemoradiation. The deep learning model will be trained by adopting the state-of-art architecture, DeepLab V3+, for segmentation in MRI, followed by transfer learning and Generative Adversarial Networks (GAN) to generate GTV contours in CT data. Upon the accomplishment of the research plan, we will build a pipeline using the deep learning model to automatically generate (1) radiomics features in quantifying phenotypic characteristics and predicting treatment outcomes and (2) tumor contours of CT and MRI for facilitating radiotherapy planning in patients with hypopharyngeal carcinoma."
"model compression, Bayesian deep learning, variational inference","In this project, we will develop algorithms to compress redundant neural networks that have huge amounts of parameters and to accelerate computations. Recently, neural networks have had state-of-the-art performance in multiple tasks, such as image recognition, object detection, and semantic segmentation, etc. Among those networks, Convolutional Neural Network (CNN) is an efficient way that has been evolved rapidly and been successful tested for identification. However, in order to gain higher accuracy, the model become larger and deeper, accompanied with more parameters and inference time. Although using graphics processing units (GPUs) to reduce the inference time of the current research by parallel computation is feasible, the applications of neural networks on the edge computing devices may still be limited by of memory and energy consumption, and the  machine learning can’t be widely used in daily lives. We will investigate the state-of-the-art research of neural network compression in many aspects, and develop the model compression algorithm to improve the computation efficiency mainly for convolutional neural networks. The project will last for one year. We adopt the Bayesian deep learning to train the network. Applying the probabilistic estimation of the model parameters with uncertainty  can compress the network in a more reasonable way and avoid irreversible errors. In this project, we will implement (1) variational inference network pruning, (2) variational inference network quantization, (3) an algorithm for learning sparsity constraints, and will integrate the network training methods with commonly used deep learning network models."
"Precision marketing, Recommendation system, Deep learning, Time-series forecasting models, click-through rate (CTR), blocking rate","With a large amount of accumulated customer behavioral data and the rise of big data analysis, data-driven precision marketing has become a crucial issue for many companies. In contrast, traditional marketing strategies require a huge amount of resources into advertisements due to the lack of precise and targeted promotion to the right customers. In this project, we aimed to build a comprehensive precision marketing platform via state-of-the-art technologies such as deep learning, data science, recommendation system, natural language processing and computer vision to predict different scenarios for our start-up collaborators. The proposed precision marketing platform aimed to blend precision marketing into existing recommendation systems used in companies, which makes automatic marketing decisions based on customer behavioral data. The platform can not only significantly improve customer satisfaction but also provide customer-centric precision marketing through the power of artificial intelligence. In the fourth year of this project, we aim to further improve upon our current platform for automated decision making in two aspects: 1) we plan to “go deeper” into technologies to further improve the current recommendation/forecasting outcomes with our industry partners. Through this process, we will further strengthen our existing partnerships and increase the value of our contributions; 2) we plan to “go broader” and expand the capacity of our platform by attempting to deliver precision marketing and personalized prediction solutions to companies in other sharing economy industries, such as WeMo (an e-scooter sharing company), Whoscall (an anti-fraud mobile app sharing economy company), and OB Design (a fashion company). Through exploring these new opportunities, we hope to demonstrate that the applicability and impact of our recommendation and prediction platform are indeed general enough to offer solutions to different types of sharing economy industries. We believe that our comprehensive recommendation/forecasting platform developed through this project is able to extract useful and actionable information from customers’ buying and other behavioral data, which will be beneficial for both the companies and their customers. We will also make an important impact on the industry through our strong industry partnerships by sharing research findings/patents and providing necessary technology transfer to these startups."
"Microwave Imaging, TM waves, TE waves, Anisotropic Objects, Neural Networks, Deep Learning, Artificial Intelligence.","This proposal is using neural network and deep learning method to reconstruct electromagnetic wave imaging of anisotropic objects. We transmit the electromagnetic wave to the anisotropic objects and record the scattered field. By TM and TE waves illumination, the dominant equivalent currents can be calculated. According to the dominant currents, we can compute the approximate permittivity tensors. Note that this approximate permittivity tensors will be a little different with the exact permittivity tensors, since only dominant currents are used. As a result, we use the neural networks (such as multi-layer perceptron, radial basis function and convolution neural networks) in the artificial intelligence to reconstruct the exact permittivity tensors by deep learning. In the first part, we will focus on the TM (Transverse magnetic) wave to reconstruct the permittivity in the z direction. In the second part, we will focus on the TE (Transverse electric) wave to reconstruct the permittivity in the x and y direction. Finally, we investigate the reconstruction of anisotropic objects. We will improve the reconstructed image by applying the dominant equivalent current and deep learning. Suitable neural networks to reconstruct the permittivity tensors will be proposed."
"maximum power point tracking, energy distribution optimization, adaptive controller, deep learning","This proposal “Design and Implementation of a Parallel Deep Learning Building Energy Control System (II)” with execution period 2020/08/01 till 2021/07/31 has the main goal to implement a power generation and energy saving system. This proposal is an extended research of the PI’s 2019 project. The proposal is divided  into three subtopics: 1. Power supply system design and implementation - we will extend the database integrating building information model from last year’s project to implement the solar photovoltaic system; 2. Maximum power point tracking adaptive controller design and realization - the maximum power point of  solar photovoltaic system is influenced by environmental factors. Therefore, this proposal will design an effective adaptive controller to make maximize the power generating performance under various conditions; 3. Energy distribution optimization using a deep learning algorithm design and realization - the uncertainty of payload demand and the battery characteristics will also affect the performance of the system. Therefore, this proposal will optimize the discharge strategy of the battery system."
"SLAM, Orthophoto, Binocular Stereo Vision Based Obstacle Avoidance,Deep Learning,Crack Detection","The inspection of infrastructures requires enormous amount of manpower and high-cost heavy machineries. Nevertheless, there is not yet a well accomplished, intelligent and automated inspection vehicle system. Thus, the inspection mostly relies on manpower which is of high cost and occupational injury risk due to high-altitude working environments. In addition, the traditional methods are extremely inefficient which make it impossible to perform comprehensive inspection and control of dangerous bridges. Moreover, sampling and inspection of certain bridges cause difficulties in industrial safety management.In order to solve the problems mentioned above, this project designs and manufactures UAV for bridge inspection. Considering the complex bridge structures and poor GPS signals under bridges, the UAV developed by our team has the following characteristics: 1.SLAM(Simultaneous Localization And Mapping) system: Since the satellite signals are shielded under bridges, UAV may lose positioning. Through self-assessment of position by real-time scanning of spatial information with radar, the problem can be solved.2.Orthophotography of Internal Structure: With our self-developed orthophoto gimbal system, image collection may not be affected by flying vibrations, etc. Instead of shooting at a fixed point, UAV can collect stable and high-resolution orthophotos during the flight. Thus, the flight time under bridges can be greatly reduced.3.Obstacle Avoidance System：By using binocular vision and 360° LIDAR scanning detection to calculate the relative distance of the current environment and RTK correction of spatial positioning, collisions can be prevented and the safety of UAV and bridges are ensured.In the latter phase, initial automatic determination of bridge degradation areas and automatic detection of cracks can be realized through deep learning which may greatly reduce manpower requirements and improve efficiency, providing a complete solution."
"construction site images, artificial intelligence, deep learning, object detection, single shot multibox detector (SSD)","Most of the construction companies would take site images for construction process records, quality control, schedule control and other project management tasks. Image files are larger and more difficult to process when compared with numbering records. As a result, image files are not used as much in the construction industry. There is a need for an image recognition and object detection system that can actively identify and mark objects such as personnel, equipment and material in the construction images. Thus, the site images are able to provide more information for project management tasks such as construction safety, site layout planning, schedule control and quality management. In addition, the artificial intelligence has been widely adopted among various research fields; in particular, the applications in the computer vision. Research results have shown that deep learning can be effectively applied in image recognition and object detection, such as the application in the development of autopilot. Therefore, this research intends to adopt the deep learning and Single Shot Multibox Detection (SSD) methods to develop an image recognition and object detection system for construction site images. The proposed system will be able to identify objects such as personnel, equipment and materials in the construction images in real time. By doing so, the system can provide more valuable site information to assist the project managers making important project decisions. In the long run, the effectiveness of the construction management can be improved and the competitiveness of the construction industry can be enhanced."
"Deep Learning, few-shot Learning, Semi-supervised Classification, Semi-supervised Regression","Deep learning has witnessed the great success in many application domains in recent years, since it provides a way to learn discriminative and hierarchical features from input data. However, several challenge problems have arisen as with the popularity of deep learning. One of the challenges is that the deep learning models normally requires a large amount of training data to learn a robust and accurate model from input data. Deep learning relies on a deep neural network architecture to learn feature representations, so the model always involves enormous parameters. Although several novel architectures and techniques have been devised to deal with the overfitting problem in recent years, the deep learning model still normally requires enormous training data. Transfer learning is one of the approaches that could be used to deal with this problem, but transfer learning is achievable based on two assumptions. First, there exists some kind of relationship between source domain and target domain, so that transfer learning is reasonable in this setting. Second, the source domain still requires enormous training data to train a pre-train model, so that one could use a few target training examples to fine-tune the pre-train model. Therefore, this work focuses on the study of using a few training examples in deep learning, and we propose a 3-year project, and the topics for each year include few-shot learning, semi-supervised classification, and semi-supervised regression. In the first year, we focus on few-shot learning, and we use meta learning setting to devise the algorithm. The purpose is to use a few training examples to lean a distance function, which could be applied to the class categories that have never seen in the training phase. Based on the result of few-shot learning, we extend our problem to semi-supervised learning, which requires to use a few training examples and enormous unlabeled examples in the training phase. The problem in this project is challenging, and we believe that our research results could be useful in academic and industrial fields."
"deep learning ,CNN, extra-solar planets","During recent years, the deep learning of artificial intelligence becomes widely used in many fields, including astronomy. In this MOST project, we plan to use the deep learning method to search for transit events from light-curve data which are obtained from images of sky surveys, and investigate the possibility of the existence of new exoplanets.There are several methods to detect extra-solar planets (exoplanets).The transit method is one of the most popular methods for detecting exoplanets nowadays. A huge number of observational data will be available for further exoplanet detections and studies through the transit method.　We will employ the Convolutional Neural Network of deep learning to construct a computer code.   We will generate 10^6 light curves for BRITE-Constellation data and train CNN models, and try to obtain a best CNN model.We will construct 1D-CNN and 2D-CNN deep learning models to analyze all the BRITE-Constellation data. We will study how the accuracy is affected by the values of parameters in models. These two models have both goodness and shortcoming, so we would like to investigate the features of these two models through BRITE-Constellation data. Finally, we will try to find exoplanets from other survey data by using this best CNN model."
"deep learning, convolutional neural network, computer vision, 3D object detection, 3D object recognition, 3D object segmentation, 3D object position","This proposal had been applied a three-year grant support, however, we only obtain one-year support; in this project, we modify the original project content to apply the remained two-year project execution. In this project, we pursue the detection and recognition rates reaching 99%, 99.5%, 99.9%, even 99.99% by modifying the existed techniques applied in special fields; we are not develop new techniques with testing in common data bases; such as, PASCAL VOC, ImageNet, MS COCO, to pursue 70%, 80% performance with 1%, 3% increasment. In the special-field applications, we need principle of CNN related theory to improve the existed techniques to reach higher performance. I studied more than 100 related papers in near retiring year, systematically prepared more than 50 famous CNN models, and supervised the middle-quality students to modify the network structure, modules, functions, and alogrithms to reach 99.5% detection and recognition rates; I have no enough time to complete the top journal/top conference papers.This research project is a two-year project. In this project, we want to develop deep-learning techniques to improve the effect and efficient of 3D object detection, recognition, segmentation, and position application techniques. In each year study, we propose two theoretical techniques on developing CNNs and two application topics on 3D objects. In the passed year, two theoretical research topics are: (1) improving the CNN with detection and recognition of objects to adapt the large size variation and (2) analyzing the performance of different fusion structures on 2D and 3D images; two application topics are: (1) comparing CNN-based object detection and recognition using RGB images and (2) CNN-based object and recognition using RGBD data. In the first year of this project, two theoretical research topics are: (1) developing 3D CNN to acquire 9 DoF parameters of 3D objects and (2) using GAN to correct the distance error of 3D camera; two application topics are: (1) executing 3D CNN for 9 DoF estimation of 3D object and (2) developing the bin-picking robot arm system. In the second year, two theoretical research topics are: (1) improving the performance and speed of the CNN and (2) modifying the CNN by adding segmentation function; two application topics are: (1) CNN-based 3D object detection, recognition, and segmentation and (2) 3D object position estimation for automonous in door vehicles.This study bases on our previous fruitful studying results, and focuses on the fixed topics to develop special CNN systems to solve the tricky problems on visual detection, recognition, segmentation, and position. The principal investigator of this project is an original researcher on computer vision; he has studied computer vision techniques more than thirty years; moreover, he has several-year experience of deep learning techniques applied on computer vision problems. In these two years, he has separately collaborated with three companies and ITRI to develop CNN techniques for object detection / recognition and defect inspection on PCBs; thus, we have ability to complete the execution of this research project."
"LiDAR, point clouds, semantic segmentation, classification, deep learning, convolutional neural networks","The semantic segmentation of LiDAR point clouds would be the important processes for 3D object reconstruction. The quality of the semantic segmentation results would directly affect the subsequent analysis and applications of point clouds. Considering that LiDAR scanners are attributes of blind systems, how to automatically perform the semantic segmentation becomes an important research topic. The traditional methods for point cloud segmentation and classification need explicit prior knowledge to extract the specific features. On the other hand, the powerful convolutional neural networks (CNNs) cannot directly be used to process the irregularly distributed and unsorted points within point clouds. The algorithm of deep learning for point clouds is still rare because of the high complexity of the network architecture and the expensive calculation time. Based on the convolutional neural networks and referring to the PointNet and KPConv models, this project will focus on the problem of the insufficient local features provided by the PointNet. A deep learning algorithm for the semantic segmentation and object classification form point clouds will be proposed. This study will evaluate and adjust the network parameters to optimize the proposed 3D deep learning model, and try to solve the problems that may be encountered, which can improve the efficiency and accuracy of the segmentation and classification from the point clouds. Finally, the actual applications of land object classification, identification and change detection on several international benchmark datasets and a real dataset in Taiwan will be carried out."
"smart manufacturing, deep learning, stochastic flow network, confidence level, correlated failure, maintenance policy","This three-year project will apply deep learning and stochastic flow network theory to forecast the reliability of smart manufacturing systems. The primary goal of this project is to forecast the reliability that a smart manufacturing system can satisfy a given demand under a specified time constraint without knowing the probability distribution. In addition, data collection with monitoring devices will be experimented to understand the applicability of the proposed network model. In the first year, a time-related stochastic flow network will be developed to assess the capacity and reliability of the smart manufacturing system. Deep learning will be applied to consider the real-time environment and machine parameters that may affect reliability forecasting. In the second year, output yield of workstations is involved in the stochastic flow network. The yield rate of workstations will be predicted via deep learning for a real-time environment, including machine parameters. Subsequently, a confidence-level approach will be utilized to determine the input amount of raw materials. Additionally, the confidence-level approach can be applied to determine a target of yield rate to be improved. An artificial intelligent decision support system is built to assist managers to take an appropriate action to improve the input amount or improve the yield rate under limited resources. In the third year, correlated failure of machines in a workstation will be considered. The correlation between machines failures will also be obtained via deep learning for real-time environments and to estimate machine parameters. Furthermore, policies to maintain and recover smart manufacturing systems under budget constraints will be developed with a sensitivity analysis procedure to optimize performance."
"H.265 Compression,Image Object Detection,Heterogeneous Image Fusion ,Deep Learning,Edge AI System,System on a Chip,VLSI Architecture Design,FPGA Design","Based on visible-light and thermal cameras, this proposal is intended to study the intelligent detection and fusion system of heterogeneous image objects. It covers several research topics such as dual image object deep learning, image fusion processing, VLSI architecture design, and edge AI SoC etc. The heterogeneous image object detection will be applied in many movement platforms, such as defense industry, smart manufacturing, autopilot vehicle etc. This is a biennial proposal and its key-point researches are described in the following:In the 1st year, this proposal focuses on the construction of heterogeneous dual camera platform, image deep learning detection and fast fusion algorithm. The design of heterogeneous dual camera platform system includes visible-light and thermal cameras, embedded system, WiFi communication, automatic image calibration, H.265 codec algorithm. For image detection, we will propose a new type of neural network architecture, called feature-concatenate U-Net, to achieve object detection, identification and segmentation of heterogeneous image. Also it can improve performance in terms of speed and accuracy. For heterogeneous image fusion, we study combining wavelet decomposition and saliency weight to enhance the effect of explicit fusion images. This approach is unaffected by weather and ambient light and dark, and the storage space requirement is reduced.  In the 2nd year, the main research focuses on the design and implementation of edge AI system and SoC chip. First, the optimizations of feature-concatenate U-Net and image fusion algorithm are considered and discussed. Next, they are implemented in the development board of Nvidia Xavier. Besides, we will complete the real-time communication between the development board and dual camera platform. Next, by computing complexity analysis, the whole system is partitioned into software and hardware for co-design. The VLSI architecture will be exploited for Feature-Concatenate U-Net to promote the processing speed. The heterogeneous image fusion is realized by embedded software. Finally, the system integration is designed and implemented by FPGA prototype."
"Dynamic Public Opinion Propagation, Social Network Analysis, Deep learning","This study is based on the theory of social psychology to expand the bounded confidence model, in which the agents will consider the surrounding public opinion when they form their own opinions. If they do not accept the surrounding opinions of others, they may be excluded (agents will consider the pressure of public opinion pressure). That is called ""normative social influence"", which is different from the bounded confidence model (In the bounded confidence model, the agent decides whether to accept the opinions of others, only depending on whether the opinions of the neighbors are similar or not). In order to simulate the effects of normative social impacts, namely ""public obedience"" and ""private acceptance"", this study has expanded agents’ ""opinion"" into two levels of ""opinion"" and ""attitude"" to simulate more extensive and realistic dynamics of opinions in the community. We design this model to be compatible with the existing bounded confidence model. In addition, we also observe the difference of dynamic evolution between opinions and attitudes, and explore its causes. We use the method of dynamic deep learning to adjust the uncertainty parameters of agents to simulate the mechanism of inner adjustment of agents to follow the public opinion or stick to their own opinions. In terms of experiments, we use this model to explore more complex and real issues, including the formation and breaking of ignorance, minority influence, ideological control, media influence, and show the application of this model in the dynamics of simulation opinions."
"Deep Learning,Virtual Try-on,Generative Adversarial Network,Pose Estimation,Human Parsing","In recent years, E-commerce grows at unprecedented rate. Because of some clothing retails turn to the network by entity shop, customers are more familiar with buying garments online. Therefore, some online shops provide the service which helps you try on clothing without entity clothes. When you choose the cloth you want to try on, the service will fit your virtual body with the specific cloth. However, most virtual try-on applications need to pre-define the 3-dimensional garment database and accurate virtual avatars. They deform the human model by following body parameters of user and use the physical cloth simulation to render the plausible results. The 3-dimensional based method is computationally expensive. Additionally, the diversity of pose and clothing is limited by the pre-defined templates. All of them can not solve the problem of exchanging an arbitrary clothing between two persons with arbitrary poses in image space.Recently, deep learning has been widely used in computer vision, computer graphics and other fields. We developed a project for portrait–aware artistic style transfer using deep learning last year, which based on deep learning, only extract features from a single style image to do texture synthesis. According to our developed project, we propose a project ""  Virtual Try-on : Deep Learning for Cloth Styles Switching"". In order to exchange garments between images, many kernel technologies will be developed in this project include: (1) Pose Estimation and Human Parsing、(2)Clothing Structure Extraction、(3)Dual Path Encoder-Decoder Generator、(4)Local Discriminator、(5)Texture Transfer、(6)Analysis and Comparison. First, the images should be disentangled into cloth part, face part, and lower body part. Besides, we need to extract the pose information from the target person image. Next, the clothing information need to be transferred across different poses by establishing the relationship between an arbitrary cloth and the target pose. Finally, due to the complex logo is difficult to synthesize, the logo should be detected and transferred onto proper region in the post-process. Our approach bases on a learning approach which extracts the body information and synthesizes the high resolution and realistic images of the target person. The main contribution of this project is that we improve the Wang’s architecture as dual input path to generate high resolution images, and propose a state-of-art end-to-end virtual try-on network. Besides, the saliency map is used to guide the logo recovery of the network outputs. Our results can preserve body, neckline shape, and clothing texture simultaneously."
"Deep Learning, Artificial Intelligence, Image data, Brain diseases, Prediction models","Intracranial Artery Stenosis (ICAS), Cerebral Aneurysm, Acute Ischemic Stroke (AIS) and Acute Hemorrhagic Stroke (AHS) are very serious neurological diseases of brain that require emergency medical intervention. Doctors use varieties of images such as Computed Tomography (CT), Computed Tomographic Angiography (CTA), Magnetic Resonance Image (MRI), Magnetic Resonance Angiography (MRA), and Digital Subtraction Angiography (DSA) images to detect these brain diseases. Those collected images are highly unstructured and are stored in DICOM format. When the brain disease patients are admitted to a hospital, huge volumes of images are generated from the patients, which are usually unstructured. All these medical images of brain diseases are stored in the PACS of Chang Gung Memorial Hospital (CGMH) and Stroke Registry of Chang-Gung Healthcare System (SRICHS). To process and analyze these imaging data using classical statistics is very difficult and time-consuming as they comprise varieties of data types in different formats.  Besides, these medical images are large in size and may contain 100 to 150 slices per patient. Analysis of various features in the images and correlating the features manually with the clinical data is a tedious job. Currently used classical statistical tools such as ANOVA, ANCOVA and MANCOVA are inefficient to handle the huge volume of the unstructured data for predicting the brain diseases. Hence, Deep Convolutional Neural Network (DCNN) is the most efficient and powerful technique by which different formats of images can be analyzed. The proposed THREE years project plan comprises the Brain stroke Neurologist and Neuro-Radiologist as the data team to support the domain knowledge of the brain diseases and respective clinical difficulties. Based on the advice of the doctors, we the Artificial Intelligence (AI) team would like to collect different formats of the retrospective image data through IRB license to analyze and design various prediction models using Deep Learning (DL). The objective of this proposal is to process and analyze the retrospective brain images using AI to design and establish the automatic outcome prediction models. In the 1st year of the plan, automatic classification and detection of the intracranial artery stenosis regions will be done by analyzing the MRA images of ICAS using DL. Besides, quantification of the stenosis region will be modeled in this year. In the 2nd year, retrospective DSA and NCCT image data of the Cerebral Aneurysm will be analyzed for classification of the intracranial hemorrhage (ICH) and subarachnoid hemorrhage (SAH) patients. Automatic prediction of SAH risk in un-ruptured cerebral aneurysm patients will be modeled using Deep Convolutional Neural Network. In the 3rd year, automatic localization models for ischemic and hemorrhagic stroke regions will be designed. Automatic prediction of ischemic stroke onset time and determination of hematoma progression models will be designed in this plan. All images and clinical data will be analyzed using Deep Convolutional Neural Network in TensorFlow, Keras and OpenCV frameworks and Alexnet, VGG 16, ResNet 50 and Inception V3 architecture. New trained models will be designed for the automatic localization and detection of the above mentioned neurological diseases by modifying the hidden layers."
"Deep Learning, Semantic Segmentation, Convolutional Neural Networks, Floor Plan Cognition","Architects can easily and intuitively identify each piece of information in the floor plan with pure geometric figures without any additional labeling, and can point out the names of possible space functions. Taking a house as an example, you can recognize the living room just by looking at the plan. What is a restaurant? What is a bathroom? What is a bedroom? How is this identification done? One of the most critical and basic abilities of architectural design professional cognition, spatial cognition is also the most important part of architectural professional education, whether it is spatial geometry (such as scale, proportion, layout, organization ...) or the function of space (Such as function names, formal meanings, cultural implicit letters, social connections, etc.) all reflect the instinct of the architectural profession, that is, the production operation of the architectural professional design, especially the graphic design drawings, which are the most important and critical diagrams that they operate. One of the face types. The theory of this study includes deep learning (DL), semantic segmentation (SS) convolutional neural networks (CNN), and architectural design plane cognition. The overall expected research projects and results, the first year is: Semantic segmentation deep learning and convolutional neural network related literature data collection and arrangement, building and housing design plane empirical data and related program systems or web search, construction of related collection of house design plane identification Basic database of spatial objects, deduction of program model for construction and design of residential building plane identification system, convolutional neural network architecture for semantic segmentation of identification system, derivation and establishment of identification system program system analysis and program compilation, prototype of building residential design plane identification system platform Construction. The second year is: the exploration of the relationship between the spatial objects of plane identification and their semantic attribute rules, the modification and expansion of the identification system platform, the verification and verification of the effectiveness and accuracy of the identification system platform, the verification and verification of the application performance of the identification system, and the automation benefits Appraisal, design of building and housing design plane identification system in the creative expression of design automation concepts, etc. The results can be used as reference for space professionals' research, teaching topics and design strategies."
"Pavement Performance Forecasting, Mechanistic Empirical Pavement Design Guide, Deep Learning, and Pavement Overlay Design","Highways are an important structure of civil engineering infrastructure. Pavement roughness and safety are also the focus of public attention on public finances. The competent authority has always hoped to achieve the results of optimizing the expenditure of the paving project budget and the long-term use efficiency. But long-term performance prediction of overlay asphalt concrete on flexible and rigid pavements has always confused for many highway scholars and experts. Many literature have problems for non-localized data, insufficient parameters and insufficient prediction accuracy. Poor long-term performance predictions make it difficult to achieve the goal of life-cycle performance management. Therefore, this research proposes a framework that combines mechanical empirical pavement design methods with deep learning. This framework can analyze the long-term performance prediction model of roughness, rutting and fatigue cracks for overlay pavement. The model considers important parameters such as the structure of the overlay structure, inter-layer adhesion, load and environment, and uses algorithms such as finite element method, generative adversarial network, and entropy-long short-term memory network to improve the prediction accuracy of the research problem. The research results include (1) increasing the effectiveness of paving effectiveness prediction samples and effectiveness, (2) constructing deep learning pavement effectiveness prediction models, and (3) empirical application analysis effectiveness evaluation. The results can not only academically promote the new development of the overlay pavement aging model, strengthen the cross-domain integration benefits of pavement engineering and artificial intelligence, and increase the development of paving technology, but also reduce maintenance costs and extend use efficiency in Taiwan and outlying islands road projects."
"Plankton Algae, Pseudococcus, Image Signal Recognition, Image Signal Counting, Deep Learning, Label","As a working woman who has lived in Penghu for a long time, I have experienced by myself that fish products in the market have gradually decreased, fish prices are getting more and more expensive, and there is a problem when purchasing aquatic products, that is, how to pick fresh aquatic products?Plankton algae is an important primary producer in the water ecosystem. Most of the Pseudococcus is provided to feed rotifers. How many Pseudococcus are fed to rotifers? People need to continuously adjust the focus of microscope to count the number of planktonic algae. I learned from the breeding teacher that this part of the breeding is time-consuming and labor-intensive, so this step is generally omitted by farmers.In the technology part, the success of AlphaGO has led to the advent of artificial intelligence technology. If we can cooperate across fields from the perspective of artificial intelligence, complete the image recognition and counting system, and design an app that can recognize the freshness of aquatic products, and provide this application Used by farmers and consumers.In the first year, the system captures image signals through an electron microscope, collects a large amount of data, and then labels the image photos of Pseudococcus. After labeling, the model training is started until the best parameters are found. It can obtain the accurate number of Pseudococcus, improve the efficiency of aquaculture work and greatly reduce the labor cost, and complete a set of image recognition and counting systems.In the second year, it is planned to classify the freshness of aquatic products into several levels, and determine the degree of freshness through artificial intelligence. Instead of only the difference between fresh and non-fresh, consumers only need to use the APP application software takes pictures of aquatic products, uploads images to the cloud database through the system, and performs model tests through the cloud database. The system then returns freshness indicators to APP users, so that consumers can clearly know the freshness when purchasing aquatic products, without the need to select fish by intuition, complete a set of aquatic freshness discrimination."
"deep learning, intelligent surveillance, abnormal event, blockchain, intelligent aquaculture","Fish is an island country’s important source of income, and also another main source which provides people with the animalistic protein. Ocean fishing has gradually been replaced by ocean farming (or aquaculture) because of the decrease in wild fish stock and water pollution. However, fish aquaculture is a job of high cost of manpower, electricity, water, and feed requirements, which has led to raise aquaculture operating costs and then cause the decline in revenue, thus the development of the aquaculture has further been limited. Therefore, the intelligent aquaculture is a potential, prospect and worthy research work. The proposed “Research on intelligent surveillance of abnormal events in aquaculture fields based on deep learning” is a three-year project, and its main aim is the technology of deep learning and visual surveillance used to solve the problems of intelligent surveillance in aquaculture fields in order to reduce cost of manpower and obtain real-time monitoring. Therefore, the result of the proposed research is an important part of the intelligent aquaculture. The first year of the project is mainly focused on the detection of abnormal events in aquaculture fields using proposed two-stream convolutional network based on R(2+1)D. Then, the supervised learning classification for recognition of abnormal events based on collaborative trajectory images is proposed in the second year of the project and used on the obtained abnormal events from the first year project. In the third year of the project, the proposed methods in last two years are integrated and further optimized to build the alarm system, and then only abnormal events using blockchain technology are stored to greatly reduce storage requirement of videos. The proposed project is the cross-domain integration of Information Engineering and Aquaculture, and it is also a combination of different properties. The proposed research is a practical application project. Overall, the proposed project is great practical and helpful for the aquaculture. Therefore, the proposed research is an important project with high research value."
"Deep Learning, Multimodal Images Fusion, Object Tracking, Image Caption, Intelligent Surveillance System","Video surveillance technology has become an important part of the security protection system of smart campuses. With the development of pattern recognition algorithms, computer vision technology has become one of the key technology of target detection and target tracking of video surveillance systems in recent years. Especially after the popularization of the unmanned aerial vehicles (UAVs), the UAVs can significantly reduce the blind angle of the existing video surveillance system. However, capturing of aerial images is limited by image shaking, smaller target, and complex background interference. Furthermore, effectively integrating aerial images with ground images remains a difficult task. If the multi-modal images fusion problem can be solved using machine learning and deep learning, target tracking performance of surveillance systems will be greatly improved. In addition, although warning message can be automatically sent out in existing video surveillance systems, the information received by the monitoring interface causes an overload of information in increasingly complex environments. The judgment of most of the false alarm messages requires on-duty security to confirm and to have consecutive effects to prioritize truly dangerous events on field. Hence, in this project, machine learning and deep learning are applied to solve the problems of multi-modal image fusion and heterogeneous information fusing problems with image caption model for applications to security systems. Furthermore, a new generation of video surveillance systems is proposed. The proposed system will effectively assist security personnel in managing security vulnerabilities on monitors. With development of the new generation of intelligent surveillance system, we believe that security detection can progress from ""passive detection"" to ""active prevention"". In other words, the new generation systems can be progressed from ""post-allocation managing"" to ""on-time processing"" and even to ""pre-prediction warnings""."
"KD-WMN, Self-configuration, Artificial intelligence, Deep Learning","This project will study the intelligent self-configuration mechanism of KD-WMN (Knowledge Defined Wireless Mesh Network) based on deep learning when the network topology is quickly change. The KD-WMN nodes make smart decision according to output from the training model of deep learning algorithm, then fast re-setup a well network topology to keep its transmission performance. The fundamental architecture of this project is working on the deep learning platform in order to propose the mechanisms about intelligent routing and transmission issues of KD-WMN when its topology was changed; then the study will focus on the intelligent handoff and dynamic path assignment for big data in high-speed transmission environment under topology change very fast condition. The project describes its developing plan of related models and mechanisms in integration, and uses the multimedia transmission service in heterogeneous and fairness requirement as study object. It will propose the intelligent mechanisms for dynamically managing class-queues and adaptive routing service. The project leader had many good experiences on above issues in the last years, he expects to continuously study them in advance by this project. The project propose three advanced principles in the fast topology variation KD-WDM: (1) Intelligent routing structure. The packet loss rate, bandwidth requirement and delay constrain are important to the quality of services here. The project will offer a platform of deep learning to the research of network topology in neural network model construction, offer the intelligent routing algorithms of KD-WMN to improve whole system transmission efficiency (2) Intelligent transmission mechanism. In fast topology variation, the optimal route allocation is very important. The topological characteristics of transmission environment will be studied by artificial intelligence algorithms to propose an intelligent transmission mechanism to get probing period and reducing TCAM memory space. (3) Intelligent high-speed transmission. Packets are transmitted according to the optimal routing algorithm, then concentrated at some relay nodes; it makes load unbalance problem. This phenomenon is serious especially when the transmission rate is increase rapidly. These topics should need to reconsider and studied again."
"Smartphone Cover Glass, Defect Inspection, Deep Learning, Convolutional Neural Network, Automated Optical Inspection","Due to the rapid development of mobile networks and mobile phones, the mobile phone cover glass has become more and more important recent years. The characteristics of scratch resistance, high transmittance, high strength and water proof make glass become the first choice of smartphone cover material. In orderto improve the quality of smartphones, surface defect inspection of mobile cover glass is important. In this study, we will focus on automatic smartphone cover glass surface defect inspection based on deep learning technology. Automatic optical inspection (AOI) is the most commonly used method in cover glass defect detection. This method is carried out manually by experienced inspectors to tune the parameters of image processing techniques. Constantly adjusting the parameters is a time-consuming and tiresome task. Moreover, the parameter variables are highly sensitive to production environment, leading to high overkill (potential good units being killed) or high underkill (potential bad units escaping). The detection error or misjudgments could reach up to 10% or more. To overcome the challenges, we will propose a deep architecture of convolutional neural network (CNN) to detect cover glass defects and distinguish them into different types.CNN methodology will be applied to automatically extract phone cover glass defects. In the first year, we will focus on glass image preprocessing, including raw images collection and defect classification. Raw images will be taken by a high resolution optical system. Then we will construct CNN models specifically for cover glass defect detection. In the second year, image enhancing techniques will be introduced to enhance the effectiveness of identification process. Then, CNN models will be imported, such as AlexNet, GoogleNet, VGG and ResNet. Various frameworks will also be compared. Based on the CNN models and various frameworks, we will create a cover glass inspection software with Python. In the third year, we will verify the established model and build a full system including software components and hardware components. In this research, we aim at improving the recognition of the existing visual technology, boosting the defect types identification, and enhancing the recognition accuracy and efficiency."
"Fastener, Internal thread, Convolution Neural Network(CNN ), AI deep learning","This project mainly focuses on the development and application of Convolution Neural Network(CNN ) of AI deep learning technique to the internal thread measurement of misaligned fastener. The integrations of optical hardware system and software platform system are included. It is similar to upgrade the conventional optical inspection machine, not only in the hardware but also in the software system platform. In the hardware part of machine vision, the system is capable to capture the image of internal thread of the fastener. For the software platform system, the Convolution Neural Network of deep learning is applied to detect and determine the defect or flaw of the internal thread of the fastener. Due to the regulation and request, the fasteners for automotive industry mostly require a full 100% of quality control inspection. The conventional optical inspection machine is unable to meet the efficiency of full 100% of quality control inspection due to the time consuming and also it has difficulty to detect and determine the defect or flaw easily. The reason we propose this project is given rise to the project of competence promotion of Kaohsiung Renwu and Yanan industrial park supported by ministry of economic affairs. After interviewing more than 50 fastener manufacturers, we find that one of their common needs is to upgrade their inspection facility in order to satisfy the request of full 100% of quality control in the future. The improvement of internal thread of misaligned fastener in inspection is just one of their special needs.  Therefore, to find out an efficient and effective inspection technique becomes extremely important and that is the main purpose of this project for."
"Image Creation, Artificial Intelligence, Deep Learning, Unsupervised Learning, Generative Adversarial Networks","Image generation based on artificial intelligence is one of the topics that have been widely discussed in the field of computer science in recent years. In this project, a framework that can automatically create cartoon images with small training datasets is proposed. The proposed system performs region segmentation and learns a region relationship tree from each learning image. The segmented regions are clustered automatically with an enhanced clustering mechanism with no prior knowledge of number of clusters. According to the topology represented by region relationship tree and clustering results, the regions are reassembled to create new images. A swarm intelligence optimization procedure is designed to coordinate the regions to the optimized sizes and positions in the created image. Rigid deformation using moving least squares is performed on the regions to generate more variety for created images. Compared with methods based on Generative Adversarial Networks, the proposed framework can create better images with limited computation resources and a very small amount of training samples. Furthermore, the proposed method can be applied to perform data augmentation for Generative Adversarial Networks to enhance the quality of generated images."
"machine learning, deep learning, multi-axis robotic arm, multi-dimension object recognition, recurrent learning, long-term short-term memory, reinforcement learning","Grabbing and moving a physical object is the necessary action of all intelligent applications. Hence, a smart and autonomous robotic arm that can help move objects for humans is the essential role in this scenario. Such a robotic arm needs to detect, recognize, and understand the objects to be gripped, and needs to decide how to drive all servos to complete the movement mission. The project is to explore how deep learning techniques can be integrated with multi-axis robotic arms for the recognition of various type of objects and the decision of servos control of movement. We configured a two-year project. However, only the first part has been granted by MOST (108-2218-E-390-017). The second part of the project, various types of object images associated with their gripping positions are modeled and multiple image sources are fused. The arm is expected to detect, recognize, and decide the gripping position even for the objects that are not seen. Then, deep recurrent learning and deep reinforcement learning are integrated for learning moving sequences of various types and sizes of objects. Such moving sequences are optimized and embedded in the loop of servo control for driving the robotic arms. With the techniques developed in this projects, smart robotic arms can be implemented. We demand a one-year grant from MOST for complete the development of the intelligent robotic arms."
"Deep Learning, Intelligent Manufacturing, Defect detection, Polarizer, Industry 4.0","The recent rise in the efficiency of the Internet of Things, cloud computing, mobile communications and machine computing has promoted the rise of the Smart industry. Smart industry refers to industries with higher digitization, networking, informatization, automation, and intelligence. Smart industry is a smart and technology-intensive industry. This project uses the defect detection of polarizers as an example, because human resources are limited, if you manually identify defects, it will greatly increase costs.Artificial intelligence has made major breakthroughs in recent years. Machine learning is a method to realize artificial intelligence. In recent years, because of the increase in machine processing speed and the development of big data, machine learning can have more applications. With the improvement of machine computing performance, neural networks can be trained faster, and more layers of neural networks can be used, so they are also called deep neural networks.Therefore, this study proposes a relatively novel regional convolutional neural network, which can not only detect whether the product is defective, but also find the location of the defect, and adjust the parameters of the machine in real time through the long-term and short-term memory model. Real-time correction can greatly increase the yield rate and reduce labor costs and wastage costs."
"stock prediction, data mining, deep learning, natural language processing, image processing, ensemble learning","Stock prediction is one important research problem of applying information technology in financial applications. In general, the conventional approach is usually based on some fundamental and technical analysis methods to analyze and forecast stock process. Recently, text mining has been shown its potential in improving the performance of stock prediction models. In particular, it is based on performing the natural language processing step to extract related textual features from web-based financial news articles for constructing the prediction models. On the other hand, deep learning techniques, which were originally proposed to solve computer vision problems, have been used for text and time series data domain problems. For stock prediction, some related studies have considered deep learning techniques to learn financial news articles and stock charts. However, financial news collected from different web sources or platforms can lead to different textual feature representations, so that the prediction models can perform differently. Therefore, the aim of the first year research is to examine the effect of using financial news collected from different online sources on the performances of different prediction models based on supervised learning classifiers and deep learning networks. For the second year research, related low-level image features are extracted from the stock charts where supervised learning classifiers and deep learning networks are trained and tested for performance comparison. Finally, the aim of the third year research is to employ the ensemble learning technique to construct multi-modal prediction models based on technical indicators, textual features, and image features in order to find out the best combination of multiple prediction models."
"recommendation systems,deep learning,review texts,explanation generation for recommendations","A recommendation system is designed to search for products or services that customers may be interested in based on customer preferences, needs, and past purchasing behavior. Many people use recommendation systems in their daily lives, such as shopping online, reading articles, or watching videos. Many important methods used in recommendation systems are based on collaborative filtering technology. Although collaborative filtering technology has shown good results in many applications, data sparseness is still one of its main challenges. Recently, one of the methods for solving the problem of data lack is to use the semantic information described in the review texts. Many research results have shown that the use of review texts can improve the prediction accuracy of the recommendation system, especially for the items and users with few scoring records. Moreover, deep learning technology has gradually been used in recommendation systems, and some studies have used review texts as the input features of users and items. However, the previous studies have not discussed the impact of time information and the sparsity of user reviews. Besides, the predictive effectiveness of these methods on a Chinese shopping site is also worth studying. Accordingly, this study will focus on how to extract the semantic information from the review texts for product recommendation. The combination of various deep learning frameworks for user/item embedding learning and latent feature extraction from review texts will be explored. We will also study the following research topics in depth: 1) Product recommendation by applying time information of reviews; 2) Strategies for solving the sparsity problem of review texts; 3) Automatic generation of natural language explanations for recommendations; 4) Performance evaluation of the proposed methods and feasibility analysis for a shopping website with Chinese reviews."
"deep learning, emotion recognition, affective computing, Electroencephalography, convolution neural network, Artificial intelligence, Intelligent home-based health-care, Artificial Intelligence chip","Recently, with the rapid development of technology, the circulation of information is increasingly widespread. In the era of information overload, modern people are under great stress due to frequent international competitions. In this situation, mental illnesses that unconsciously outbreak would cause the irreparable tragedies. Hence, the understanding of the own psychological state in time is getting increasingly important. If the patient can realize that he(she) is under negative emotional status at home, he(she) would be able to perform the bio-neuro-feedback exercise to relieve himself(herself) immediately. The family or nurse can also take care of the patient as soon as possible. Furthermore, the long-term information could be presented to the psychologist as the reference. Hence, this project intends to present a portable and deep learning-based affective computing system using the EEG signal. The system can measure EEG and detect the current emotion in real-time. It can be the aid of the diagnosis and take part in the psychotherapy. Moreover, the patient could immediately perform mental accommodation during the outbreak of mental illness by bringing the system home. Achieve home-based mental status monitoring and health care.    The project aims to develop the methodology of cross-subject emotion recognition using the EEG signal and deep learning algorithm. Combining with the implementation of the System on Chip (SoC), we integrate the deep learning model and the related signal processing units into a portable and low-power AISoC platform. The computing platform includes the EEG pre-processing unit, fast Fourier transform unit, deep learning accelerator, and the Bluetooth transmission module. It could perform real-time EEG signal acquisition, processing and Artificial Intelligence (AI) for decision making. The physiological parameters and the emotional status would be transmitted to the smartphone or the personal computer for the GUI display. Finally, the neuro-feedback module on the GUI could help the patient stay healthy physiologically. Except for the acquisition and analysis of the edge information, the system could be able to connect with the cloud database, achieving the objective of real-time and long-term home-based mental status monitoring and health care."
"Deep Learning, Online Vision-based Human Action Recognition System, Mobile Robots, Human Action Analysis, Computer Vision.","The traditional offline vision-based human action recognition techniques can only recognize human actions obtained from stationary camera and output the recognition results after the human action completely finished. Therefore, this kind of techniques are suitable for the fixed robots with stationary cameras, not for the mobile robots with moving cameras. Thus, to develop a vision-based online human action recognition system for mobile robots is an important issue recently since these robots become more and more popular. To recognize the human actions in the videos obtained from the vision system of mobile robots is more difficult than that from the vision system of the fixed robots. However, to overcome this challenge is necessary and worthy. Therefore, this proposal hopes to develop a vision-based online human action recognition system using deep learning techniques for smart mobile robots. This study follows the previous studies, development of a vision-based human action recognition system for companion robots (MOST 106-2221-E-003-034; MOST 108-2221-E-003-015), and focuses on the development of an online system which can improve the ability of human action recognition.Compare with the traditional offline vision-based human action recognition systems, the proposed online system should solve some difficult problems. First, the background always changes since the robot is in motion. Second, vibration reduction and image stabilization should be involved in the system because the robot waddles. Third, the viewpoints of the mobile robot are various when recognizing the human actions. Finally, the online system should output the recognition results as soon as possible even the human actions are not completely finished. In summary, a vision-based online human action recognition system using deep learning techniques for smart mobile robots will be developed in this study. We hope the vision ability of mobile robots will be improved greatly in the future."
"Non-intrusive load monitoring (NILM), Anomaly detection, Demand response, Deep learning, Reinforcement learning","The development of the smart grid has enabled energy information to exchange between power generators and consumers via the Internet, which makes the improvement of the energy efficiency possible. The smart meters can provide demand response and appliances control through the power information to optimize the energy efficiency. In this research, we propose to develop the optimal strategy for the energy management systems (HEMS) used in smart homes and factories based on deep learning and reinforcement learning. Three key technologies are proposed to address the challenges in non-intrusive load monitoring (NILM) and demand response (DR) issues. In the first year plan, we perform the energy disaggregation to identify specific electrical appliances. To achieve this goal, we propose to use a hybrid training process in order to derive a better deep neural network model to identify various appliances and their abnormal behaviors. The Adam descent gradient method and Meta-Heuristic hyper-empirical algorithm are used iteratively to achieve a faster and robust deep neural network convergence (Key Tech. 1). In the second year plan, a novel Soft Actor-Critic reinforcement learning algorithm is applied on the demand response in HEMS to provide real-time scheduling optimization for appliances control (Key Tech. 2). In the third year plan, we apply the federal learning framework and homomorphic encryption algorithm to derive a high effective deep learning model collaboratively while preserving patient’s privacy at the same time (Key Tech. 3)."
"machine tools, smart machines, fixtures, 3D object detection, collision avoidance, computer-aided design, finite element method, mesh, point clouds, deep learning, stereo cameras, semantic segmentation","How to improve the intelligence of current machine tools is critical, because smart machines are the basis of smart manufacturing, which is the trend of industrial development. Before the machine tool starts machining, the fixture, workpiece, tool holder and tool must be set up on the machine. At present, we need to manually input the information and related files into the machine tool controller correctly to ensure the correctness of subsequent processing. It is not possible to know whether the input information is correct except by manual check. The objective of this research is to develop the techniques to automatically detect the type and location of the fixture installed on the machine so that this information can be correctly input to the machine tool controller to avoid machine collisions. Also, the actual shape of the semi-finished product can be obtained to compare to the ideal shape in multiple processes to ensure the completion of each process.	To detect the type and location of the fixture simultaneously, we first use a computer-aided design (CAD) model of the fixture and use the finite element method's mesh generation function to generate a 3D point cloud to construct a deep learning model for the fixture. The point cloud for training can be quickly generated by only using software, which is the key to this research. Then we use the RGBD stereo camera to capture the 3D image inside the CNC machine and make semantic segmentation to get the type and location of the fixture. At the same time, we can also obtain a three-dimensional image of the workpiece for comparison with its ideal shape.	After the completion of this project, the intelligence and added value of machine tools can be significantly enhanced to ensure safety during machining. This three-dimensional object detection technology can also be applied to areas such as a robotic arm picking and classifying objects, which is highly practical."
"Multi-omics data, integrative analysis, automatic analysis pipeline, deep learning, disease prediction, complex disease","Complex diseases such as Alzheimer's disease, hypertension and diabetes are caused by multiple factors such as the joint effects of multiple genes, gene-gene interactions, epigenetics, environments, and gene-environmental interactions. Hence, to understand the complex disease mechanisms, it is necessary to consider data from difference sources and jointly consider their effects on the disease. Due to the advance of the next-generation sequencing technology, many high-throughput omics data (e.g., genomic, epigenomics and transcriptomic sequencing data) are rapidly generated. This provides the researchers the opportunity to study the effects of these multiple types of omics data on the complex disease. This can be achieved by performing an integrative multi-omics data analysis by jointly considering the effects of multiple types of omics data on the disease. Deep neural network (NN) has become an attractive approach to integrating multi-omics data. Several deep NN-based multi-omics analysis methods have been proposed. However, two major challenges are faced in deep NN to analyze the multi-omics data: data dimensionality and data complexity. The dimensionality of the multi-omics data is typically large, which can include millions of features. Furthermore, different types of omics data exhibit different data distributions, and it is not straightforward to combine them into a single matrix. Hence, how to perform dimensionality reduction from a large scale multi-omics data and transform different types of omics data to the same scale become an important issue for developing the multi-omics analysis methods using deep NN. As more and more multi-omics data are available, it is essential to have an efficient pipeline to process the data. Based on the deep NN algorithms that will be developed by our group, we will implement them into an efficient multi-omics data analysis pipeline. Dimensionality reduction and data transformation will be automatically performed in the pipeline, followed by deep NN modeling. The pipeline will be very helpful for performing the complicated tasks of multi-omics data analysis."
"Image forgery detection, Image tampering detection, Deep learning, Generative Adversarial Network, image splicing, copy-move, image inpainting","The history of image manipulation is almost as long as the invention of photography itself. With rapid advances in digital photography, post-processing and even malicious editing now require little expertise and extremely low cost. Coupled with the prevalence of social media networks, misinformation containing manipulated photos floated around unobstructedly. Effective detection of image forgery or tampering has thus become an issue of grave concern for many administrations around the globe.The motives behind image manipulation range from simple enhancement (to improve photo quality with filtering, contrast stretching, or noise removal) to delicate content modification (to create false information with splicing, cloning or inpainting), with an abundant of methodologies available nowadays. This project delineates these two major types of image manipulation and investigates state-of-the-art technologies for coping with these alternation methods.  Specifically, we will survey and evaluate latest developments in content-based image tampering detection methods without the presence of metadata. The assessment will be centered on domain adaptation and the ability to handle composite manipulations. Based on the results of extensive evaluation, we will propose a deep neural network to effectively address the limitations of current approaches, and train a more robust model to detect and localize malicious image tampering regions."
"polymerase chain reaction, primer annotation, AI primer design, deep learning, convolutional neural network","Polymerase Chain Reaction (PCR) is the most widely used and indispensable technology in biological and medical laboratories. Before performing a PCR experiment, a suitable primer set must be designed to efficiently amplify a specific DNA fragment. Many primer design methods have been proposed in the literature are all based on the primer constraints. The design method relies too much on the parameter setting of the calculation method and the primer constraint parameters of the PCR experience of researchers. Therefore, the designed primers by different experimenters for the same calculation method cannot completely meet the needs of PCR experiments, and it is easy to cause waste of experimental consumables, time and costs. In view of the global artificial intelligence (AI) deep learning technology successful cases, coupled with the fact that there is no scholars to propose AI deep learning technology for the research and development of PCR primer design fields, and in view of our long-term deep research on PCR primer design related topics and rich experience of primer design algorithms, the three-year research project is proposed. The project is proposed to develop an innovative primer design method and system based on AI deep learning technology to intelligently design feasible primers based on experimental requirements, avoiding excessively dependent on the parameter settings of the primer design method and the primer constraint parameters to ensure that the designed primers by researchers are effectively and successfully used in PCR experiments. First year, three kinds of primers and PCR experiment data collection methods were planned to collect available PCR primers and experimental data, including (1) computational intelligence-based primer design method developed by our previous study to provide primer simulated data and development of automation annotation program for primer information; (2) construction and provision of a friendly user interface and complete PCR primer and experimental data collection and annotation system; (3) development of literature extraction and data mining program automated collection of PCR primers and results. Second year, a convolutional neural network (CNN) is proposed to establish a deep learning model for primer design. BLAST alignment via PCR primers to obtain a DNA sequence template, and one-Hot coding sequence matrix conversion of the DNA sequence template and PCR primers as inputs, and the meanings annotated by the PCR primers and experimental database provided in the first year, through deep learning to understand the characteristics of these DNA sequence templates and establish a reliable and robust PCR primer design deep learning model. This year focuses on the establishment, training, inference and improvement of deep learning networks and models. Third year, combined with the results of the PCR primer and experimental data collection and annotation system established in the first year and the PCR specific primer design deep learning model in the second year, and integrated with the sequence, gene, drug and disease association databases to provide DNA sequence templates, genetic information, drug-related information, and disease-related information and functions to researchers to achieve the world’s first systematic analysis platform for AI specific primer design."
"Indoor positioning, deep learning, object detection, mobile devices, location-based services.","Global Navigation Satellite System (GNSS) provides people convenient positioning services, such as navigation systems, intelligent transportations, and Location-Based Services (LBSs), but when the signal is blocked, how to continue to provide accurate indoor positioning services is a big challenge. In the past, indoor positioning technology mainly relied on Pedestrian Dead Reckoning (PDR) and wireless signal intersection, but it was easy to cause the problems such as error accumulation and signal interference. The positioning accuracy still needs to be improved greatly. Therefore, image-based positioning technology has become another direction of thinking. The main concept is to establish a field model containing images and coordinates, and determine the location by the feature extraction and matching. However, the huge amount of calculations makes the positioning effect unsatisfactory for real-time applications. In this project, we will develop a series of indoor positioning technologies and location-based services based on mobile devices and indoor environments, with deep learning as the core. First, we will develop automatic data collection technology to reduce the cost of field data collection, support scene simulation and enhance the diversity of data, and connect image object detection and pre-processing strategies. Next, we will design a new deep learning model. In addition to model training from images, we will also use the sensing features of mobile devices to assist the accuracy of the model, and improved training efficiency through transfer learning. Finally, the positioning technology will be transplanted to mobile devices, and the model simplification and extended applications of various location-based services will be discussed. We believe that accurate and stable indoor positioning technology will not only help promote smart services, but also the patent layout and market value derived from it. We expect this plan to produce highly innovative research results and industrial application values."
"deep learning, echocardiography, non-ST elevation myocardial infarction, infarct related artery","Cardiovascular diseases are the second major cause of mortality. Among them, acute coronary syndrome (ACS) is the most fatal and emergent. According to the elevation of ST segment, ACS is divided to three groups of ST elevation myocardial infarction, non-ST elevation myocardial infarction and unstable angina. Nevertheless, only small amount of patients with ST elevation myocardial infarction could be identified with infract related artery (IRA) at the acute stage based on electrocardiogram.Being aware of IRA helps physicians to set up the interventional strategies beforehand. Although echocardiography is widely applied in the clinical practice, the subtle regional wall motion abnormality (RWMA) in patients with ACS remains possibly being under-diagnosed even by the experienced cardiologist. Despite scant publications discussing RWMA post myocardial infarction, whether upon deep learning echocardiography could correctly identify IRA at the initial stage of non-ST elevation myocardial infarction is an unsolved issue. Therefore, through the comparison of echocardiography and coronary angiography, whether echocardiography could facilitate the early diagnosis of IRA using deep leaning is an important issue with clinical benefits. In this project, through the technique of 3D deep learning we aim to establish a system to spontaneously detect the subtle RWMA and further to identify IRA in patients with non-ST elevation myocardial infarction and unstable angina. Superior to previous deep learning models, this novel one combined several neural-networking from different fields, including Fully convolutional neural network、Fully connected neural network and DenseNet. With this niche, we expect the clinical unmet need could be complete. In this three year project, we aim to achieve the following aims,1.	To collect clinical data and establish an AI prototype of RWMA detection in echocardiography 2.	To train and to optimize the AI detection system 3.	To evaluate the accuracy and efficiency as applying this detection system into the Health Information System (HIS) Not only publications and patents, the result of this project could also facilitate setting up the clinical guideline in early and accurately detecting IRA which makes patients receiving the optimal therapies in a comprehensive preparation."
"Deep Learning, Artificial Intelligence, Defect Inspection, Digital Image Processing, Computer Vision","This is a three-year project to use computer vision and digital image processing methods to develop FuhKit, a deep learning and artificial intelligence machine vision defect inspection software that can be used in various manufacturing fields such as Printed Circuit Board (PCB). In the first year undergoing, we will research Single Image Analysis: to train and inspect defect features of each image. In the second year, we will research Image Comparison: to train and inspect defects by focusing on the differences between two images. We will also research Multi Image Analysis: to train and inspect defects by analyzing the correlations among various images. In the third year, we will research One Class Learning: to inspect defects by training only normal images without defect images. We will use Deep Learning, CNN (Convolutional Neural Network), and AI (Artificial Intelligence). We aim to research to achieve lower FAR (False Acceptance Rate) and FRR (False Rejection Rate). We also aim to break patent and technology barriers from United States, Korea, Germany, and Japan and enhance Taiwan Automatic Optical Inspection (AOI) system competitiveness and market share in global market."
"group activity recognition,  deep learning,  conditional random fields, self-attention mechanism","This project  investigates a novel  relational network comprised of three modules for group activity recognition. Our network first augments the conditional random field (CRF) with the self-attention mechanism to learn the temporal evolution  and spatial relational contexts of every actor, the latter of which are modeled by multiple cliques with different scales of locality to address the diversity of the actors’ relationships in group activities. Such a combination not only exploits the potent self-attention to infer both temporal evolution and spatial relations of all actors at various distances, but also has a faster convergence speed in inference. Afterward, a dynamic soft attention module is devised to fine-tune the generated relational information based on the relevancy of every actor to the group activities. Finally, a bidirectional universal transformer encoder  is utilized to aggregate the refined relational contexts and scene information for group activity recognition. Our pilot study shows that  the  proposed approach surpasses the state-of-the-art methods on the widespread Volleyball and Collective Activity datasets."
"Chronic disease, Healthcare, Deep learning, Big data, Dependable system, Modeling, Validation, Traditional Chinese Medicine, Multi-Platform Software, Image processing","Chronic disease management is the most expensive, fastest growing, and most intractable problem facing healthcare providers in every nation on Earth. Healthcare big data analytics has become an important and effective approach to help to solve the problems. Healthcare’s data isn’t just big, including patient medical history records, treatment data, and information coming from wearable health trackers and sensors. Everyone can benefit from the knowledge hidden in their personal dense dynamic data cloud — based on their genome, their microbiome, their medical history, extensive blood analysis of chemistries, proteins and metabolites, and even the daily input from fitness trackers and home scales. Analyzing and integrating these data will lead to actionable possibilities that will permit individuals to improve their wellness and avoid disease. Our project adopts P4 medicine model that is predictive, preventive, personalized, and participatory. It is able to identify the earliest markers of disease and reverse them before the disease can develop. With the support of P4 medical model, we can help patients change their behaviors and optimize their wellness. Together, these capabilities will prevent the development of many of the chronic conditions that ravaged our collective health and cost our system billions every year. We will be able to quantify, characterize, and address a given patient’s risk of certain chronic diseases. Our project proposes an effective dependable smart cloud computing platform, to support data collection, consolidation, modeling, analysis, deep learning, and validation for chronic disease health care.Our project includes four subprojects to construct the proposed system; subproject 1 is responsible for developing a service framework and middleware to maintain the QoS of service of the proposed smart health care system, subproject 2 is responsible for developing image analysis and deep learning technologic to support Chinese and western medicine in chronic disease. Developing related patient is the part of work of this sub-project. Subproject 3 is responsible for the big-data analysis of the Chinese medicine Tongue Characteristics and Ryodoraku in chronic illness patients, subproject 4 will collect medical data and providing doctors’ knowledge and validation on chronic kidney disease. By integrating these four subprojects, it can make this project successful."
"Non-destructive Measurement, Fruit Brix Level, Deep Learning, Convolutional Neural Networks, Transfer Learning","In this research project, we proposed to develop and implement a deep learning based non-destructive optical fruit sugar content measurement system on mobile devices, the consumer only need to install the App, without using an expensive professional sugar measurement equipment, choosing a tasteful fruit will be easy and comfortable. We proposed to build a training set which includes: apple, pear, grape, strawberry, tangerine, mango, orange, and peach. For each fruit, 12 pictures from 6 angles and 2 color temperatures are taken, and an environmental thermal compensated digital Brix meter is used for sugar content measurement as the ground truth. YOLOv3 and Mobile-YOLOv3 will be used for model training, and then, the reduced model will be porting to iOS/Android mobile devices. Transfer learning will also be used to improvement the training performance. We plan to apply the proposed scheme for fruit yield monitoring in the future."
"Computer Graphics, Deep Learning, Street Trees, Street View, Image Segmentation, Open Data","Street trees play an important role in improving environmental quality and representing the style of a city. However, it is very difficult to detect trees in arbitrary street images by using conventional image processing methods. In recent year, there are great advances in the field of image recognition by using Deep Learning. And at the same time, there are tremendous amount of street images available on Google Street View, which provides us a very rich source for training data collection. Moreover, many countries start promoting open data, especially for smart cities. Among these data, very useful information related to street trees are well documented with free access. 　　Therefore, in this research, we aim to use city open data to find relatively isolated trees, collect their images in urban areas around the world from Google Street View, use Deep Learning method to detect street trees, and finally perform tree growth assessment by calculating its relative pixel coverage. In addition, to alleviate the insufficiency of training data with labels, we developed a progressive refinement methodology for data augmentation. By adopting this methodology, not only the size of dataset can be expanded in a meaningful manner, but also the high cost for data expansion can be greatly reduced. The experiment results shown that our proposal has great potentials for automatically monitoring and managing street trees in smart cities."
"Deep learning, low density parity check code, impulse noise, iterative processing, approximate message passing, neural networks, clipping, orthogonal frequency division multiplexing, turbo principle","Emerging techniques from the design of iterative receivers for low density parity check (LDPC) coded orthogonal frequency division multiplex (OFDM) systems subject to multipath fading and non-Gaussian impulse noise are studied in this project. In particular, three different deep neural network (DNN) based architectures are launched. Assuming the statistics of all interfering sources, a standard fully connected neural network is designed to implement the optimal minimum mean square error (MMSE) estimators for both the OFDM symbol and the non-Gaussian noise. Moreover, capitalizing on the unitary property of the Fourier transform matrix, the DNN-based iterative receiver is devised to synergize those two estimators to enable the turbo principle, popularly known in the area of Bayesian learning, for system performance enhancement.Since DNNs are prone to rare adversarial perturbations, a clipping-featured receiver, lacking the statistical knowledge of interference, is proposed to simultaneously suppress the impulse noise and estimate the OFDM symbol by capitalizing on deep unfolding. Moreover, compared with the aforementioned data-driven DL based receiver, this model-driven DL based receiver boasts substantial reduction on the number of trainable parameters. The structure of the network is built upon an iterative optimization algorithm with a manageable objective function by obviating the demanding task such as estimating the statistics of impulse noise. With remarkable performance and sustainable complexity, the approximate message passing (AMP) algorithm is poised to be adapted to another deep unfolding composed of two neural networks: AMP-Est and AMP-Det. While AMP-Est is responsible for impulse noise estimation and AMP-Det for the OFDM signal detection, this project will exploit a synergy of these two networks to facilitate the turbo principle. Finally, the soft output information of the OFDM symbol (from each of the three above described receivers) will be fed into the LDPC decoder for data recovery. Computer simulations will be extensively conducted to verify the validity of the proposed DL based receiver designs and to compare accuracy and runtime complexity with conventional counterparts."
"distributed deep learning, efficient and adaptive communication, model compression and parameter elimination, data consistency model, server-client cooperative learning.","Large neural networks need to be trained with large amount of data, or the model will be easily overfitting. As a result, we need a large and powerful computer system to train such a large network and store the tremendous size of training data. This is not possible to be done on a single machine due to its limited storage size and computing capability. Therefore, we need a distributed system to train the network in parallel in order to build intelligence model.To perform the training in a distributed manner, we need a parameter server to share, store and process the model parameters. The efficiency and scalability of a parameter server become the keys in distributed learning. To develop an efficient and scalable parameter server, we need address several issues. First, distributed learning needs parameters to be transferred and shared between the workers and the parameter server. Due to the large size of parameter data, the network bandwidth is likely to become the bottleneck. Therefore, the data need to be transferred in an efficient way. Second, the parameter server need to be scalable for training large networks. The read/write congestion have to be eliminated easily by adding more nodes into the parameter server. Third, as the parameter server to be large-scale and distributed, it needs to be fault tolerant to achieve data reliability. Fourth, the parameter server has to provide flexible consistency model for the applications, so that the developers are able to balance the system efficiency and algorithm convergence. Finally, the server may benefit from a server-client cooperative learning technique to improve the model accuracy.In our previous project, we developed a scalable and efficient parameter server to enable large-scale and distributed deep learning by addressing the abovementioned issues. We designed a novel two-layer architecture for the parameter server. The proposed architecture facilitates addressing several design challenges in our system, including efficient communication, scalability, flexible consistency model, fault tolerance and integrability. The results have been published in IEEE Big Data 2018, IEEE ICPADS 2018, IEEE ICNCC 2018, ICPP 2019, and CANDAR 2018, and won the CANDAR2018 Outstanding Paper Award. Because of the good results we have achieved, we plan to continue and expand our research on this topic. In this project, we propose several techniques to make our system efficient and scalable: (1) a structure-aware I/O scheduling algorithm to manage the parameters transmission according to the computation dependency, (2) a flow-based approach for balanced data transmission, (3) a client-side cache to compress and eliminate data, (4) range push and pull to reduce communication overhead, (5) flexible consistency model, (6) re-computation and replication for fault tolerance, and (7) server-client cooperative learning for increasing model accuracy. We aim to develop a high-performance parameter server which can be easily integrated with existing deep learning systems, such as Tensorflow, Caffe, and enhance their efficiency and scalability. We will use two real-world applications to demonstrate the effectiveness of our proposed parameter server."
"brain atlas, multiscale neuroimages, image classification, connectome, brain network construction, unsupervised deep learning, complex network","In this project, we will develop an algorithm combined the unsupervised deep-learning and the complex network theory. The algorithm can extract the morphological features of neuroimages in multiple scales, and classify the image types according to the features. The algorithm can be applied on various brain sizes, from Drosophila melanogaster to mammals and different modalities of imaging including fluorescent confocal microscopy, X-ray tomography, and electron microscopy. At the largest scale, the mammalian brains, we can classify and label brain regions according to the morphological features extracted from the images by our algorithm. At the smaller scale of single neuron images, we will classify the cell types of neurons according to their morphology and innervation type. Since neurons with similar shape and position usually perform the same functions, we can construct a much simpler but representative enough network of the whole brain by one neuron for each cell type for further structural and functional analysis. At even smaller scale, we can classify and label the compartments of a neuron. Basic building blocks of neurons can be identified in this procedure. With the neuronal compartment classification, neuron structure can be disassembled as LEGO blocks and represented by a “assembling manual” of building block list and assembling instruction. At the smallest scale, synapses and organelles can be automatically identified. After the analysis and labelling for multiscale neuroimages, we can build a Google Earth-like brain atlas (at least partially) as a base for further functional analysis and simulation."
"sepsis, biomarker, clinical prediction rule, emergency department, unsupervised learning, cohort study, procalcitonin, c-reactive protein, causal relationship, recursive partitioning algorithm, random forest, risk factor, machine learning, artificial intelligence, deep learning, therapy responsiveness, heart rate variability","The definition of sepsis was re-defined in 2016 to replace the previous “severe sepsis” to increase the prognostic accuracy. However, the incidence and mortality of sepsis did not change significantly since the last decade in Taiwan and the world. The challenge can partly explain the difficulty of predicting the outcomes of therapy for patients with clinically suspected sepsis, despite the current advancement of machine learning and deep learning. Furthermore, researchers are unsatisfactory of merely predicting inevitable outcomes such as mortality and turning to prognosticate patient-centered outcomes such as shock development and responsiveness to therapy. With non-invasive monitoring widely available and affordable during the past few years, hemodynamics and the heart rate variability monitoring becomes possible in front-line health-care settings such as emergency departments. Sepsis, as a disorder widely influence the immunologic and cardiovascular system vias the sympathetic nervous system in the human body, could be monitored via different analysis domains of the heart rate variability motoring. Many researchers have proved the concepts of early detection of septic shock by monitoring the heart rate variability; however, larger studies are still merited to translate the concept to the bedside further. In the meantime, many artificial intelligence and machine learning algorithms, such as recursive partitioning algorithms, support vector machines, and deep learning, are now well developed and can be easily implemented. However, to take advantage of the deep learning algorithms, many researchers now propose utilizing image transformation before applying these algorithms. Furthermore, different fine-tuninig methods such as imbalance data management, modeling in subgroups, and incorporation with unsupervised learning are believed to improve the performance of these prediction models.  In this study, we plan to start a three-part serial study to develop a forecast model of sepsis: 1) a 14-year comprehensive longitudinal retrospective sepsis cohort from the Chang Gung Research Database in all branches in Chang Gung Memorial Hospital to compare the effectiveness of the current clinical practice and biomarkers; 2) a prospective one thousand heart rate variability of sepsis (1KHS) project to evaluate the performance of heart rate variability parameters, focused blood-derived biomarkers, hemodynamics and echocardiography via point-of-care ultrasound to validate the importance of time course in these biomarker in forecasting the patient-centered outcomes including development of sepsis and septic shock and responsiveness to therapy during hospitalization; and 3)  To develop different machine learning and deep learning-based forecast models based on different subgroups of patients, including stages of sepsis and phenotypes obtained via unsupervised learning. We anticipate this project to initiate a comprehensive understanding of the interaction between sympathetic nerve system, inflammation, and sepsis progression for different subgroups of patients. We also anticipate this project to bring us more knowledge and experience in practicing machine learning and deep learning-based modeling in critical care and emergency medicine. With the advancement in forecasting the responsive of therapy in treating sepsis, a disorder that large  causes mortality and morbidity among patients with all kinds of comorbidities, we believe could bring us a more healthy and productive future."
"Deep Learning, CNN, GoogLeNet, ResNet, GAN, Driver Assistance Systems, Weather Classification","As the total number of vehicles has increased year by year, the number of accidents has also continued to rise. In order to reduce accident rates and improve driving safety, people have started to develop advanced driver assistance systems (ADAS), in which image recognition technology plays a very important role in driver assistance systems. In the past, image-based driver assistance systems were often built on the assumption that the line of sight is good, such as in sunny days and no light pollution. However, in the real environment, there are influences caused by weather factors such as rain, fog or snow. Although image restoration techniques are available to mitigate the impact due to weather factors, the restoration techniques for different weathers are very different and there is no universal method. Therefore, the driver assistance system installed on the vehicle must be able to identify the weather and make the most appropriate response. Based on this demand, this study proposes a deep learning method for weather classification to achieve the objective of fast and accurate. This project will use convolution neural networks (CNN) for training and GoogLetNet Inception v4 and ResNet would be its network architecture. There are four weather categories, including sunny, rain, fog, and snow. Because the technology to be developed in this project is for vehicles, we will use a large number of road images. The existing road images in various weather conditions are insufficient, so we will also use the generative adversarial network (GAN) to expand the number of images. The innovation of this project is trying to use a powerful deep learning network architecture for weather classification and integrate it into the vehicle imaging system. The practicality of this project lies in the fact that the technology to be developed meets the needs of current and future advanced driver assistance systems."
"garnish image, deep learning, image aesthetic quality assessment","In past decade, some Web-based sharing and community services such as Instagram, Facebook, and YouTube have made a vast and rapidly growing amount of multimedia content, i.e., social multimedia, available online. Users often share images and videos with their friends via social networks such as Instagram and Facebook. It is no doubt that users would like to share images with high visual quality to their friends. This means that image aesthetic quality assessment is important and it can be used in many applications such as photo editing, image retrieval, image understanding, object recognition, and photo management. In fact, a garnish image with high visual quality can attract customers’ attention especially on food ordering and delivery services. Furthermore, it is important to effectively teach students the concept of food presentation in culinary arts. Therefore, in the project, we would like to develop an aesthetic quality assessment system for garnish images.In this project, the system will be composed of several parts: ROI (region of interest) detection, aesthetic attribute extraction, visual aesthetics estimation, and information fusion. A ROI detection algorithm will be developed based on humane visual system, content analysis, and machine learning. An aesthetic attribute extraction algorithm will be devised to extract some specific features from garnish images based on deep learning framework. To estimate the aesthetic value of a garnish image, a visual aesthetics estimation will be designed. To integrate the aesthetic results, we would like to consider the ROI information for information fusion.Besides the above academic research, this project would like to create an experimental platform. Based on the platform, we will evaluate the performance of the proposed aesthetic quality assessment system based on deep learning for garnish images. From the viewpoint of research, a great progress of aesthetic quality assessment can be achieved by this project."
"Industry 4.0, smart manufacturing, visual-guided robot arm control, a pile of object grasp, computer vision, deep learning, R-CNN, 3D Bounding Box","In industry 4.0 – smart manufacturing, intelligent robot arm plays an important role for manufacturing automation. About “intelligence” of robot arm control, it requires the technologies of computer vision and artificial intelligence – deep learning in order that robot arm can automatically learn by itself for picking and placing the 3D objects. In order to reduce the production cost brought by rising wages, the manufacturing industry replaces the traditional manpower with automated production equipment and performs material processing or quality inspection. However, the feeding between machines is still a challenge. We hope to replace the part of loading materials manually or shaking and flattening the piled semi-finished products by the vibratory feeder with a robot arm system, and increase the flexibility and decrease the cost. In this project, we are going to integrate RGB-D sensor, computer vision and deep learning algorithms, and robot arm to design a system for detecting, classifying and grasping objects in pile. We will develop two deep learning models for the solution: First, the 2D RGB-D R-CNN（Region-Convolutional Neural Network）model having multiple inputs which are RGB color image and raw depth map. The 2D RGB-D R-CNN model will have a precise detection and classification performance for a pile of objects by fusing RGB and depth extraction feature maps.  Based on the 2D bounding box (BBox) and depth information for each object, robot arm can grasp the top object in order to complete the work. Second, we further modify the 2D RGB-D R-CNN model to 3D RGB-D R-CNN model.  The output will be the 3D bounding box for each object in pile."
"Light deep learning network, atrous convolution, embedded system, Taguchi method, parameter optimization, depthwise separable convolution","In recent years, AI technology has been applied in various fields. The issue of Taiwan's aging society and elderly living alone has become even more important. Through the use of domestic companion robot, the robot can understand the behavior and status of young children and the elderly and make responses. In order for the robot to obtain the user's emotions information, this project design a face recognition system for humanoid robot based on embedded lightweight deep learning network. Different from the traditional convolutional neural network requires a lot of hardware and time cost. The proposed lightweight deep learning network adopts the atrous convolution to extract image features, which can improve the perception range of feature extraction without increasing the number of parameters. In order to reduce the number of convolutional layers in the convolutional neural network, the depthwise separable convolution is introduced to replace the convolution operation in the traditional convolutional neural network. At the same time, the optimal parameters of the network structure are designed by using the Taguchi method. Finally, the lightweight deep learning network is ported to the embedded system and integrated with the humanoid robot to achieve real-time facial expression recognition."
"intelligent fish feeding, deep learning, underwater 3D object recognition, sonar image processing, fish feeding intensity recognition, drone, autonomous ship","This project presents deep-learning based underwater image processing and recognition for smart aquaculture feeding. The system uses an autonomous drone to capture image sequences for the target aquaculture farm modeling, data collection, monitoring, and event prediction. An autonomous ship, equipped with an underwater stereo camera is also used to monitor underwater objects for inspecting the growth and behaviors of fish school. Finally, to achieve the goal of intelligent fish feeding, a cloud system is constructed to execute the deep-learning models and store the collected fish-related data into the database. The deep-learning models for detecting and recognizing 3D objects in underwater stereo and sonar images are first trained based on the collected dataset captured by the fixed cameras which are still necessary because autonomous drone or ship is often out of services in bad weather days. This project is divided into three parts: (1) the deep-learning models for underwater 3D object detection and recognition are trained using fixed cameras; (2) both autonomous drone and ship are used to capture underwater images for understanding the behaviors of fish and fish school; (3) a smart fish feeding system is finally designed based on the techniques developed in the first and second parts. The project is a sub-project of the integration one which focuses on the development of underwater environment monitoring for smart aquaculture farming. The techniques under development include image recognition, water-quality inspecting, and intelligent robots for aquaculture farm monitoring. The project co-operates with Department of Aquaculture at National Taiwan Ocean university and Fisheries Agency, Council of Agriculture, Taiwan. The co-operative departments would provide us the experimental equipment and environments for building up meaningful aquaculture database which is important in developing new smart aquaculture artificial intelligent services."
"Clinical Decision Support System (CDSS), Deep Learning, Artificial Intelligence, Convolution Neural Network, Erectile Dysfunction, Hospital Readmission, m-Health.","Background: Clinical decision support systems (CDSSs) provide useful information to assist healthcare providers to improve medical outcomes. Our preliminary results showed that the incidence of erectile dysfunction (ED) was found to be associated with gout, sleep disorder, and other comorbidities. This motivated us to design CDSSs for predicting ED and detecting hospital admission using integrated Genetic algorithm (GA) and support vector machine (SVM) with the former used for selecting salient features and adjusting SVM parameters whereas the latter for discriminating normal from abnormal patients. Deep learning (DL) techniques have been widely applied in developing CDSSs based on physiological signals, medical images, and electronic health record (EHR). However, CDSSs designed using DL techniques based on Taiwan national health insurance research database (NHIRD) are still scant. Recently, m-Health systems have also been demonstrated to be effective in managing and preventing disease deterioration. The study objectives are to organize personal patient data embedded in the NHIRD into a sequence of temporal visits, and then fed into the DL platform for CDSS design to predict ED and readmission. Moreover, an m-Health system will be designed for caring patients who may develop ED for preventing their ED occurrence and elevating quality of life.Materials and Methods: In the 1st year, data of men older than 20 years old diagnosed with ED between January 2000 and December 2010 will be retrieved from the NHIRD for CDSS design. The comparison cohort comprised randomly selected patients without ED history will be frequency-matched (1:2) with the ED patients according to age and index date. In the 2nd year, data of patients admitted with pneumonia and readmitted within 30 days after discharge within 2000-2010 are retrieved for CDSS design to predict readmissions. The entire NHIRD data of a patient will be organized and coded as a temporal sequence of outpatient and inpatient episodes separated by irregular time gaps or transfers, and then fed into a convolution neural network (CNN) for training and validating the CDSS models. The steps of applying the CNN on the sequential temporal data include data embedding, convolution, pooling, and classification. Its predictive performance will be compared with CDSSs developed using traditional AI techniques. In the 3rd year, an m-Health system will be designed for preventing patients who are more likely to develop ED from having ED occurrence. Sixty patients will be recruited and randomly divided into control and study groups for verifying effectiveness of the m-Health system.Expected Outcome and Contribution: (1) The DL CDSSs developed will be beneficial in reducing ED occurrences and increasing patient’s quality of life. (2) The DL CDSSs designed for effectively predicting pneumonia patients with high-risk readmissions after discharge will benefit from the reminding function to notice family members to watch patient’s health and provide healthcare professionals to regularly track patient’s health status to prevent readmissions, improve healthcare quality, and reduce healthcare costs. (3) The m-Health system will be effective in preventing high-risk ED patients from deterioration of comorbidities as well as ED occurrence."
"Industry 4.0, Heterogeneous and Multimodal Deep Learning, Optical Inspection, Computer Vision, Intelligent Production Scheduling, Gated Recurrent Units (GRU),Long-Short-Term-Memories (LSTM) Neural Networks, Artificial Intelligence","Based on the concept of industry 4.0, this research project focuses on the development of various artificial intelligence techniques, data analytics methods, computer vision applications, and machine learning algorithms. With the data collected from the production lines of electronic oscillators and sensors by TXC manufacturing center, the participating students from institute of information management and department of information management and finance, NCTU, will utilize the advanced information/communication technology and Cyber-Physical System (CPS) to assist the realization of smart manufacturing. The project integrates interdisciplinary research fields, such as industrial engineering, computer science, information management, automation control, computer vision, and visual recognition. The research goal of the first year is to develop various computer vision techniques and applications for chip-by-chip big data collection. Several in-line management system and visual recognition techniques will be implemented in their production machines. The data storage and management framework of the large amount of manufacturing record collection should be also designed with the process analytical technology. Then, the major research direction of the second year is the deep learning techniques in artificial intelligence field. We focus on the development of novel learning method to model time-series data and make intelligent decision in industry 4.0 by prediction and forecasting. Based on well-known Gated Recurrent Units (GRU) and Long-Short-Term-Memories (LSTM) neural networks, an intelligent analytic system should be developed from batch-to-batch manufacturing management to piece-by-piece big data analytics. Finally, the intelligent process enhancement, yield rate improvement, automatic production scheduling, and even more smart industry 4.0 applications will be designed and developed after the well construction of artificial intelligence infrastructure."
"Deep Learning, Manifold Reconstruction, Whitney’s extension problem, Riemannian manifolds","We are based on Fefferman's recent article on manifold reconstruction as an attempt to explore the theories of deep learning from a mathematical perspective. This project uses deep learning and a ResNet-like structure to replace the ones used in the algorithm in Fefferman's article. It is hoped that under the given conditions, we can also use a similar method to construct a desirable manifold through deep learning. Furthermore, we hope to describe deep learning in more mathematics way. For instance, we want to use the method of ""distillation"" to discuss whether it is possible to find a ""minimum model"" in some sense."
"Denoising Auto-Encoder, recommendation systems, cold start recommendation","In this research project, we will study the new user cold start recommendation problem. We will investigate the well-known denoising auto-encoder model which is effective in extracting hidden information of high dimensional data and removing noise from the data. We will develop user rejuvenation strategies to rewind recommendation system users back to their entry stage. Denoising auto-encoder then is applied to the entry-stage data to restore user-item behavior, so as to model user preferences. Also, the embedding produced by the model will be incorporated with other recommendation methods to enhance the generated recommendations. Finally, attention model will be studied to aggregate the recommendations generated by different methods to improve our new user cold start recommendation performance."
"deep learning neural-network (DLN or DNN), instance-aware semantic segmentation,single view video (monocular camera video) depth estimation, 2D-to-3D stereo video conversion, perspective depth-conducted anchor lines, advanced driver assistance systems (ADAS), edge-computing","In this 3-year project, the depth estimation with deep learning neural-network (DLN), which is a milestone extension of our last MOST project achieved in 2018, will be designed with different networks with the camera in a car recording system to become an advanced driver assistance system (ADAS), or a fully-automatic 2D-to-3D stereo video conversion, or perhaps an autonomous vehicle system. In this project, we aim at attaining the accurate and robust depth estimation with single-view car video camera for general Taiwan roads. In the first year, we combine instance-aware semantic segmentation DLN, perspective depth-conducted anchor lines (PDALs) generation DLN and super-resolution DLN to construct an accurate rational depth creation system for monocular road landscapes video. The PDALs are employed to conduct the coarse depth allocation for supplying the depth mean to each segmented object, and then the super-resolution DLN creates the depth details inside each individual object to achieve fine depth estimation. We leave some necessary yet separable estimation DSPs and analyses in the prototype of proposed system accordingly. This is for facilitating the clarification against ill-posed problems in learning and functional DLN backbones. Thus, subsequent refinements and rectifications for those DLNs could easily enlighten how to properly fuse the temporal cues into them in the next year. The expectation to this year work is finishing the depth generation prototype system which can at least be applied to the self-driving of monotonous traffics.  In the second year, we aim at an intimate collaboration of spatial and temporal cues to help PDAL-generating DLN and super-resolution DLN to obtain the precise PDALs and accurate depth details, respectively. Specifically, the job in second year focuses on how to embed the non-local blocks into DLNs to remove the isolated temporal signal processes. For monotone road landscapes with few cars, the extracted PDAL shall be exactly the major/central lane markers with embedded depths, because it plays a role of critical depth reference to steer primary perspective estimation for ADAS applications. The expected result of this year is achieving the high-accurate depth generation for quasi-automatic 2D-to-3D video conversion and the autonomous driving in specific self-driving district. In the third year, the proposed automatic depth estimation will be compliant to the commodity acquirement of almost automatic 2D-to-3D stereo-video conversion for Taiwanese traffic roadways to rectify, refine and promote the employed DLNs. The refinement and the promotion could be associated with the structural modification for terse signal/information exchanges, the inserted restraints of kernel weights updating for steadier learning convergence, the automatic adaptions of batch size, learning rate and the loss function completeness. Those refinement works are desired for higher accuracy in outside testing using unlabeled dataset. Finally, under the limitation of performance degradation, we make the proposed framework as concise as possible for robust depth-estimation of single-view video in edge-computing in ADAS, autonomous vehicle and quasi-automatic 2D-to-3D stereo-video conversion tool."
"Text Analytics, Social Network Analysis, Social Media, Ensemble Learning, BERT","Social media facilitates the sharing of personal opinions, positions, viewpoints, experiences, media, intelligence and other information on social events and issues of concern, so it has gradually become a source of news content for journalists. This research is aimed at online news with sources cited from social media-related content, by analyzing the online interaction behaviors of social media opinion-related participants, and publishing information, in order to explore the communities where news reporters cite or trigger writing as news Media content related features. Aiming at the content of social media comments cited by reporters, this study attempts to construct a prediction model to observe whether it will become a news event by calculating social network analysis indicators (SNA Indicators) and sentiment indicators and the aid of artificial intelligence  of deep learning algorithms. This study will explore whether combining social media sentiment analysis, corresponding SNA behavior analysis, BERT deep learning, and ensemble learning methods can effectively predict social media contents being reported by the news and further improve its prediction accuracy. This research further explores the analysis of the particular sections, issues, content preferences, and time gaps of the social media cited by various news. The experimental analysis of this study will be based on the online news media ranked higher in the forefront of the digital news reports of the Reuters Institute of Journalism. Four online news websites in Taiwan will be selected as experimental subjects. PTT and Dcard, the two most commonly cited websites, are used as a source of retroactive data. Based upon the constructed prediction model this research may effectively grasp the key factors of social media content leading to ""quoted news"" and ""headline news"" and their influence intensity, so as to serve not only as key indicators for corporate higher management as early warning and monitoring mechanism, but also to cope with and prevent the impact of various flowing information on internet media."
"Fuzzy neural network, hierarchical fuzzy neural network, outlier, resistant learning machine, deep learning","In this project, novel resistant hierarchical fuzzy neural networks will be proposed and their deep learning problems are studied.  These fuzzy neural networks can be used to model complex controlled plant and can also be used as fuzzy controllers.  Generally speaking, in a given real dataset, there are more or less some observations which are well separated from the majority of the data, or in some way deviate from the general pattern of the data; these anomalous observations are called outliers.  These outliers may have undesirable or unpredictable influences on the final learning machines.  The primary motivation of this research is the development of a special class of fuzzy neural networks so that these learning machines may have resistance or robustness against the adverse effects of the outliers.  The hierarchical fuzzy systems made their debut (i.e., first appearance) in control area.  However, to the best of our knowledge, hierarchical fuzzy neural networks have never been used as resistant learning machines in the past researches.  In this project, we will use the least trimmed squares and Wilcoxon norm as our resistant cost functionals.  To enhance the predictive power of the proposed hierarchical fuzzy neural networks, in each child fuzzy neural network, various types of layers, including dense layers, convolutional layers, LSTM recurrent layers, and GRU recurrent layers, may be added after the first hidden layer.  The back propagation algorithm (BP algorithm) provided by TensorFlow will be utilized to find the optimal connection weights of the neural networks.  In this project, real datasets will be used to compare the performances of the proposed resistant hierarchical fuzzy neural networks and the standard fully connected fuzzy neural networks."
"breast cancer, 3D Doppler ultrasound, B-mode ultrasound, angiogenesis, neo-adjuvant chemotherapy","Angiogenesis is widely accepted as a process for the growth of cancers. Tumor vascularization has been proved to be an important factor that correlated with tumor malignancy. Tumor vascularization has been proved to be an important factor that correlated with tumor malignancy. The Doppler ultrasound blood flow signals have been demonstrated that associated with malignant tumor vascularization. Three-dimensional (3D) High-definition flow (HDF) Doppler ultrasound was performed to investigate blood flow and solid directional flow information in breast tumors. The vascularization of tumor would be used as a factor to evaluate the effect of the neo-adjuvant chemotherapy prior to surgery. Moreover, breast brightness mode (B-mode) ultrasound is able to identify cancer structure and it can be a good tool at monitoring the response of the neo-adjuvant chemotherapy. The aim of this project is to find out potential early predictors from the HDF Doppler sonography and B-mode ultrasound images for good responses to neo-adjuvant chemotherapy. This project plan to combine the vascularization and lesion features from the ultrasonography for analyzing the tumor of metastatic breast cancer patients by using deep learning techniques, i.e. GCN (Gabor convolutional network) and Multi-view CNN (MVCNN). Results of this project shall be expected to be helpful in developing a breast tumor neo-adjuvant chemotherapy effect evaluation scheme."
"Network Slicing, Software-Defined Network, Network Function Virtualization, Vehicle-to-everything, Deep Learning Model","The next generation of mobile communication technology is rapidly developing. International standards organizations have promoted network slicing technology, using SDN (Software-Defined Network) and NFV (Network Functions Virtualization) for network slicing, and dividing traditional network services into several different application service scenarios to provide users with advanced QoS (Quality of Service). However, network functions must be visualized for application services using network slicing. NFV transfers the original traditional telecommunication special equipment to software function, such as the core network system is implemented by software in virtual hosts (Virtual Machines, VMs). The software functions in the server combine computing, access and network resources to replace the traditional telecommunication special equipment. Therefore, this research uses deep learning to implement dynamic network slicing in heterogeneous network V2X in next-generation mobile communication technology. We takes V2X (Vehicle-to-everything) active safety alert as an example of vertical integration. We will implement dynamic network slicing for high-throughput transmission and low-latency transmission in heterogeneous networks to ensure V2X active safety driving assistance system can assist vehicle response immediately, thereby improving driving safety."
"Deep learning, light microscopy, renal pathology, image segmentation, anomaly detection","In Taiwan, chronic kidney disease (CKD) is a prevalent disease (about 12% of people) and most CKD patients are unaware of their disease. For patients with renal functional impairment of unknown etiology, renal biopsy is a valuable and irreplaceable diagnostic procedure to help the nephrologist make a definite diagnosis. Light microscopy images of tissue taken from the renal biopsy are the most important and basic renal pathological images, and can be taken in conjunction with various staining techniques to emphasize different important pathological characteristics for improving the accuracy of diagnosis by the pathologist. However, the interpretation of renal pathological images is so extremely time-consuming that the formal pathological report is almost always provided one to two weeks after the renal biopsy. If some tools can be developed to assist the pathologists during the process of pathological image interpretation, it would dramatically improve the efficiency, quality and accuracy of the current diagnostic process. Deep learning (DL) has become one of most popular computer related techniques, and it is especially suitable for image analyses which has shown remarkable performance surpassing traditional techniques based on hand-crafted features. In recent years, a variety of medical image analysis tasks using DL have been proposed, e.g., detection and classification (cancerous area vs. non-cancerous area), and segmentation and object detection (neuronal or cell structure). Over the past two years, we have accumulated an abundance of experience in the use of various DL techniques for the detection of hip fractures from pelvic X-ray images and identification of glomeruli from renal biopsy pathological images. Based on this experience and results with processing medical image data, in this project we plan to continue collecting vast amounts of available renal biopsy pathological images from Taichung Veterans General Hospital and perform image labeling. In addition, we plan to apply various deep learning techniques to renal biopsy pathological images for identification and interpretation of glomeruli, tubules and interstitium, which are important microstructures in renal pathology. These microstructures can give us a great deal of information, e.g., the number of sampled glomeruli can be used to identify the adequacy of the renal specimen and the pathological morphology of the microstructures can give us some hint about the clinical prognosis for the patients. These techniques include adopting image segmentation techniques and exploring the relationship between the renal microstructure images and clinical data, and introducing the anomaly detection method to identify abnormal renal microstructures through the use of generative adversarial networks. In summary, the tasks for this project are 1. Collecting renal biopsy pathological images from Taichung Veterans General Hospital and performing image labeling.2. Adopting image segmentation techniques and exploring the relationship between the renal microstructure images and clinical data.3. Through the use of generative adversarial networks introducing the anomaly detection method to identify abnormal renal microstructures.By accomplishing the above goals, we expect this fundamental work can facilitate the understanding of the relationship between the renal microstructure images and clinical data, and promote the advancement of the automatic interpretation of renal pathological images in the future."
"cafeteria checkout system, deep learning, depth map, food image detection, food image recognition, food volume estimation, food calories estimation","In recent years, the technology of artificial intelligence (AI) and robots is rapidly spreading to countries around the world. More and more scholars and industry experts have proposed AI deep learning models and methods to solve human life problems and improve work efficiency. Modern people's lives are very busy, coupled with the child-less trend, the demand for cafeterias has gradually increased. However, eating at a buffet in cafeteria often encounters two problems: the first problem is that you need to queue up to check out after you finish taking up the food. But it always takes too much time waiting, especially at noon or off time. The second problem is sometimes we questioned the charges are too expensive at checkout counter. In addition, modern people value diet nutrition and health, and want to know the calories and nutrients in each meal. If people can know the nutrition and calories contained in the meal, I believe it will benefit many people. Therefore, it is necessary to develop a smart food image recognition and cafeteria checkout system. In this study, we plan to use computer vision and deep learning technology to implement an automatic checkout system for restaurants, and build a food image recognition platform for food photo shooting and identification.The proposed cafeteria checkout system includes the following four functional modules: (A) Image capture module (B) Image segmentation module (C) Image recognition module, and (D) Price and nutrition calculation module"
"Artificial Intelligence, deep learning, Convolutional Neural Network, Recurrent Neural Network, Image Recognition, Ground-penetrating radar","The non-destructive inspection technology, ground penetrating radar (GPR) has been widely used to detect the damage infrastructures such as rebar corrosion, carking, leakage. The deterioration of infrastructures such as bridges, buildings, tunnels, roads becomes be some severe problems. The ground penetrating radar (GPR) is an efficient technique for inspection those issues. Therefore, the proposed methodology is based on the integration of conventional image processing techniques and Convolutional neutral networks (CNN) and Recurrent Neural Network (RNN).This project will base on the convolutional neural network (CNN)and trained to recognize the characteristic signatures in GPR scanning of reinforced concrete structures. Then to collect the GPR data for a damage structures, the trained CNN is employed."
"Fused deposition modeling (FDM) , Dome structure, Deep learning theory, Numerical analysis, Robot collaborative processing","This research is aimed at the improvement of fused-deposited (FDM) laminated manufacturing construction technology for intelligent robot-assisted the 3D dome structure objects with curved layer ceiling component  without supporting objects or supporting materials. The research objectives continue the foundation of the established intelligent robotic arm collaborative hollow suspended wire structure manufacturing experimental platform, and propose a data sample construction method that effectively accelerates the learning efficiency of artificial intelligence to assist the efficiency of deep learning model construction and convergence. In order to improve the support effect of thermoplastic suspension forming, the DDPG in reinforcement learning is used to obtain the motion parameters such as the supporting position and duration time etc., so as to control the robot arm in the simulated environment to reach the support target position and obtain characteristics from the environment. The message is passed to the DDPG system to update the DDPG neural network. However, due to the application of deep learning methods for parameter setting and performance measurement analysis of actual experiments, a large number of process operations and effectiveness evaluations need to be performed to provide the establishment of artificial intelligence computing models, which often require time-consuming and labor-intensive model calculation for required learning and test sample data. Based on the established experimental platform of multi-robot collaboration, this research proposes the idea of using partial numerical model calculation data to assist experimental data samples to accelerate the construction of deep learning models. Because the material forming process of the circular arched plastic suspension wire manufactured by the FDM base discussed in this study can be considered as a structural mechanics problem with both geometric nonlinearity and material nonlinearity. Therefore, the temperature change of the plastic suspension wire needs to be measured first. Data values such as material characteristics at different temperatures are used as parameter values for numerical calculation of finite element analysis. This study will evaluate the core unit of the system's calculation analysis using a more suitable program. Currently, ANSYS's solid structure module has been selected for preliminary testing and has been qualitatively obtained. Reasonable results need to continue to confirm the characteristic values of materials and temperature effects. It is expected that reasonable data validation will be obtained in quantitative terms and can be applied to the establishment of deep learning auxiliary data samples for the study of this project to accelerate the efficiency of model learning. The results of this research will improve the execution efficiency of the intelligent robot-assisted FDM-type 3D printing collaborative operation system, and improve the innovation and efficiency of the dome-type shell-like three-dimensional structure with a hollow cavity and the use of FDM's new curved structure printing technology."
"Lossless Image Watermarking, Deep learning, Robustness","Generally, in the design of an effective watermarking mechanism, characteristics such as the security, invisibility, robustness, and capacity of the system architecture are assessed. Designing a watermarking mechanism that meets these characteristics is a big challenge. In this project, we proposed an image restoration algorithm that can improve the robustness of lossless image watermarking mechanisms based on deep learning technology. In lossless image watermarking mechanisms, both the embedding and extraction of a watermark are related to the characteristics of the image. If the image characteristics are distorted due to damage by malicious image processing, the watermark retrieved will also get damaged, which will affect the identification of the watermarked content. In this proposed mechanism, after the protected image gets damaged, the restoration program in the proposed algorithm can restore the characteristics of the image approximately to its original characteristics, which helps to obtain clearer results for the retrieved watermark. This method can assist most of the existing lossless watermarking algorithms in improving the robustness of their mechanisms and protect multimedia data in different environments."
"Remote Sensing Image, Convolutional Neural Network, Feature Extraction, Transfer Learning, Structure Identification/Parameter Learning","Remote sensing imaging system can be applied in many different areas of astronomy, monitoring change of landscapes, geology and geophysics, change of ecosystem, and earths' environment protection, etc. These applications can be formulated as a classification/recognition problem and addressed by a learnable system. Before learning task, the fundamental problem of traditional machine learning is to design a feature extractor for a specific domain in order to extract important features. However, the learning process is very easily stuck to local optima.Recently, deep learning has achieved great success in image recognition, computer vision and many other areas. Among them, Convolutional neural network (CNN) is the most common used model in this issue. Specifically, convolutional neural network, where the convolutional layer plays an important role in selecting discriminatory features for performance improvement, is more appropriate to extract features from raw data directly. It also automatically extracts translational-invariant spatial features and integrates with deep neural network-based classifier in one unit. Regarding satellite remotely sensed imagery, these research efforts have illustrated a variety of problems ranging from feature extraction, mixing pixels of different classes, and the problems to “transfer knowledge” between homogeneous/heterogeneous images. Therefore, this research explores the discriminatory power and learning capability of convolutional neural networks with separation metric in conjunction with transfer learning for classification to recognize a variety of targets from remotely sensed imagery data. In addition, the CNN-based transfer learning model with transfer learning, making knowledge learned from the CNN with optical scene images transferrable to the heterogeneous Synthetic Aperture Radar (SAR) images, can extend the generalization capability of convolutional neural network. The pre-trained CNNs are expected to transfer knowledge to heterogeneous data classification tasks, with the ability of the proposed structure identification and parameter learning simultaneously. Finally, a collection of remotely sensed imagery, including SAR images and optical image, will be extensively verified and compared with the past proposed Automatic Target Recognition approaches."
"evidence-based medicine, systematic review, natural language processing, deep learning, document classification, document annotation","Systematic review and meta-analysis assist in the decision making of the diagnosis and the treatment in evidence-based medicine. However, conducting a systematic literature survey is tedious work. Thousands of articles obtained from keyword searches against medical databases should be manually reviewed and selected. After acquiring the literature that matches the topic of our interest, a critical appraisal on full-text should be done for the assessment of trustworthiness. We would like to apply deep learning-based natural language processing techniques to assist in the systematic review needed for evidence-based medicine. The specific aims of this project are as follows:1.	Develop automated document classifiers for the topic-specific literature screening.2.	Develop automated document annotators for literature survey.3.	Integrate the results of the previous two tasks and develop software systems with user-friendly interfaces."
"Artificial Intelligence, Deep Learning, Local Binary Patterns, Content-Based Image Retrieval (CBIR)","E-Commerce or Mobile Commerce with the technology of deep learning and computer vision great advancement. Sogou App in China developed a search engine by uploading pictures or taking pictures by customers to Sogou search engine, and find similar or identical recommended products from hundreds of millions of products in the Gogou App backend. Moreover, Sogou App can draw a chart showing the price of that specific product over past one month and Sogou can tell customers when and where to buy that product can get the best price.The Shopee App (Singapore), Taobao App (China), and Momo App (Taiwan) also have the similar function in searching similar products for their customers.  The image search function are widely being used in E-Commerce or Mobile Commerce with great advancement of deep learning and computer image recognition technology.  Although, Google image search function already have applied similar technology, but Google search algorithm are based on keywords to perform searching , and the results of recognition are not so effective in texture, shape and fabric.     With rapidly development of Artificial Intelligence, deep learning using Convolution Neural Network (CNN) has a great advancement in computer vision.  Therefore, in new retail revolution, how to use computer vision in identifying and searching similar commercial product becomes more challenging and meaningful task. Apparel, clothing and shoes products are very close in shape, color, texture, and fabric, whereas traditional computer vision cannot distinguish the clothing product in terms of material, texture, and fabric. Therefore, to develop a mini search engine for similar texture clothing or shoes for E-Commerce customers is the key purpose in this study.  This research used the local binary pattern LBP to construct a clothing (shoes) product identification search system to solve the problem of e-commerce consumers looking for similar clothing (shoes)."
"Image Retrieval,Deep Reranking","In this project, a deep reranking algorithm will be proposed to improve the retrieval accuracy for image retrieval systems. First, a pre-trained 1000-class convolutional neural network (CNN) is used to extract the feature vectors of the query and database images. The initial ranking list can be generated by computing the distance between two CNN feature vectors. Then, according to the initial ranking list, several pseudo relevant and irrelevant images are automatically selected without any user interaction. These relevant and irrelevant images are used to fine-tune the 2-class (relevant vs. irrelevant) CNN. Based on the fine-tuned 2-class CNN, the new feature vectors can be extracted and match again. Finally, a new ranking list can be generated based on those new feature vectors. As a result, the images can be reranked in an attempt to move those relevant images to the top of the ranked lists. Experiments will be conducted on Oxford 102 Category Flower Dataset、COIL-100、Corel10k、Leeds Butterfly、Oxford Buildings and Paris Dataset."
"Blind source analysis, Cocktail Party problem, Beamforming, Deep learning, Asynchronous update algorithm.","In the multi-speech environment, identifying and enhancing voice targets has been an important development direction for blind source analysis to solve cocktail party problem. Previous studies mostly used simple microphone voice signal processing to perform target speech analysis and enhancement, such as speech feature recognition through a large amount of training data、supervised machine learning、classification statistics and independent component analysis. This approach has good results for instant stationary noise suppression, but its processing effect is relatively limited for non-stationary voices from specific targets. This study propose a Real-Time System for Multi-speech Separation and Noise Reduction Method based on beamforming technology and computer vision for a cocktail party environment, which using asynchronous update algorithm will divided into two stages. In Stage 1, we will use computer vision to detect and identify sound source targets and calculate source angles and distances. Meanwhile, use beamforming technology to enhance the target sound source. Stage 2 will use deep learning technology to ensure that real-time system for multi-speech separation voices were processed and output instantly. Consequently, ensure the feasibility of the results of this study and increase the market potential for future commercialization."
"smart shopping cart, deep learning, commodity recognition, facial recognition, visual SLAM, path planning, automatic guidance","In recently years, ""AIoT"" and ""Smart Robots"" are developing rapidly. In addition, the future industrial model will be ""Intelligence + Service"". Therefore, in response to industrial transformation, this project intends to design a smart guide shopping cart based on visual simultaneous localization and mapping (SLAM) and deep learning recognition techniques. The central control system of the smart shopping cart is a high performance laptop which is connected to a camera for deep-learning-based commodity recognition. It can help consumers see the information of commodities for controlling their shopping budgets. In front of the smart shopping cart, there is a 3D camera for 3D visual SLAM. Then, after path planning and controlling the 4-whell drive mecanum wheel mobile robotic platform, the automatic shopping guidance can be completed. A tablet is used for user interface and capturing the face image for the deep-learning-based facial recognition. By doing facial recognition identity validation, the smart shopping cart can recommend the discount commodities according to their shopping habits. By vision-based tracking techniques, the smart shopping cart can follow the consumer automatically. The “Google Cloud Speech API” is applied for speech input and “Firebase” is utilized to construct the hypermarket cloud database for smart shopping cart access."
"Deep learning, idiopathic epiretinal membrane, vitrectomy, visual acuity, optical coherence tomography","Idiopathic epiretinal membrane (iERM) is a common retinal disease among the elderly with an age-standardized prevalence of 9.1%. The prevalence of iERM in Taiwan has not been studied, but a higher prevalence among Chinese than other ethnicities has been reported. The diagnosis and management of iERM has revolutionized with the advance of optical coherent tomography (OCT). The high-resolution cross-sectional images of OCT provide an in-vivo histologic view of the membrane and the associated pathologic changes at macula. Surgical removal of ERM is a standard treatment for patients suffering reduced VA or intolerant to metamorphopsia. Most patients have improved visual function following surgery. However, there is currently no consensus in the indication and timing of vitrectomy for iERM because of the variable natural course, unpredictable postoperative visual gain and the lack of consistent biomarkers for surgical outcome prediction. A great effort has been made to elucidate potential characteristics in the OCT images which are explainable for the functional changes, and predictable for postoperative visual outcome. Several parameters were therefore developed, but none is adopted universally in daily clinic due to inconsistent findings or the need of intricate calculation. Deep learning has the ability of catch features on the OCT images to differentiate multi-categorial retinal disorders and is capable of extract new knowledge from funds images for systemic disorder assessment. Deep learning may therefore be able to extract multiple features in the OCT images of iERM for prognosis prediction since the impact of iERM and its removal on visual function may be complex and cannot be determined by simple quantitative parameters. Through the cooperation with the Industrial Technology Research Institute using a new approach of deep learning, heterogeneous data fusion net (HDF-Net), we will be able to incorporate clinical measurements, OCT images, and the time-series changes of all the parameters into the deep learning model for outcome prediction. This study aims to collect 1000 subject with iERM using ICD-9 and surgical code from the Big Data Center and Image Database of our institute. We will use deep learning to identify subjects with iERM who will have progressive disease and to predict postoperative visual outcome following vitrectomy using OCT images and clinical parameters. As a reference standard for comparison, we will also use the statistical approach to build an integrated predictive formula for visual outcome prediction. Through this large-scale clinical and image data collection and the analysis proposed in this study, we will have a great opportunity to establish a protocol to guide appropriate timing and candidate selection for surgical intervention to improve the management of iERM in our population."
"deep learning, financial technology (FinTech) , graph embedding, knowledge graph, precision marketing, explainable recommendation","With the rapid development of artificial intelligence, deep learning techniques have become effective tools to deal with complicated tasks in various fields. In innovative services related to financial technology (FinTech) area, the issue of precision marketing of financial products has possessed with unlimited research potential since financial products and customer behaviors are quite variable and complex. In addition, industries has accumulated enough data to be analyzed through deep learning techniques. Traditional recommendation system applied collaborative filtering algorithm to recommend products to users. However, it comes up with data sparsity and model scalability problems in our research. The lack of model interpretability may also reduce the value of the recommendation system. To deal with above problems, in this research, we develop a financial product recommendation system based on deep learning, graph embedding and knowledge graph techniques. To analyze investor trading behavior and provide personalized recommendation results, the graph-structured network is constructed based on connecting customer with similar purchasing and selling behavior. Later, the aggregator function generates a corresponding embedding vector for each customer and the model will predict the willingness of purchasing specific financial products. In addition, we apply knowledge graph embedding to construct recommendation systems with tailored explanations. As a result, people can better understand the results produced by the model and thus achieve the purpose of precision marketing. To sum up, the research focus on graph embedding and knowledge graph techniques to build an explainable recommendation system. The proposed method improve the data sparsity problem as well as increasing explainability of the recommendation model, which attains the goal of applying advanced artificial intelligence algorithms into traditional financial industries."
"Deep Learning, LSTM, Dataset, Transfer Learning, Gaze Estimation, Visual Behavior Analysis, Intelligent Edge","The project aims to explore to provide new techniques for better data acquisition and analysis of audience' vision behavior, and to build the dataset by watching videos. This project proposes the temporal based gaze point estimation technology, which will be closer to the visual behavior that can help on improving the effectiveness of gaze analysis. There are several innovative methods include gaze point estimation using time-based deep learning technology to overcome environmental problems such as head swings and more realistic visual behaviors; propose data augmentation of adding face attributes to solve the problem of insufficient training samples; propose the transferring learning method from image training to video that can improve the accuracy of gaze estimation; intelligent interaction analysis and application based on LSTM can infer visual behaviors such as object preferences and abnormal visual behavior; the intelligent edge implemented resource management which integrates deep learning-based gaze information extraction, and intelligent interactive analysis and application.The main research topics in this issue include: (1). Synchronization data collecting of time-series related dataset and automated labeling technology. (2). LSTM based gaze estimation. (3). Data augmentation for new face attributes. (4). Based on LSTM analysis and application of intelligent interaction. (5). Resource management implemented by intelligent edge. It is hoped that the realization of research topics can help improve the effectiveness of applications."
"Deep learning, computed tomography","In recent years, deep learning (DL) has been growing rapidly, and has many industrial and commercial applications in various fields. Similarly, DL has shown many encouraging results in the field of medical image processing and analysis. In this project, our aim is to study the clinical applications of DL in computed tomography (CT). Two applications will be studied in this project. First, we will investigate whether DL can generate dual-energy CT (DECT) imaging from single- energy CT. If it is feasible, we can have DECT imaging without purchasing an expensive DECT scanner. Moreover, only one single-energy CT scan is required. Second, we will investigate whether DL can produce virtual non-contrast (VNC) CT using contrast-enhanced CT. If it is feasible, a non-contrast CT scan is no longer required. The two applications of DL have the benefit of reducing patient radiation dose. In this project, we will perform a retrospective study that includes two groups of patients. The first group will recruit patients who received a DECT scan. We will compare the DL-based DECT images with the true DECT images. The second group will recruit patients who received two CT scans (one with contrast and the other without contrast). We will compare the Deep learning-based VNC CT images with the true non-contrast CT images."
"Opinion Mining, Deep leaning, Omnichannel, Kano model","Since the mobile payment rapidly growing popularity, most customers become to purchase products and services by internet shopping. Recently, the brand company provide different channels to fulfill customers’ convenience. The idea of Omnichannel is to create a single customer experience across your brand by unifying sales and marketing that accounts for the spillover between channels. Since the online consumer product reviews are also considered as an important resource which deeply influenced the readers to make purchase decision. We will propose a three years plan to construct a novel framework combining “deep learning” and “opinion mining” techniques to build a marketing intelligent framework based on customer journey to fulfill the marketing strategy designed at Omnichannel environment. At the first year, we propose a deep learning model to improve the attribute extraction of reviews qualitative. The attribute extraction is the most important step at opinion mining process. We will explore the new techniques of deep learning applying at opinion mining and  will design a spider to grab the real online review forums about the travel information to build our own review database. Next, we will propose a framework for aspect-based sentiment analysis based on BERT. After processing the review database based on the proposed framework, we design a method with a Kano model to analyze online reviews to develop appropriate product improvement strategies.Finally, we will design an O2O recommender system for collecting user browsing history. At first, we will design a Chabot based on the aspect database extracted by previous year to collect users’ preference information. And then we will design novel deep learning technique based on the collected data to detect user’s preference profile. The validity of the approach is verified by carrying out extensive experiments using real data sets.Based on the collected rich information, we can explore a whole map of customers’ journey. It’s a challenge approach to combine the O2O marketing knowledge and the novel deep leaning of NLP technique to detect the customers’ journey from customer reviews."
"Deep learning, traffic flow prediction, recurrent neural network, long short-term memory, attention mechanism, cycle embeddings","Deep learning is a very popular learning technique and the benefit of big data has grown up in many research issues. The traffic big data is also a very popular issue in many years. In order to improve the performance of traffic flow prediction, this project proposes three years to build a deep learning model with multiple time series attention mechanisms. First-year, a Surroundings Attention mechanism with a Recurrent Neural Network model (SA-RNN) is used to learn time-series features of an MRT station and vehicle detection devices (VDs), and the attention mechanism is used to estimate the weights of VDs with the target station. Second-year, we extend the SA-RNN mode with a single station to multiple stations based on its route and use an attention mechanism to estimate the weights of routes with the target station, called Route Attention mechanism with a Recurrent Neural Network model (RA-RNN). Third-year, we also extend the RA-RNN model with the last statue of time series to full statues of time series and use the Cycle Attention mechanism with a Recurrent Neural Network model (CA-RNN) to estimate the weights of all time points with the cycle embeddings. Therefore, this project can be built an effective traffic flow prediction model which includes the surroundings of VDs, routes of MRT and cycle characteristics. In addition, the innovative deep neural network structure can affect researchers who want to use our proposed model to other time series problems."
"Deep learning, Quantum simulator, Intelligent screening of materials, Structural optimization of devices","The development of new materials and devices is always important in semiconductor industry. Because it takes a considerable amount of time and resource. How to improve the efficiency in discovering new materials and designing innovative devices becomes the most important issue in this field. In order to speed up the development cycle, the main goal of this project is to develop several tools of quantum simulator by machine learning. Deep learning algorithms will be implemented in the screening of materials and designing of devices in these tools. It is expected to provide an intelligent working flow for materials screening and devices designing which therefore can speed up the research cycle in semiconductor industry."
"plant phenotyping, plant growth curve, wilting leaf detection, deep learning","Traditional plant phenotyping involves manual measurement of plant traits. Because plant phenotyping is slow and labor intensive, it has been considered as an important bottleneck in the research of plant breeding. As a result, automation of plant phenotyping has drawn much attention in the recently years. In particular, image-based phenotyping techniques have the promise to analyze visual traits up to a satisfactory level of accuracy. These techniques can significantly boost production performance and reduce cost because fewer workers would be required for manual measurement in the field. In this project proposal, we plan to develop a high-throughput phenotyping system for broccoli. In particular, we will utilize YOLOv3 to detect the curd of broccoli for the whole growth stage (from budding to harvest). Then, we can perform regression analysis to obtain its growth curve. We will also use YOLOv3 to detect the wilting leaves of broccoli, which is an important indicator of plant health. Thus, our developed system can automatically record the growth curve and the number of wilting leaves to facilitate the process of broccoli breeding. To validate the proposed system, we will conduct a series of experiments using broccoli images provided by AS-BCST (Academia Sinica – Biotechnology Center in Southern Taiwan)."
"outage capacity, multimedia communications, multi-objective function, model-driven deep learning, loss function modification, constrained optimization, non-orthogonal multiple access, ultra-reliable low-latency communications, source encoding rate control, rate-distortion (RD) function.","Recently we proposed a cross layer source encoding rate control and radio resource allocation scheme minimizing the sum video distortion for NOMA-OFDMA video transmissions (scheme A) and outperformed the previous OFDMA cross layer scheme and previous OFDMA/NOMA physical layer scheme in average peak signal to noise ratio (PSNR). Also we proposed a data-driven deep learning with post-processing version of scheme A, scheme A’, and showed close average PSNR performance.  For 5G ultra-reliable low-latency (URLLC) scenario, however, the outage capacity is more emphasized than the ergodic (average) capacity in 4G, and the DNN output post-processing of scheme A’ incurred extra delay due to sorting and was not suited for low latency applications. In the 1st year proposal, we propose the outage capacity based subcarrier assignment/user pairing and NOMA user power allocation scheme maximizing average PSNR, and also data-driven deep learning without DNN post-processing for NOMA-OFDMA video transmissions. The proposed scheme B re-allocates subcarrier/user pairing (the candidate user to obtaian subcarriers is derived in Appendix A) by increasing the number of satisfying users (PSNR above the threshold), the outage capacity, first and increasing average PSNR second. We propose NOMA user power allocation maximizing average PSNR (new derivation in Appendix B) instead of minimizing sum video distortion in scheme A and A’. The proposed scheme C lets the user with the lowest PSNR takes away the subcarrier of the highest PSNR considering increasing the outage capacity first and increasing average PSNR second. The data-driven deep learning without post-processing version of the schemes B and C (schemes B’ and C’) are also proposed. The proposed modified loss function in scheme B’/C’ can solve the constrained optimization and remove the DNN post-processing (to satisfy the constraints) and reduce the complexity. Scheme B’/C’ is more suited to URLLC applications because no iterative operations and no DNN output post processing are required. In the 2nd year proposal, we propose MIMO NOMA-OFDMA video transmissions outage capacity maximization resource allocation schemes AA/BB/CC extending schemes A/B/C, LMS update of RD function parameters inside one GOP, model-driven deep learning, and deep learning of RD function parameters. We consider subcarrier domain-power domain (strong/weak users)-spatial domain (clusters) 3-dimensional resource allocation instead of subcarrier domain-power domain 2-dimensional one in the 1st year proposal. In addition, we propose video content-based RD function parameters update at the video slice level instead of GOP levels using adaptive LMS algorithm (derivation in Appendix C). Furthermore,	we propose model-driven deep learning approach for scheme AA/BB/CC. That it, we use scheme AA/BB/CC as coarse resource allocation first and apply DNN as the following universal approximator to get finer resource allocation. It is expected to get smaller training data size and lower computing time. Finally, we plan to use CNN to learn RD function parameters, get RD function of a video in an online way, and apply it to cross layer source encoding rate control and radio resource allocation."
"Deep Learning, Feature Extraction, Single-Shot Localization, Model-Based Localization, Simultaneous Localization and Mapping","The goal of this project is to study how to apply deep learning to visual ego-positioning. This project is a three-year project. In the first year, we will compare performance of feature matching between traditional features and deep learning features. Furthermore, we will analyze the influence of the positioning accuracy by changing the traditional features used in the traditional single-shot method and continuous method to deep learning features. In the second year, we will improve the “single-shot” localization method using deep learning, which includes two parts of improvement. The first part is to modify the long short-term memory networks to “weighted” long short-term memory networks, thereby achieving higher positioning accuracy. The second part is to improve the optimizer in deep learning, thereby increasing the training speed and increasing the accuracy of the parameters in the loss function. In the third year, we will improve the “continuous” localization method using deep learning, which includes three parts of improvement. The first part is to add the optical flow estimation model into the deep learning framework to help the deep learning model to effectively converge while training. The second part is that we will use pre-trained image segmentation models to help the depth estimation model to estimate the depth at the edge of the objects more accurately, thereby indirectly improving the positioning accuracy. The third part is to adjust the training strategy to ensure that the training input data can have sufficient parallax."
"gene, non-image data, feature extraction, machine learning, deep learning","This proposal is planning using deep learning to extract features of non-image data which has no topological property between variables. Several feature extraction method for image data are well-developed. Because of the structure of variables of non-image data being not as clear as image data, the approach of feature extraction for non-image data is not as advanced as those of image data. Due to this situation, we are planning to get breakthrough in  this perspective. The subject data will mainly be public gene data base such as TCGA."
"Violence detection, Complex action decomposition, Two-stream deep learning architecture, Action silhouettes, Optical flow","There has been significant improvement in action recognition efforts over the past decade since the boom of computer vision. Majority of these researches focus mainly on simple actions, while having minimal focus in determining aggressive complex actions such as violence. Real-time implementations of this technology in surveillance cameras will be extremely useful in public safety such as schools, public spaces, prisons or psychiatric facilities. There is a perceived need for violence detection systems, particularly in surveillance systems but there are certain concerns that hinder progress in this kind of task such as the availability of efficient software for real-time detection. Another concern in performing violence detection jobs is the availability and quality of data, such that there is no consistency and standard in data in the wild. It can be said there is a need for an intelligent system that can determine violence in videos. In this project, we propose a real-time human violence recognition network named “ViolenceNet” to identify violence actions through (1) a two-stream architecture using the state-of-the-art technology in object detection and optical flow estimation; (2) an enhanced optical flow input using action silhouette overlays; (3) complex action classification technique using action decomposition; and (4) a quality violence dataset for surveillance cameras. The project expects to produce competitive results compared to the state-of-the-art having an accuracy greater than 88% and implemented in real-time running on at least 11 frames per second."
"Tremor detection, home healthcare, deep learning, face identification, video processing","In response to the coming aging and lonely society, the home healthcare needs of the elderly must also be reformed. Many chronic diseases increase with increasing life expectancy, and symptoms of physical tremors accompany most. If we can detect and treatment early, it can slow the progression of the disease and enable patients to live long and enjoy a high quality of life. However, the tremor of these diseases is very subtle in the early stages, which makes it difficult to detect with the naked eye. Therefore, detecting body tremor signals is critical to identifying or diagnosing underlying diseases. The frequency measurement using the camera can obtain the spatial high-density information of a long-range measurement target, and can also be used for remote or non-contact monitoring. Therefore, it has the advantages of low cost, high availability, and simple installation, which makes it very suitable for home care environments. However, such image-based frequency detection systems require complex image and signal processing to interpret frequencies from image data. This project proposes a method based on video and machine learning that can detect tremor signals covering the frequency range of six significant tremor symptoms in the human body. This method uses long short term memory recurrent neural network (LSTM-RNN) and multi-objective learning to directly predict the tremor frequency. Then, based on the principle of long-term observation, the weighting average statistics is used to identify possible categories of tremor symptoms and alert the subject of changes on time. The system also uses facial recognition for different members of the family, which can accurately provide personal health care services."
"Artificial Intelligence, AI in Healthcare, AI Black Box, AI Deep Learning, Civil Liability","AI artificial intelligence has become the hottest topic today. The breakthrough and rapid development of AI technology have gradually changed the face of human life. Artificial intelligence (AI) in healthcare is the focus of the topic, and its application range is very wide, including medical robots, image assist Diagnosis, clinical decision support system, personal health assistant and medication management, etc. According to reports, the market size of medical AI has reached 2.24 billion US dollars in 2018, and such a huge market urgently needs a legal system to regulate and support.    The application of AI medical treatment has achieved exceptional results in both medical radiology and medical imaging; its accuracy and speed of detecting diseases even exceed that of human doctors. The IBM's ""Watson for Oncology"" has created a new era for AI in healthcare. This AI system can diagnose various cancers including breast, lung, large intestine and rectal cancer. The system can not only provide treatment recommendations to physicians through interpretation of patient medical records, physiology and imaging studies, but also display information on drug efficacy, side effects, 5-year survival rate, etc. for its recommended medication. To a certain extent, ""Watson Oncology Doctor"" has already become an AI doctor who consults with human doctors, not just a tool to follow the instructions of human doctors. Taipei Medical University has already introduced the ""Watson for Oncology""in 2017 and has provided medical services to more than 700 patients.    However, AI will have the problem of ""Black Box"". When people input data into AI, the system processes through complex neural network of deep learning, and then outputs the results of its judgment. However, how does AI make specific results or diagnosis suggestions? It is difficult for humans to understand its operation logic. The entire process is as opaque as a black box. In this case, if the AI medical system is wrong and misdiagnosed, who should bear the civil liability? Is it AI system manufacturer or supplier? Or AI algorithm developer? Or is it doctor or hospital? This issue is worth exploring in depth.    This research project explores the civil liability for AI in healthcare under the US and EU legal systems, and compares it with Taiwan's legal system, to examine how Taiwan's civil liability system should be adjusted to  the impact of future AI medical waves. This research will focus on four topics: who should bear the civil liability for AI misdiagnosis, the issue of the negligence of doctors using AI, the defensive medicine issue resulted from the application of AI, and the ""electronic personality"" issue of AI. I will discuss and analyze the relevant literature of the US, the EU and its member states, and Taiwan, including their legislation, amendments to the law, academic articles, expert opinions and other valuable materials, and propose amendments to the current Taiwan's civil legal system so that Taiwan's civil law system can fully reflect the international trends in the development of AI in healthcare."
"Deep Learning, Neutral Network, Channel State Information (CSI), Activity Recognition.","This project studies the application of Deep Neutral Network (DNN) based on Channel State Information (CSI) and Received Signal Strength (RSS) to design and develop the device-free position and activity recognition system. Based on the diverse and information of CSI and RSS, as well as the excellent performance of deep learning, it can effectively capture the user's position and activity to achieve device-free indoor positioning and motion recognition. The performance of deep learning depends on a large amount of sample data to ensure that enough sample bases are learned in order to obtain better robust performance. However, obtaining a large amount of sample data is a time-consuming task, so the first of this project will focus on the capture and segmentation of CSI and RSS data to achieve the effectiveness of deep learning in positioning and activity recognition. Through accurate segmentation of CSI, the amount of data required for training samples can be reduced, the time-consuming work of data collection and the accuracy of limb activity recognition are improved. A tandem integrated positioning and activity recognition system is proposed to train the positioning/activity recognition network separately, then connect the two models in series, and finally perform fine-tune training to reduce the number of training samples and training time."
"Privacy concern, deep learning model, sensitive information","The purpose of this research project is to investigate the influence of patient’s demographic information and sensitive information on inpatient’s privacy concerns. Demographic information including gender, age, living area, special identity, and class of bed will be collected. Sensitive information including whether patients admit to hospital with operations, with chronic diseases, allergy, type of diseases, Elixhauser comorbidity index, and specialty of admission to hospital will be collected. This research project will be carried out in one year. Subjects will be inpatients who asked for hiding their information to the public. The collected data will be analyzed by using deep learning models and logistic regression, and prediction accuracy will be used to compare between these two types of analysis techniques."
"Deep Learning, Botnet, Data Cleansing, Big Data, NetFlow","Nowadays, most botnet detection researches prefer using synthetic traffic datasets to evaluate their performance. Synthetic datasets are usually generated from TestBed by capturing the behaviors of malware samples such as Storm, Waledac, and Zeus. They can benefit us to label the malicious traffic as well as benign traffic correctly. However, these kinds of datasets still have a deficiency, which lacks the variety in contrast to real-world traffic. This is also the reason why most botnet detection methodologies cannot apply directly to real network environments. In our previous work, we have developed a P2P botnet classifier using deep learning with BotCluster trying to identify malicious activities on the fly. The P2P botnet classifier fills the vacancy of BotCluster, which is the need for accumulating enough data before do analyze. However, we also found that under the same parameter settings, a model has very opposite performance on a synthetic dataset and real-world dataset. FPR (false positive rate) in real traffic is 20 times than in artificial traffic. After investigating the details, we find that many feature vectors have ambiguous labeling in real-world traffic in contrast to the synthetic datasets. The impurity datasets will influence the model training, lower the predicting performance, and eventually induce GIGO (garbage-in garbage-out). This research proposes a data cleansing method to improve the data quality by removing ambiguous labeling for enhancing the precision in predicting of P2P Botnet in real-world traffic."
"Artificial Intelligence, Deep Learning, Sentencing Prediction, Charge Classification, Multi-Objective Optimization","In this project, we propose a sentencing prediction system for criminal law cases through deep learning. This project assists judges in making decisions in the criminal trials. In addition, by providing case result prediction systems to the public, the court’s trial logic is foreseeable, as a result, the credibility of our judicial institutions can be enhanced. To build the prediction model, we collect two kinds of open data from the government, which are indictment and judgment. The prediction model is built upon the judgment, and the accuracy is evaluated using the indictment. There are four parts in this project. The first part is to extract the semantic features, and automatically select the key items from the law texts, and combine the legal corpus for the analysis of subsequent steps. The second part is to build a crime type classifier and predict through the mapping of fact descriptor and crime type labels. The third part is to build a sentencing predictor for criminal cases through deep learning technology. Through the multi-objective optimization mechanism, the first and second goals are interacted to affect the accuracy of crime classification prediction and sentencing prediction. Through a single machine learning architecture, the weights of all neural networks are completed at once Adjustment. The fourth part is to establish an online service that allow users to input their case and upload customized selection suggestions. Finally, our system will return the predictions to the user. The goal of this project is to establish a system and technology to help the judges in the court and the people in the public. For the legal institutions, we hope to provide high-value intelligent references to help decision making and help people understand the logic of law, thus improve the judicial credibility and facilitate the efficiency of legal affairs."
"Multi-task model, advanced driver assistance system (ADAS), instance segmentation, semantic scene segmentation, monocular depth estimation, deep learning network","Advanced driver assistance systems (ADAS) is an important topic in the research of smart vehicle technologies. One of the critical parts in ADAS is scene understanding, which processes the information coming from the external environment. Recently, deep learning technology has greatly improved the accuracy of  task execution in ADAS. However, most proposed models are complicated, and execution of independent tasks usually causes a waste of time and inefficient memory usage. Therefore, the goal of this project is to design a new architecture of multi-task systems to effectively improve system performance. 	Three important issues should be considered in designing a multi-task model: the architecture of the neural network, the design of the loss function, and the allocation of memory resources. Most multi-task models often select existing components that perform well in single-task processing and combine them into a multi-task model without considering the parameter configuration, the characteristics of the models, and sharing-content between tasks. Therefore, it results in a huge system. Moreover, traditional methods manually adjust the weighting factors between multiple loss functions. Not only is it difficult to learn the model from all tasks, but the model is not easy to be adapted to different scenarios.  Due to the limitation of memory space, existing methods may discard the complicated backbones which have powerful feature representation capabilities, or use light networks in the subnet. This kind of selection will affect the accuracies. 	This project proposes a two-year research project to develop a new multi-task neural network, which can be efficiently applied to the tasks of instance segmentation, semantic scene segmentation, and monocular depth estimation. In the first year, the project proposes a new module unit for the shared layer of a multi-task neural network, which can extract better features for each task. The module unit developed in this project will be named as Entire Attention Module (EAM).  The proposed module can enhance the representation ability of the feature sharing layer between subnets and can be easily applied to other existing architecture. To enhance the feature representation for semantic scene segmentation and instance segmentation at the same time, we plan to use three attention models as the structures of subnets, and the FLOPs and the usage of memory will be better than traditional networks with 3x3 convolutional masks.	In the second year, the project proposes solutions for how to allocate limited memory resources and how to design a good loss function. For memory resource allocation, we plan to propose a new multi-task architecture, Pyramid Entire Attention Network (PEANet). The determination of subnets and parameters is based on the importance of each task. For the design of the loss functions, we intend to integrate the methods mentioned above and propose a set of loss functions which can have stable  and faster convergent process."
"multi-exposure image fusion, multi-focus image fusion, deep neural network, attention network, image alignment, dilated attention ResNet, tone mapping, morphology operation, Gaussian filtering","In the first year of this MOST research project, a multi-exposure dynamic image fusion approach using deep neural networks is proposed. First, reference LDR color image selection and pre-processing are performed. The attention network is used to align non-reference LDR images with the reference LDR image. Then, dilated attention ResNet is used to generate the fused HDR image. Finally, the final fused HDR color image is obtained by tone mapping. In the second year of this MOST research project, a multi-focus image fusion approach using deep neural networks is proposed. First, the gray level version and then the EOL image of each multi-focus color image are obtained. CNN is employed to exact multi-scale image features. The probabilities generated by CNN are used to generate the initial focus map, followed by the final decision map using binary classification. Based on the final decision map, the final fused image is obtained by image fusion."
"deep learning, earthquake, earthquake location, graphic processing units","A rapid and accurate earthquake detection and location algorithm could provide timely information of seismic activities and therefore benefit the understanding of the physical mechanism of faulting and seismic hazard assessments. I propose a GPU-accelerated Automatic Microseismic Monitoring Algorithm (GAMMA) for accurate and near real-time earthquake location form small to large earthquakes. The GAMMA utilizes a backprojection based method to automatically detect potential earthquakes. A deep learning method, attention U-net techniques, is adopted to pick seismic phase arrivals. The accurate seismic phse arrivals could improve earthquake locations. For more a complete earthquake catalog, the qualified earthquakes are then selected as template events for searching small earthquakes in continuous recordings using the template matching algorithm (TMA). The more complete catalog determined may provide essential information for understanding the physical mechanisms of faulting and comparisons with other independent studies, such as dynamic ruptures, or crust deformations."
"lymphoma lesion, whole-body diffusion-weighted magnetic resonance imaging, deep learning, automatic segmentation","Imaging biomarkers are important tools for the detection and characterization of cancers as well as for monitoring the response to therapy. Diffusion weighted magnetic resonance imaging (DW-MRI) probes tissue water molecule diffusivity with the possibility of extracting alternative quantitative information, the so-called apparent diffusion coefficient (ADC).     We have shown previously the potential of DWI with ADC mapping for lymphoma lesion detection at diagnosis and treatment response assessment (Lin et al. 2010, 2011). Recently complete results from our NSC (former MOST) - ANR supported Taiwan-France joint project also showed ADC values of the residual masses after two chemotherapy cycles were significantly higher in good PET response patients than those with inadequate response (Lin et al. 2019 RSNA conference paper). Continuing ancillary study as an individual MOST project assessing water diffusivity as imaging biomarker of Hodgkin lymphoma treatment response is ongoing and in its last year of patient inclusion.    So far our NSC-ANR results have been focused on the main bulky mass (> 7cm) with volumetric ADC analysis encompassing the entire mass. The reason was that the bulky mass tends to stay early during the chemotherapy and their response is crucial for patient’s prognosis. However, lymphoma lesions can be disseminated and it might be worthy evaluating the clinical implication of “whole body” tumor burden in terms of tumor volume showing restricted diffusion and their interlesional heterogeneity on DW-MRI. Nevertheless, it can be extremely time consuming to detect and to delineate all lesions on a whole-body scale. Unlike FDG-PET, few tools providing automatic segmentation of lesions on DWI are available but not commercially available. Until now a single conference paper had brought up this idea in lymphoma, but without using artificial intelligence (AI) deep learning approach.     Therefore the purposes of this project were to 1) test proposed approaches including both traditional image segmentation methods and deep learning, 2) determine the robustness of these three approaches in automatic lymphoma lesion segmentation. Our training input image data will be based on 100 Taiwan patients’ whole-body DW-MRI from our above mentioned MOST projects."
"large-scaled cortex-like mapping, convolutional cortex-like neural networks, grid-structured filters, cubic convolution, deep learning, interactive dynamics of unsupervised learning and supervised learning, generative sub-grids, convolutional cortex-like hidden layers, stacked convolutional responses, minimal wiring and maximal fitting, four-dimensional convolutional filters, Kullback-Leibler dive","This project proposes novel deep convolutional cortex-like neural networks, exploring convolutional operations of grid-structured filters and stacked convolution responses, and developing hybrid objectives of unsupervised learning and supervised learning as well as deep learning processes. The proposed neural architecture and deep learning processes will be extensively applied to object classification, high-level feature abstraction,  internal representation extraction and visualization, test accuracy boosting and video classification. In additional to the input and output layer, a deep convolutional cortex-like neural network is composed of multiple hidden cortex-like layers, each consisting of grid-structured cortical points or convolutional filters and forming ordered cubic neural organization. A pattern is received from the input layer, and feedforward propagated layer-by-layer through hidden layers to the output layer. This project plans to correspond cortical points  to high-dimensional convolutional filters and organize a cortex-like hidden layer by grid-structured filters.  On the basis, this project further explores adaption of convolutional filters following the requirement of minimal wiring of neighboring filters on a grid, and clarifying its effectiveness for boosting test accuracy subject to the criterion of minimal training error.  Following the minimal wiring and maximal fitting principle, this work devises novel interactive unsupervised and supervised learning processes. Filters organized on a grid operate linear convolution, planar or cubic convolution. Convolutional responses of filters on a grid are stacked according to the grid structure to form the stacked output pattern of the hidden cortex-like layer, which is further convoluted  by  the upcoming cortex-like hidden layer.  The input pattern of a hidden cortex-like layer is the response of its previous cortex-like hidden layer. The output patterns of all cortex-like hidden layers are consistent in form for convolution. Except for  revisiting formulation of minimal wiring and maximal fitting criteria, this work explores deep learning based on novel quantitative objectives. The  gradient-based  deep learning optimizes coefficients of filters or interconnections of convolutional cortex-like neural networks in combination with generative sub-grids on nodes of a primary grid for constructing large-scale cortex-like hidden layer. Against existing convolutional neural networks, the proposed architecture  is more efficient for developing grid-structured filters that tends to fit the requirement of minimal wiring under premise of the minimal training error. Minimally wired neighboring filters on a grid are expected more effective for extracting high-level feature abstraction of discriminate analysis, boosting test accuracy based on interactive dynamics of unsupervised and supervised learning with applications to object classification and video analysis. Pre-project study has encouraging numerical results of applying preliminarily developed software of learning deep convolutional cortex-like neural networks for analyzing cifar-10 dataset, where the test error has been reduced to 16.6% and test accuracy of analyzing cifar-10 dataset has been significantly improved against popular deep learning softwares."
"optimal water source allocation, pest detection, Deep learning, Crop damage assessment","Taiwan has been classified as a water-poor region by the United Nations. Due to the impact of global climate change, the problem of water resources is becoming increasingly serious. The agricultural products produced in Neimen District of Kaohsiung City are of good quality and have a very good market response. However, there is a lack of stable water supply, which may cause considerable agricultural losses in the event of a drought. A good water distribution system can ensure that the farmland can have a stable water supply at any time. It can also analyze the dry season, geology and other variable factors and take special measures to deal with sudden water shortages. In addition to the lack of water, plant diseases and insect pests are also one of the major factors that cause agricultural losses. Plant diseases also cause the appearance of the crop to deteriorate, resulting in poor sales and economic losses. Therefore, this research hopes to use advanced technologies, such as image interpretation, machine learning, and geographic information systems (GIS), to help farmers solve problems to ensure the yield and quality of crops.Therefore, this study will be divided into four parts, namely optimal water source allocation, planting area early warning system disease, pest detection (taking banana as an example), and yield and damage assessment. The optimal water resources allocation will consider the distance from the water source, the species of crops grown, the water requirements of the crop, plus elevation and geology, and evaluate the water sources available during the dry season to develop a complete water resources distribution system; The area early warning system will use on-site survey methods, supplemented by machine learning images to classify species interpretation, and collect planting species borrowed from various places in the test area. And use geographic information system, add Fuzzy judgment mode and establish crop supply and demand curve in the region, assist the region to determine whether it is over-planted, and provide suggested planting options; the study will use multiple machine learning methods and deep learning to automatically detect and diagnose pests Through the testing of algorithms, a more convenient and faster method for detecting pests and diseases will be established. Yield and disaster assessment will use image analysis and processing software, combining features and analysis algorithms of ground features, to perform yield estimation and disaster assessment."
"COVID-19,Deep Learning","At the beginning of 2020, the COVID-19 caused more than 3.04 million infection cases in the world. The incubation period from infection to onset is 2 to 14 days and the period of the first three days of onset is the most infectious. Thus, early detection of infected cases is important to prevent the spread of disease. Among the currently published literature and the winning teams of the Kaggle, most of the research results focus on the classification between COVID-19 and normal images. However, clinical patients may have lung diseases other than COVID-19. So, it is necessary to develop a diagnosis model for COVID-19, pneumonia and multiple lung diseases. This project will develop the multi-lung disease imaging diagnosis model. Based on our previous research, we plan to develop the deep learning model that can quickly diagnose COVID-19 and multi-type lung disease imaging within one year."
"Taiwan Sign Language, Automatic Translation, Sign Language Training, Deep Learning","The joint project entitled “Taiwan Sign Language Translation and Training Systems Base on Deep Learning Techniques” plans to investigate deep learning methods (including training data preparation, detailed feature extraction, base sign gesture recognition, and continuous sign language translation (and for training). The project includes four subprojects:Subproject one: Construction of Taiwan Sign Language Database for Deep Learning TrainingSubproject two: Lifelong-learning Based Sign Language Recognition Associated with Facial Expressions and Meaningful GesturesSubproject three: Using Deep Learning Techniques for Common Taiwan Sign Language TranslationSubproject four: A Deep-Learning-based Visual Recognition Scheme for Taiwan Sign Language TrainingThe project team includes many professors in Computer Engineering areas, including Human-Computer Interaction, Software Development, and Deep Learning. In addition, experts of Taiwan Sign Language Translation will define the scope of sentences that will be used in the translation system. Test data will be collected by the Association for Taiwan Sign Language Translation. The first subproject focuses on the scope definition for translation. And, a data collection tool will be implemented. A database management system will be integrated with the data collection tool. Thus, collected sign language data set can be retrieved in an easy manner. The second subproject focuses on semantic segmentation of sign language videos. Facial expressions will be recognized and used as a base in translation. The second subproject also proposes a new direction to use a minimal set of training data. Thus, the translation system can be used for other sign languages in the future. The third subproject deals with the main sign language translation modules. Base sign gestures will be recognized by CNN like neural networks. With the changing time duration of gestures in a typical sign sentence, the third subproject will also propose methods in sequence to sequence translation (e.g., RNN, LSTM, etc.), in order to precisely translate words and sentences. The fourth subproject further analyze skeleton of two hands, as well as features in user’s face. A training system will be implemented to give users a score, which reveals the degree of similarity w.r.t. a standard signa language sentence. The training system can be further implemented in a lightweight device for users. Automatic Taiwan Sign Language translation is a difficult and very important research area. If properly implemented, the contribution will benefit those who relies on sign language for communication, as well as those who use a similar technology for practical applications (e.g., gesture for interactive machine design). The systems that will be delivered can be used for technical transfer purposes in Taiwan’s industry. The Taiwan Sign Language dataset and its database management system can also benefit other researchers who are interested in Sign Language Translation."
"Deep learning, transfer learning, anomaly detection, fracture","Trauma is one of the major sources of medical cost. It is also the leading cause of hospital admissions and emergency department visits by younger and middle-aged members of the population. Fractures are the most common consequence of trauma, and the most frequently missed fracture sites include pelvic, femoral neck, foot, elbow and wrist fractures. If these fractures are not diagnosed upon first examination, it could lead to delayed effective setting or surgical intervention and cause further unnecessary disability and excessive medical expenses. Although a foreign company based on Western X-ray images has developed a system for wrist fracture detection, there is no available tool or computer system to assist with the clinical diagnosis of fractures elsewhere in the body from X-ray images. First line emergency physicians depend on their own experience to diagnose fractures from patients’ X-ray images. Sometimes, the existence and site of a fracture is not obvious or is difficult to detect if it remains slight or undisplaced and this can lead to a missed diagnosis. Deep learning (DL) has become one of most popular computer-related techniques, and is especially suitable for image analyses which has shown remarkable performance surpassing traditional techniques based on hand-crafted features. In recent years, a variety of medical image analysis tasks using DL have been proposed, such as detection and classification (cancerous area vs. non-cancerous area), and segmentation and object detection (neuronal or cell structure). Over the past two years, we have accumulated an abundance of experience in the use of various DL techniques for the detection of hip fractures from pelvic X-ray images and identification of glomeruli from renal biopsy pathological images. Based on this experience and results with processing medical image data, in this project we plan to continue collecting vast amounts of available limb joint and pelvic X-ray images from Linkou Chang Gung Memorial Hospital and perform image labeling. In addition, we plan to apply various deep learning techniques to limb joint and pelvic X-ray images for the detection and identification of fractures. These techniques include adopting the transfer learning concept and anomaly detection method through the use of generative adversarial networks, and the addition of a deformable convolution operation and visualization techniques, in order to further improve the performance of fracture detection models. In summary, the tasks for this project are 1. Collecting limb joint and pelvic X-ray images from Linkou Chang Gung Memorial Hospital and performing image labeling.2. Through the use of generative adversarial networks introducing the transfer learning concept and anomaly detection method for fracture detection.3. Adding various other deep learning approaches to improve the performance of fracture detection.By accomplishing the above goals to develop a model using DL, we expect this fundamental work can combine with clinical settings for developing a medical imaging warning system to assist in the early diagnosis of fractures in the future."
"smart water meter, data analytics for water supply, deep learning, edge computing","Smart water governance has become an important issue due to limited water resource. For this, smart water meter (SWM) is key to smart water supply services. With SWM, typos caused by manual meter reading and disturbance caused by customer visits can be avoided. It could also be applied to detect abnormal water leakage or meter malfunction, and to determine whether the caliber of water pipe is appropriate. Moreover, by analyzing the trend of water demands, customer behavior can be learned and the peak/off-peak time of water demand in urban can be derived. Then, the performance of water supply can be improved. However, as the wide deployment of SWM, several technique issues are required to be solved, including the effect of data analysis, the reliability of the system and the protection of data privacy. Therefore, by cooperating with the largest SWM manufacturer, Energy Management System Co. (EMS), in this project, we would like to develop the value-added AI-driven services for SWM systems. Through integrating the domain know how of EMS and the research resource of NTU, this project will analyze the operations of SWM based on deep learning, extract the feature of water demand, detect abnormality and issue alarm, protect data privacy, and automatically discover the distribution and variety model of water demand. Based on the developed techniques, the detailed features can be extracted and the analytics model can be determined. Moreover, the requirements from various parties can be fulfilled by improving the SWM system, and the quality of life of customers can be promoted. The waterworks can also be managed efficiently. Overall, this project considers both theoretical innovation and industrial benefits. It not only improves the management of smart water service and enriches the variety of data economic applications, but also increases the international visibility of Taiwan in smart water management."
"Photovoltaic Module , Electroluminescence, Defects , Machine vision, Deep learning","Because of Taiwan’s reliance on energy import and the current global energy shortage, energy transformation and energy autonomy means for reducing reliance on energy import are novel drivers of green technology development and industrial innovation in Taiwan. In the photovoltaic module manufacturing industry, manufacturing procedures involve dozens of precision manufacturing steps on the production lines, in which no error is allowed in each step. Manufacturing errors can result in damages to solar panels such as hidden cracks, broken fingers, ruptures, and unevenness. These defects affect the solar power conversion efficiency and panel service life. To address this problem, this study will capture electroluminescence images after photovoltaic module manufacturing to determine the defects of modules. Machine vision and image processing will be employed in combination with deep learning models trained for defect detection to develop a smart defect detection system. This study will implement the following work items over a course of 1 year.  1.	Construction of machine vision modules2.	Optomechanical design and manufacturing3.	Development of image processing and identification technology4.	Establishment of deep learning platforms for defect detection and model training5.	Development and integrative testing of a software program for the integration of the operating interface and defect analysis system"
"Driving behavior analysis, fuel consumption driving, On Board Diagnostic II, Controller Area Network Bus, driving information, deep learning","Driving behavior analysis has been applied to achieve positive effects of fuel consumption driving and driving safety in some advanced countries. The PM2.5 emitted from vehicles was close to one-fifth of the total air pollution. The problem of air pollution has led to a reduction of 1.8 years in the average life of each person in the world. Therefore, how to achieve a fuel consumption driving is an urgent issue. Moreover, an excellent fuel consumption driving usually enhances driving safety. In North America, driving information using On Board Diagnostic II (OBDII) and recording driving behavior in the database has become very popular. There is no interference for driver using a vehicle’s OBDII port to collect driving data. Such as the new application of driving behavior analysis, there are 500 million people using Usage Based Insurance (UBI) to reduce premiums. Vehicles equipped with the remote information capturing device allow an insurance provider to have more precise information to access driver’s premiums. Therefore, this project estimated driving behavior by wirelessly transmitting driving information to remote servers based on the CAN Bus multi-protocol integration technology. Moreover, the proposed system can provide statistical recommendations for drivers by analyzing the relationship between fuel consumption and driving behavior through deep learning model. Finally, the environmental pollution and traffic accidents can be improved through the fuel consumption driving training."
"Deep learning,Smart Surveillance,Object recognition,Convolution Neural Network,Real-time,Embedded system","In recent years, deep learning has been widely used in the field of smart surveillance, and technologies that have been deployed in consumer products such as object recognition, vehicle brand recognition, parking space recognition, etc. In the smart surveillance application of deep learning, it is necessary to have powerful image recognition ability. Through the continuous research and improvement of future generations, a deep learning architecture suitable for application in the field of image recognition has been developed. This deep learning architecture is called Convolution Neural Network (CNN).The CNN architecture used by Smart Monitor is mostly derived from the winning network architecture of the ImageNet Large Scale Visual Recognition Challenge 2012. These more famous CNN architectures have deeper and more complex neural networks for higher precision. With the development of hardware technology, high-end hardware devices have enabled these complex neural networks to achieve real-time operations. However, in the field of smart surveillance, multi-channel frames need to be processed at the same time and real-time operations; thus, the computational intensive required for these large numbers of surveillance videos is difficult to overcome. Due to the huge computational cost of the surveillance system, the main research content of this project is using the high similarity characteristics of continuous frames to improve the architecture of the traditional CNN; and reduce the weight parameters of the neural network appropriately to reduce redundant computation. Enables the system to process multiple channels of surveillance videos more efficiently on embedded system."
"Unmanned Underwater Vehicle, Underwater Image Restoration, Localization and Navigation, Cooperative Localization, Deep Learning, Sonar Signals","Rapid progress in deep learning and artificial intelligence has drastically boosted the level of autonomy in unmanned vehicles.Nonetheless, most R&D efforts have been put on land-use or air-bone devices. Research on underwater unmanned vehicles (UUV) has received attention only recently. Over 70% of the earth is covered by water. In particular, Taiwan is an island surrounded by oceans. The demand for UUV is strong, and there exist huge market opportunities for this type of product.?Underwater localization and navigation are complicated by two factors: poor image quality and lack of reliable features for tracking. This project aims to investigate and develop feasible solutions in three aspects: 1) underwater image and video restoration, 2) vision-based localization and navigation, and 3) cooperative localization and navigation mechanism by integrating multiple sensors.For image and video restoration, we will utilize deep learning frameworks for underwater color correction to provide high-quality images for operators or object detection modules to form better decision making. After model compression and optimization, we plan to integrate the solution into existing devices through an edge-computing unit. For vision-based localization tasks,?we plan to evaluate the robustness of tag-based solution and stereo cameras, in an effort to investigate the feasibility of underwater SLAM.For multi-sensor cooperative approaches, we will integrate visual data, sonar signal, and GPS information from different UUVs to build a reliable localization and navigation system that can operate when only partial, incomplete data are available.The solutions developed in this research will be integrated into ThunderTiger's products to enhance image quality and device autonomy, thereby strengthening its competitiveness and?expanding its market share."
"Artificial intelligence, Deep learning, Edge computing, Face Recognition, Facial Landmark, Human machine interface, Access control system","Compared with the traditional access control system which USES RFID password electronic lock or fingerprint and iris identification, people's development status of artificial intelligence technology and the innovation and evolution of access control system, face recognition technology has become a new eye-catching focus in the market. The introduction of AI artificial intelligence into the access control system has evolved into an emerging access control management identification technology, which has become a new development trend of access control system. From the Angle of the artificial intelligence in combination with entrance guard system, applying the entrance guard system with more deep learning technology import as function, using artificial intelligence to assist edge platform authentication of identity, through the cloud platform is combined with the weak force platform makes system establishing cost more conform to the trend of market value, effectively through the neural computing to accelerate the great reduce demand for end device of computing power, more in line with the operational requirements of human face recognition system at the same time. This project combines the cloud computing platform to apply the system called Tiny Deep system to the edge computing platform of weak and strong computing power. The work is divided into three parts: (1) Design a depth study of the first part is weak and the strong force between edge computing platforms and cloud computing platform training model automatic transfer system, two cross training and inference system, to develop a set of training mechanism will use Google Cloud services training, after training and through the Cloud IoT core for deployment, to complete the training on the Internet are marginal platform is weak and the strong force, at the same time the system will provide application oriented human face recognition, make Google Cloud can according to the resources needed to provide terminal unit operation. (2) The second part is the design of TinyDeep system developed with facial calibration function of entrance guard face recognition technology and application, research TinyDeep system use strength to calculate force platform using deep learning, effective under the face recognition and face calibration, let whole system in the simplest way to integrate into a depth study of access control management system. (3) The third part is the design of TinyDeep system development which keep the characteristics of human face recognition model and the training model of quantitative (Quantization) optimization. To make neural accelerate rods can count in weak force platform operation, the training optimization and quantitative processing of the model after training and inference make the TinyDeep system faster and less costly. Finally, face recognition is used for identity authentication and access control management."
"Deep learning, edge computing, flame detection","With the popularization of edge computing in 5G network technology and and cameras are generally installed in modern buildings, this project intends to capture images of objects burning flames through network cameras, and use artificial intelligence deep learning technology for flame detection in the flame burning growth process. Moreover, this project intends to provision of flame recognition results to the front-line disaster relief command center through edge computing technology, for it to decide whether to assign firefighters to the fire scene to extinguish the fire and fight for the disaster site.To collect sutiable fire flame data sets is first step, and then we build the artificial intelligence framework, Tensorflow, and the deep learning YOLO object detection algorithm. A flame detection model is built for the burning and growth state of fire flames. In addition, it combines edge computing technology and deep learning flame detection technology to provide future forward-looking research on real-time flame detection and information transmission at the fire scene. The research results can be used for subsequent improvement of domestic fire protection. The improvement of the system strives for fire rescue time and reduces personal injuries."
"lithium-ion battery pack,Automated production line,Data integration,Defect detection,Deep Learning","Lithium-ion batteries have the advantages of high energy density, long cycle life, no memory effect, light weight, only slow charge loss when not in use, and have been widely used in information technology (Information Technology, IT), power tools market (Power Tools, PT), electric vehicle (Electric Vehicle, EV) and energy storage. Although Taiwan's lithium-ion battery pack factory accounts for 40% of the world's market share, but the quality of products is uneven, lithium batteries burning or exploding when heard. The production of lithium-ion battery pack is a key step in the design and application of the future power battery system, and the automation and intelligent development technology of lithium-ion battery pack production is an indispensable key technology for Taiwan's manufacturers. Techway Industrial Co., Ltd. for the domestic power tool leading manufacturers, electric wrench output value for the world's first. In order to be able to effectively provide high-quality power tools, Techway Industrial Co., Ltd. in 2018 began to carry out the introduction of automated lithium-ion battery pack production line. After more than 2 years of development and correction, although the production and testing data of each station of the production line are digitized, but cannot effectively integrate. This plan will be based on the development of the lithium-ion battery pack production line developed by Techway Industrial Co., Ltd, the island-type data will be integrated, to achieve the production line production and testing data seamlessly connected and integrated. Moreover, with deep learning algorithm to greatly shorten the image detection time of defective products, will effectively improve the production rate and efficiency of lithium-ion battery pack. The technology developed by this research can also be transferred to the relevant industries, which will effectively enhance the key technical capabilities of the lithium-ion battery pack assembly industry in Taiwan."
"deep learning, ingredient recognition, image analysis, telemedicine, cloud web hosting, personal nutritional blueprint","Based on research into the applications of artificial intelligence (AI) technology in the medical and infomation industry in recent years, many medication activities can focus on person-centred  interaction. Nowadays, people are undoubtedly familiar with the maxim that prevention is better than a cure. Hence, many wearable devices such as Continuous Glucose Monitoring (CGM) are used to manage diabetes and helped other chronic medical conditions to be cared. As we know a healthy diet helps every grow and reduces the risk of chronic diseases. It may be keep users from getting sick, if services of the CGM system can be redeveloped for keeping the information of user’s dietary. However, most commercial CGM systems are mainly relied on dietitians to interpret the nutrition information. It is hard for them to translate the uploaded ingredient pictures into the nutrition information. In this project, we propose a dietary tracking supporting system based on the deep learning architecture to help the dietitians in interpreting the nutrition information and the amount of calories in pictures. We then keep the uploaded information as our training data and testing data for further processing. And developing applications to establish a personal nutritional blueprint. With the blueprint, the medical care services can access the history of the patient behavior and give a better solution for the future."
"Fall Detection, Internet of Things (IoT), Artificial Intelligence (AI), Edge Computing, Deep Learning","Falls are a major issue facing elderly people (i.e., adults older than 65 years of age). An estimated one-third elderly people globally falls occur each year. The mortality increases when falls are discovered late. Accordingly, this proposal proposes an artificial intelligence (AI) edge computing fall detection system to timely discover a fall event and issue the emergency notification for life safety care of elderly people. In this system, a deep learning framework (e.g., Tensorflow) with human pose estimation is implemented over an AI edge computing embedded module to infer multi-person skeleton movements in given images from an image sensor module. Based on the inferred skeleton moving information, a fall detection algorithm is proposed to calculate the moving speed, tilting angle, posture changes of each skeleton to determine whether a person in front of the image sensor lens falls or not in real time. The proposed AI edge computing fall detection system can be formed into all-in-one version, and distributed version, respectively for applying in various fields. The all-in-one version system is developed as a module-integrated device composed of an AI edge computing embedded module, an image sensor, and a PoE network module, which is suited for the home care environment. The distributed version system is designed as an edge computing server composed of multiple AI edge computing with PoE network embedded platforms to integrate with the existing IPCAM system in public safety care fields (e.g., nursing home, hospitals, and so on). Therefore, the distributed version system is enabled to detect fall events by using the video streaming from the designated IPCAM. Unlike the existing wearable fall-detection solutions, the proposed system discovers falls by using the images from image sensor or IPCAM without requiring the elderly people to wear any device. Furthermore, the images from image sensor or IPCAM are only used for fall detection in this system but not forwarded to remote site. Thus it will not cause privacy issue as the existing camera-based solutions. In order to determine the effectiveness of the proposed AI edge computing fall detection system, this proposal plans to deploy the system in one of the selected nursing home or hospital for testing and discovering the fall-detection performance. In hopes that the contributions of this research and development (R&D) project can not only update the cooperative company’s AIoT application R&D capability and enhance its R&D human resources in AIoT technologies but also be an example of the AIoT application in life safety care domain."
"textile coil defect detection, deep learning,  data argumentation,  ResNet50, network re-training","This proposal is to develop a deep-learning based textile coil defect detection system. Since those coil defects are of different properties and usually in a small region, it is difficult to be detect by traditional image processing techniques. From our primitive study, by using deep learning networks, the performance is promising. Thus, in this study, we will consider the actual environment and images obtained to build a real deep-learning based textile coil defect detection system. In the study, a user interface system will be built to obtain training data. In the system, defect marking and data argumentation will be established. The network used now is ResNet50. In the study, some modifications for network will also be considered. Since the detection may hope to have more accurate in normal cases, the threshold for on-hot coding will also be calibrated to match the real requirement. Finally, due to errors or new defect cases, re-training or reinforcement learning must be considered for long term usage of the detection system. This study will also have investigation on this issue."
"Construction site management, Image recognition, Deep learning, Artificial Intelligence, AI","This academia-industry collaboration research is aimed at studying how to effectively apply the emerging technologies of automatic image capture and recognition for construction site management, in order to achieve the goal of intelligent surveillance of the on-site activities, and automatically generate the reports regarding the on-going activities, in particular the activities concerning safety, scheduling, quality control and efficiency. The study includes layout optimization of IOT devices, such as CCTV, for image capture and the deep learning technique from the field of Artificial Intelligence (AI) for vision-based object and activity identification. The collaborating companies in this research project will provide their surveillance needs for construction management as well as surveillance videos from the construction sites. A smart vision-based monitoring system with automatic reporting will be developed by researchers in the university and tested by the collaborating companies to achieve the goal of elevating the effectiveness and efficiency of construction site management."
